Title,Content
Les promesses et les dangers de l’IA générative dans les tests logiciels,"[{'', '<p>L’avènement de l’IA générative (GenAI) marque le début d’une nouvelle ère dans le domaine des tests logiciels. Agissant comme un ingénieur de test IA, GenAI utilise un enregistreur de test conçu pour effectuer un travail équivalent à celui d’un ingénieur d’automatisation de test humain. Il interprète les instructions en langage clair pour générer de manière autonome du code d’automatisation de test. Cette capacité démocratise les tests, en permettant aux personnes sans expertise en codage d’interagir directement avec les frameworks de test. Elle simplifie le processus d’automatisation des tests en permettant aux utilisateurs de générer du code sans effort en enregistrant leurs interactions avec un site Web, sans codage manuel requis. Les testeurs pilotés par GenAI s’intègrent parfaitement dans les pipelines CI/CD, détectant de manière autonome les bugs et alertant les équipes des problèmes potentiels.</p>'}, {""<h3>Transformer l'assurance qualité grâce à l'IA</h3>"", ''}, {'', '<p>Le passage du testeur d’automatisation humaine à l’ingénieur en automatisation des tests par l’IA est transformateur. Traditionnellement, la transition vers l’automatisation des tests nécessitait beaucoup de temps et de ressources, notamment l’apprentissage du codage et la compréhension des cadres d’automatisation. L’IA élimine ces obstacles et accélère les cycles de développement, réduisant considérablement les délais de mise sur le marché et améliorant la précision, tout en diminuant le niveau de tâches administratives pour les testeurs de logiciels.</p>'}, {'', '<p>Les outils basés sur l’IA peuvent interpréter des scénarios de test rédigés en langage clair, générer automatiquement le code nécessaire à l’automatisation des tests et exécuter des tests sur différentes plateformes et langues. Cela réduit considérablement le temps d’activation, permettant aux professionnels de l’assurance qualité de se concentrer sur des tâches stratégiques plutôt que sur des complexités de codage. Cela répond également au grave manque d’automatisation des tests, aidant les entreprises à atteindre la qualité de leurs offres numériques en un rien de temps, pour n’importe quel nombre de scénarios en parallèle et en quelques minutes. Il crée une automatisation des tests pour les sites Web et les applications multilingues, ainsi que pour n’importe quelle taille d’écran, y compris les ordinateurs, les tablettes et les mobiles.</p>'}, {'', '<p>Les gains de productivité de l’IA dans les tests sont considérables. Alors que l’automatisation des tests traditionnels peut être limitée à une seule plateforme ou à un seul langage et à la capacité d’une seule personne, les tests améliorés par l’IA brisent ces limites. Les testeurs peuvent désormais créer et exécuter des tests sur n’importe quelle plateforme (Web, mobile, ordinateur de bureau) en utilisant plusieurs langages, avec la capacité de plusieurs testeurs. Cela amplifie non seulement les capacités de test, mais introduit également un nouveau niveau de flexibilité et d’efficacité.</p>'}, {""<h3>L'avantage de l'IA : tests multilingues et 24h/24 et 7j/7</h3>"", ''}, {'', '<p>Le renforcement des compétences des équipes d’assurance qualité grâce à l’IA offre des avantages considérables en termes de tests multilingues et de fonctionnement 24h/24 et 7j/7. Sur le marché mondial actuel, les produits logiciels doivent souvent répondre aux besoins d’utilisateurs divers, ce qui nécessite des tests dans plusieurs langues. L’IA facilite ce processus sans exiger que les testeurs connaissent chaque langue, ce qui élargit la portée et la facilité d’utilisation des produits logiciels.</p>'}, {'', '<p>La possibilité de réaliser des tests 24 heures sur 24 garantit que les tests ne deviennent pas un goulot d’étranglement dans un développement rapide. De plus, les capacités de maintenance autonome de l’IA réduisent encore davantage le temps et les efforts nécessaires à la mise à jour des cas de test, garantissant ainsi que les tests restent pertinents et efficaces.</p>'}, {'', '<h3>Relever les défis</h3>'}, {'', '<p>Bien que GenAI offre des avantages significatifs, il présente également des défis opérationnels et de sécurité que les organisations doivent relever :</p>'}, {'', '<li>Hallucinations : l’IA peut générer des résultats inexacts ou fabriqués pendant les tests, ce qui conduit à des résultats incorrects et peut potentiellement négliger des problèmes critiques.</li>'}, {'', '<li>Biais : les systèmes d’IA peuvent hériter de biais issus de leurs données de formation, ce qui a un impact sur les résultats des tests et entraîne des scénarios de test injustes et des cas extrêmes négligés.</li>'}, {'', '<li>Confidentialité des données : le risque de mauvaise gestion ou de fuite de données sensibles utilisées pendant les tests soulève d’importantes préoccupations en matière de confidentialité.</li>'}, {'', '<li>Manque de transparence : la nature de « boîte noire » de nombreux systèmes d’IA rend difficile le traçage des processus de prise de décision, ce qui entrave le débogage et la confiance dans le système.</li>'}, {'', ""<li>Vulnérabilités de sécurité : les systèmes GenAI sont sensibles aux attaques adverses qui pourraient exploiter les faiblesses du système, compromettant potentiellement l'ensemble du processus de test.</li>""}, {'', '<li>Résultats incohérents : l’IA peut produire des résultats erratiques ou non pertinents, affectant la fiabilité des tests et rendant difficile le maintien de normes de test cohérentes.</li>'}, {'', '<h3>Stratégies d’atténuation des risques</h3>'}, {'', '<p>Pour exploiter la puissance de GenAI tout en atténuant ces risques, les organisations peuvent mettre en œuvre plusieurs stratégies\xa0:</p>'}, {'', ""<li>Supervision humaine dans la boucle (HITL) : l'intégration d'une supervision humaine garantit que les résultats générés par l'IA sont rigoureusement validés en termes d'exactitude et de fiabilité. Les superviseurs humains peuvent examiner et approuver les cas de test générés par l'IA, garantissant ainsi qu'ils répondent aux normes nécessaires avant leur mise en œuvre.</li>""}, {'', '<li>Limiter l’autonomie de l’IA : limiter la liberté créative de l’IA empêche le système de faire des suppositions ou d’agir de manière injustifiée. La définition de limites et de directives claires garantit que l’IA fonctionne dans des paramètres acceptables, en maintenant un processus de test prévisible et fiable.</li>'}, {'', '<li>Exiger un raisonnement pour les actions : l’application d’une politique selon laquelle l’IA doit expliquer ses décisions favorise la transparence et renforce la confiance dans les résultats générés par l’IA. En exigeant un raisonnement pour chaque action, les développeurs peuvent obtenir des informations précieuses sur le processus de réflexion de l’IA et procéder à des ajustements éclairés.</li>'}, {'', ""<li>Pratiques de gestion sécurisée des données : la mise en œuvre de politiques de gestion des données rigoureuses permet de protéger les informations sensibles contre toute utilisation abusive lors de la formation de l'IA. Le chiffrement, l'anonymisation et les contrôles d'accès sont des mesures essentielles pour protéger la confidentialité des données.</li>""}, {'', '<li>Utilisation de données de formation diversifiées : la formation de l’IA sur un ensemble de données très varié minimise les biais et améliore la robustesse du système d’IA. L’exposition à des données diversifiées aide l’IA à mieux généraliser et à réduire le risque de résultats biaisés. La mise à jour régulière des données de formation pour refléter les scénarios actuels et complets garantit que l’IA reste efficace et équitable.</li>'}, {'', '<h3>Exploitez la puissance des pratiques de test pilotées par GenAI</h3>'}, {'', '<p>Alors que GenAI s’intègre de plus en plus dans les cycles de vie du développement logiciel, il est primordial de comprendre ses capacités et ses limites. En gérant efficacement cette dynamique, les équipes de développement peuvent exploiter le potentiel de GenAI pour améliorer leurs pratiques de test tout en garantissant l’intégrité de leurs produits logiciels. En prenant soigneusement en compte les défis décrits et les stratégies d’atténuation, les organisations peuvent exploiter toute la puissance de GenAI pour stimuler l’innovation dans les tests logiciels et fournir des produits logiciels de haute qualité.</p>'}]"
Une enquête révèle l'écart entre DevOps et ITSM en matière de gestion des incidents,"[{'', ""<p>Une enquête menée auprès de 505 développeurs de logiciels, professionnels de l'informatique et décideurs informatiques aux États-Unis révèle que 70 % des répondants travaillent pour des organisations qui tiennent les développeurs responsables des déploiements, et que seulement 22 % d'entre eux effectuent des autopsies sans reproche.</p>""}, {'', ""<p>L'enquête, menée par Atlassian, révèle également que seulement 60 % des personnes interrogées travaillent pour des organisations dans lesquelles les développeurs font partie de l'équipe qui gère les incidents informatiques, et 57 % d'entre elles indiquent qu'elles sont disponibles en cas de besoin. Cependant, 70 % d'entre elles déclarent qu'il est facile de faire appel aux bons coéquipiers en cas de besoin.</p>""}, {'', ""<p>La plupart des répondants (86 %) effectuent également des analyses post-mortem ou post-incident (PIR) après un incident. 97 % d'entre eux déclarent également avoir mis en place des procédures, des processus ou des manuels d'exploitation pour gérer les incidents, 78 % ayant recours à des jeux de guerre ou à une autre forme de formation à la gestion des incidents.</p>""}, {'', ""<p>Dans l'ensemble, l'enquête révèle que les incidents informatiques sont presque tous gérés par une équipe d'exploitation informatique (95 %). Outre les développeurs, les autres équipes impliquées sont les ingénieurs (53 %), les cadres (43 %) et les ingénieurs en fiabilité du site (37 %).</p>""}, {'', '<p>Toutefois, l’enquête révèle également que seulement 15 % des répondants disposent d’équipes interfonctionnelles comprenant des développeurs, du personnel d’exploitation et d’autres professionnels de l’informatique, et que seulement 35 % ont déclaré que leur organisation mettait l’accent sur DevOps comme un changement culturel qui fusionne les équipes de développement et d’exploitation. Seuls 30 % ont souligné l’utilisation de pratiques d’automatisation et d’intégration continue/livraison continue (CI/CD) pour rationaliser les flux de travail, réduire les opérations manuelles et garantir une livraison de logiciels plus rapide et plus fiable.</p>'}, {'', '<p>De plus, seulement un quart (25 %) des personnes interrogées associent DevOps à l’amélioration de la rapidité et de l’efficacité du développement logiciel, et encore moins (20 %) se concentrent sur le rôle joué par DevOps dans l’amélioration de la qualité et de la fiabilité des logiciels grâce à des tests automatisés, une surveillance continue et un suivi des performances en temps réel. Seuls 15 % ont déclaré que la sécurité et la conformité étaient une priorité absolue dans leurs pratiques DevOps.</p>'}, {'', '<p>Néanmoins, 96 % des personnes interrogées estiment que les équipes de développement et d’exploitation disposent de la visibilité nécessaire pour effectuer leur travail efficacement, tout en minimisant les perturbations. 70 % des personnes interrogées ont déclaré que leur organisation peut accéder à l’historique des incidents, aux déploiements récents ou aux modifications récentes pour obtenir du contexte lors de la réponse aux incidents, mais seulement 55 % ont accès aux informations sur l’état des services en temps réel.</p>'}, {'', '<p>Selon l’enquête, plus des deux tiers des répondants (68 %) travaillent pour des organisations qui gèrent de manière proactive les incidents informatiques. Presque tous (99 %) utilisent des outils de surveillance, dont 86 % s’appuient sur eux pour détecter les incidents. Près des trois quarts (73 %) ont déclaré qu’ils utilisaient ces outils pour détecter de manière proactive les incidents avant qu’ils ne soient signalés par les utilisateurs finaux ou les clients.</p>'}, {'', ""<p>La planification des capacités (80 %), l'intelligence artificielle (IA) pour l'analyse des tendances des incidents (74 %) et la surveillance des transactions des utilisateurs (73 %) sont les outils de gestion des incidents les plus largement utilisés, selon l'enquête.</p>""}, {'', ""<p>Kate Clavet, responsable marketing produit pour la gestion des services informatiques (ITSM) chez Atlassian, a noté qu'à mesure que l'intelligence artificielle (IA) continue d'évoluer, il deviendra de plus en plus facile d'intégrer des simulations dans la formation à la réponse aux incidents.</p>""}, {'', ""<p>En termes de mesures suivies, la plupart des répondants suivent le temps écoulé entre la résolution et la résolution (80 %), tandis que 71 % suivent le temps écoulé entre la reconnaissance et la réponse et 55 % le temps écoulé entre la réponse et la résolution. Au total, 61 % utilisent les tickets créés par les plateformes ITSM comme source unique de vérité pour la gestion des incidents, tandis que 39 % s'appuient sur un outil de chat. 60 % ont déclaré qu'ils n'utilisaient pas de base de données de gestion de configuration (CMBD) pour les aider à gérer leurs environnements informatiques. 97 % ont toutefois déclaré qu'ils avaient mis en place des pratiques de gestion des changements pour minimiser les perturbations potentielles</p>""}, {'', ""<p>Malgré quelques pannes notoires récentes, la gestion des incidents semble avoir atteint un niveau de maturité avancé, mais en l'absence d'intégrations plus étroites entre les équipes DevOps et ITSM, il existe encore beaucoup de marge de progression.</p>""}]"
LambdaTest Kane propose une solution complète de tests d'IA,"[{'', ""<p>LambdaTest, une société de plateforme de test basée sur le cloud, a lancé KaneAI, un agent de test logiciel d'IA de bout en bout. Les logiciels d'IA ayant un besoin (certains diraient urgent, ou du moins approfondi) de tests approfondis pour éradiquer les hallucinations, identifier les biais et garantir la mise en place de systèmes de ratification plus larges, y compris la génération augmentée de récupération, il y a beaucoup à tester.</p>""}, {'', ""<p>Trop utilisé par les fournisseurs de technologies dans les domaines de la mise en réseau, de l'observabilité des systèmes et des outils de cycle de vie du développement, le terme « de bout en bout » dans ce contexte est l'engagement de l'entreprise à offrir des outils qui fonctionnent de la phase de création jusqu'au débogage et à la gestion continue, le tout en langage naturel afin que les équipes créent et exécutent des tests automatisés.</p>""}, {'', ""<h3>Qu'est-ce que les tests de bout en bout ?</h3>""}, {'', ""<p>Fonction très appréciée des équipes d'ingénierie de la qualité logicielle (du moins celles qui sont efficaces), les tests de bout en bout se décomposent très précisément en cinq étapes principales dans le monde LambdaTest, voire dans d'autres.</p>""}, {'', ""<blockquote>La phase 1 est la planification, où les tests sont ajoutés à la fonction de gestionnaire de tests. La phase 2 est la création, KaneAI travaille à générer des scénarios de test en langage naturel. La phase 3 est l'exécution et la planification afin que les tests puissent être exécutés sur différentes instances de cloud, c'est-à-dire un cloud de test de navigateur, un cloud de test de régression visuelle, un cloud d'appareil réel (LambdaTest fonctionne pour tester des sites Web et des applications sur plus de 5000 appareils Android et iOS réels) et un HyperExecute Cloud (l'outil d'orchestration de tests de l'entreprise qui regroupe et distribue automatiquement les tests de manière intelligente dans différents environnements de test et prend en compte les exécutions passées). La phase 4 est le débogage, où les développeurs peuvent déboguer les tests à l'aide de commandes en langage naturel. La phase 5 est le reporting, où les membres de l'équipe peuvent analyser les rapports de test.</blockquote>""}, {'', '<p>La phase 1 est celle de la planification, où les tests sont ajoutés à la fonction de gestionnaire de tests.</p>'}, {'', '<p>La phase #2 est la création, KaneAI travaille à générer des scénarios de test en langage naturel.</p>'}, {'', '<p>La phase 3 est l’exécution et la planification afin que les tests puissent être exécutés sur différentes instances de cloud, c’est-à-dire un cloud de test de navigateur, un cloud de test de régression visuelle, un cloud d’appareil réel (LambdaTest fonctionne pour tester des sites Web et des applications sur plus de 5 000 appareils Android et iOS réels) et un cloud HyperExecute (l’outil d’orchestration de tests de l’entreprise qui regroupe et distribue automatiquement les tests de manière intelligente dans différents environnements de test et prend en compte les exécutions passées).</p>'}, {'', ""<p>La phase 4 est le débogage, où les développeurs peuvent déboguer les tests à l'aide de commandes en langage naturel.</p>""}, {'', ""<p>La phase 5 est celle du reporting, au cours de laquelle les membres de l'équipe peuvent analyser les rapports de test.</p>""}, {'', '<p>LambdaTest affirme que KaneAI est le premier studio de test génératif basé sur l’IA du secteur des tests logiciels. Étant donné que les tests utilisent le langage naturel, ils offrent également la possibilité à différents personnels (souvent moins techniques) de participer au processus de création des cas de test, puis d’intégrer les tests dans les flux de travail DevOps.</p>'}, {'', '<h3>Renforcer la fragilité</h3>'}, {'', '<p>« Les tests automatisés sont depuis longtemps un élément essentiel du développement logiciel, mais ils s’accompagnent souvent de défis importants. L’automatisation des tests est souvent en retard par rapport aux sprints de développement, les tests fragiles nécessitant une maintenance constante. Même les solutions low-code/no-code ont une courbe d’apprentissage et commencent souvent à s’effondrer à grande échelle, ce qui rend difficile la configuration de l’automatisation des tests pour suivre le rythme de l’évolution des besoins en matière de tests », a déclaré Asad Khan, cofondateur et PDG de LambdaTest.</p>'}, {'', ""<p>Associé à des fonctionnalités intégrées telles que la planification intelligente des tests, la réparation des tests basée sur l'IA et les assertions conditionnelles avancées, KaneAI prend en charge les flux de travail complexes et garantit une couverture complète des tests.</p>""}, {'', ""<p>Alors que l'équipe LambdaTest affirme que les solutions low-code/no-code peuvent atteindre des limites d'évolutivité, KaneAI fournit des fonctionnalités d'édition de tests bidirectionnelles, qui permettent aux utilisateurs de créer soit en code, soit en langage naturel. En outre, il permet l'exportation de code multilingue sur tous les principaux frameworks ainsi que des fonctionnalités uniques de traduction d'instructions en code et de code en instruction. Cela permet une maintenance sans effort des tests à grande échelle et garantit que même les besoins de test les plus complexes sont satisfaits.</p>""}, {'', '<h3>Le cheval des merveilles du flux de travail ?</h3>'}, {'', '<p>Le PDG Khan estime que la boîte à outils de son entreprise est une heureuse révolution pour le processus de débogage grâce à ses capacités d’observation des tests alimentées par l’IA et d’analyse des causes profondes en temps réel. Cela aide les équipes d’ingénierie distribuées à grande échelle à minimiser les temps d’arrêt des applications et à accélérer les cycles de publication, sans compromettre la qualité des produits logiciels.</p>'}, {'', '<p>Que KaneAI soit ou non aussi « révolutionnaire » que le prétend LambdaTest, il s’agit d’un produit conçu avec précision et doté d’un vaste ensemble de fonctions, on pourrait presque dire de fonctionnalités de bout en bout. KaneAI s’intègre parfaitement aux flux de travail existants, prenant en charge des outils populaires tels que Jira, Slack, GitHub Actions et Microsoft Teams.</p>'}]"
Ne bougez pas à gauche sans plateforme,"[{'', ""<p>Le terme shifting left (décalage vers la gauche) est un terme créé par Larry Smith en 2001. Il fait référence au cycle de vie de l'ingénierie logicielle. À l'époque, il était normal de tout construire, puis de tout tester et enfin de tout publier. Larry Smith a fait valoir qu'il était préférable d'effectuer les tests à un stade antérieur du pipeline du projet, d'où le terme shifting left (décalage vers la gauche).</p>""}, {'', ""<p>À partir de là, les choses ont commencé à devenir intéressantes. En 2007, le mouvement DevOps a pris forme. Une conséquence évidente de DevOps a été de faire avancer le déploiement plus tôt dans le pipeline du projet, en d'autres termes, de le déplacer vers la gauche. Vers 2015, la sécurité est entrée dans la mêlée, ce qui a donné naissance à DevSecOps.</p>""}, {'', ""<p>La tendance est claire. De plus en plus d'objets ont été retirés des mains des spécialistes, transformés en facilitateurs (nous y reviendrons plus loin), pour être confiés à des ingénieurs, qui ont dû rapidement devenir des généralistes.</p>""}, {'', '<h3>Alors, pourquoi est-ce un problème ?</h3>'}, {'', '<p>Commençons par une approche traditionnelle de l’ingénierie logicielle. Les développeurs construisent l’itération dans son intégralité. Les testeurs la testent et trouvent des bugs. Il y a beaucoup d’allers-retours. Ensuite, l’équipe de sécurité analyse et l’équipe de bases de données crée des requêtes et stocke les procédures avant que l’équipe d’exploitation ne les mette en production. Cela présente l’inconvénient majeur de nécessiter une ingénierie par lots.</p>'}, {'', ""<p>Des lots plus petits sont synonymes d'un meilleur flux, et un meilleur flux est synonyme d'une livraison logicielle plus prévisible. Par conséquent, nous devons diviser notre travail en incréments beaucoup plus petits. Cependant, maintenant, au lieu de traiter une seule demande importante, l'équipe de test est inondée de dizaines de demandes provenant de chaque équipe d'application qui construit un composant différent du système. Cela va rapidement devenir un goulot d'étranglement.</p>""}, {'', ""<h3>Le problème du goulot d'étranglement des spécialistes</h3>""}, {'', ""<p>Lorsqu'une seule personne sait comment réaliser une tâche, à mesure que l'entreprise évolue, cette personne devient la principale contrainte à la productivité. On les appelle des points de défaillance uniques (SPOF). Ils doivent être présents à chaque révision, à chaque version et constituent un élément clé de toute session de conception.</p>""}, {'', '<p>Les spécialistes sont essentiels pour une organisation, mais leur incapacité à évoluer constitue un énorme problème, ce qui pousse les organisations à se concentrer sur des généralistes en raison du potentiel d’économies (une personne peut faire cinq choses) et de la promesse de flexibilité, donc de l’absence de contraintes strictes. Ce n’est pas une mauvaise stratégie, à condition que vous n’ayez pas besoin de spécialistes. Mais comme le dit le dicton, on ne sait pas qu’on a besoin d’un plombier jusqu’à ce que sa maison soit inondée.</p>'}, {'', '<h3>Du spécialiste au facilitateur</h3>'}, {'', '<p>Team Topologies décrit quatre types d’équipes différentes, dont l’une est l’équipe d’activation. Cette équipe élimine les obstacles et permet aux équipes de se lancer. La manière dont elles s’y prennent peut être décomposée en plusieurs options : facilitation, collaboration ou « X en tant que service ». Nous pouvons y voir l’état d’esprit fertile d’une plateforme.</p>'}, {'', '<p>Sans plateforme, nous sommes un groupe d’individus possédant des connaissances spécialisées, cherchant tous à collaborer et, par conséquent, contraints au rythme de notre lien le plus lent. Avec une plateforme, nous élaborons chacun des solutions pour multiplier notre présence dans l’organisation. Notre objectif est d’amplifier l’impact de nos connaissances. À quoi cela ressemble-t-il ?</p>'}, {'', '<h3>Des opérations à la SRE</h3>'}, {'', ""<p>Plutôt qu'une équipe opérationnelle qui connaît les particularités du déploiement et gère tout personnellement, une équipe SRE élabore des solutions qui permettent aux équipes de déployer en toute sécurité. Ils mettent en œuvre des garde-fous, déploient des stratégies de test, créent des mécanismes d'auto-réparation et bien plus encore. Toutes ces choses font qu'elles font partie de toutes les équipes à la fois.</p>""}, {'', ""<h3>De l'InfoSec à la SecOps</h3>""}, {'', '<p>Au lieu d’une armée d’employés armés de presse-papiers et dont le travail consiste à surveiller les activités des équipes, il serait plus efficace d’avoir un groupe de personnes soucieuses de la conformité et de l’ingénierie, qui recherchent constamment les vulnérabilités, conseillent les équipes, créent des fonctionnalités et contribuent à la plateforme partagée. Cela, encore une fois, augmente considérablement la portée de l’équipe et réduit le nombre de réunions nécessaires pour mettre un produit en production.</p>'}, {'', '<h3>Un exemple classique</h3>'}, {'', '<p>Imaginons une organisation qui gère Kubernetes. Elle regroupe des professionnels de la sécurité, des professionnels des opérations, des ingénieurs, etc. Plutôt que de travailler en vase clos, en exigeant des réunions les uns avec les autres pour garantir la conformité avec un cadre, ils collaborent à la création d’un pipeline. Ce pipeline garantit plusieurs choses :</p>'}, {'', '<li>Tout le code a une couverture de test minimale (généralement 80\xa0%)</li>'}, {'', '<li>Toutes les dépendances sont exemptes de CVE connus</li>'}, {'', '<li>Le code lui-même ne présente aucune vulnérabilité connue, comme une attaque par injection SQL</li>'}, {'', ""<li>Le fichier conteneur ne contient aucun CVE ou il s'agit d'une image provenant d'un fichier pré-numérisé</li>""}, {'', ""<p>Ensuite, l'application est déployée à l'aide d'un organigramme partagé, qui comporte un autre ensemble de responsabilités\xa0:</p>""}, {'', '<li>Les politiques réseau garantissent que seuls les ports nécessaires sont ouverts</li>'}, {'', ""<li>Les souillures, les cordons, les affinités et les sélecteurs de nœuds sont définis pour garantir que cette charge de travail s'exécute sur le bon serveur</li>""}, {'', ""<li>L'application dispose d'un contrôle de santé qui est utilisé pour les contrôles de vivacité</li>""}, {'', ""<li>L'application dispose d'un HorizontalPodAutoscaler pour garantir qu'elle peut évoluer pour répondre aux besoins</li>""}, {'', '<p>Plutôt que de tenir des réunions interminables pour garantir la conformité de chaque version, chaque équipe de parties prenantes doit renforcer la confiance dans le diagramme de gestion. Cette confiance se traduit par une confiance, et cette confiance ouvre un tout nouveau niveau de collaboration.</p>'}, {'', '<h3>Le déplacement vers la gauche nécessite une multiplication des forces</h3>'}, {'', '<p>Si vous souhaitez déplacer vos processus vers la gauche, réduire la taille des lots et améliorer le flux, le défi que vous devez relever est le suivant : comment conserver la rigueur des spécialistes lorsque les choses sont gérées par des généralistes ? La réponse est une plateforme.</p>'}, {'', ""<p>La réflexion sur les plateformes transforme un millier de réunions en quelques centaines de lignes de code, et si vous souhaitez vous déplacer vers la gauche sans sacrifier la perspicacité et la sagesse de vos spécialistes, c'est le seul moyen de garantir que chaque équipe bénéficie de leurs connaissances sans contraintes excessives sur sa capacité à fournir des logiciels.</p>""}]"
DevOps et réussite de la phase de test,"[{'', ""<p>Dans le cadre de DevOps, la capacité à publier des logiciels rapidement, parfois plusieurs fois par jour, est impérative. Les développeurs doivent être prêts à effectuer et à terminer les tests en quelques minutes, afin de déterminer si le logiciel est prêt à passer à la phase suivante ou si les équipes doivent abandonner le projet. La détection et la résolution des bugs avant qu'une version n'entre en production sont essentielles au cycle de vie du développement logiciel (SDLC) — tout comme l'intégration d'une phase de test dans vos processus.</p>""}, {'', '<p>Pour cela, des outils de test automatisés sont nécessaires, bien que leur type varie en fonction de l’application en cours de création. Par exemple, des outils comme Newman sont parfaits pour tester les méthodes publiques d’API. JUnit ou Jest sont les meilleurs pour les tests unitaires de code et de composants. Playwright ou Cypress sont idéaux pour les implémentations de tests E2E (de bout en bout) complètes. Vous pouvez également utiliser des outils de gestion des tests comme TestRail, qui peuvent fournir des rapports qui tiendront les parties prenantes informées de la progression et de la maturité d’une application.</p>'}, {'', '<p>Quel que soit l’outil utilisé, l’entreprise doit se concentrer sur la qualité. Les tests ne sont plus la seule responsabilité de l’assurance qualité (QA) ; l’ensemble du département d’ingénierie doit être impliqué et responsable. Ce modèle de responsabilité partagée produit les résultats les plus fiables, corrigeant les problèmes avant qu’ils ne s’installent et ne gaspillent les investissements par la suite. Il accélère également les cycles de livraison de logiciels plus continus, les tests automatisés réduisant le risque que les humains ne parviennent pas à détecter et à résoudre les problèmes.</p>'}, {'', '<h3>La pyramide de test</h3>'}, {'', ""<p>Un concept populaire dans le développement de logiciels est la pyramide de tests, un cadre utilisé pour guider les processus. Elle se compose de plusieurs couches de tests qui traitent des aspects de fonctionnalité, de performance et de fiabilité. La liste suivante examine les couches clés, les types de tests les plus utilisés et les avantages qu'ils offrent.</p>""}, {'', '<li>Tests unitaires : ces tests se concentrent sur une seule unité de travail, généralement une méthode ou un composant. Ils sont faciles à réaliser, peu coûteux et offrent une première ligne de défense en matière de qualité du code. Idéalement, ces tests doivent être effectués pendant la phase de construction.</li>'}, {'', ""<li>Tests d'intégration et API : ces tests valident la capacité du logiciel en cours de développement à s'intégrer aux systèmes, sinon il sera inutilisable. Cela relève généralement du domaine des développeurs et de l'assurance qualité, mais peut varier en fonction de la structure de l'entreprise.</li>""}, {'', ""<li>Tests UI E2E : ce sont les tests les plus complets, nécessitant l'intégration complète de vos systèmes, y compris le front-end, le back-end, la base de données et le réseau. Ils sont généralement rédigés par des personnes de l'assurance qualité, qui travaillent en étroite collaboration avec les différents secteurs d'activité et les propriétaires de produits. Ce sont les tests les plus coûteux et nécessitent plus de temps et de maintenance, en particulier à mesure que les besoins de l'entreprise et les scénarios de test évoluent. L'accent doit rester mis sur les tests E2E. S'ils sont surprovisionnés, les équipes peuvent retomber dans les tests API ou unitaires et la pyramide pourrait s'inverser, ce qui augmenterait considérablement les coûts globaux.</li>""}, {'', ""<h3>Attribution d'automatisation</h3>""}, {'', '<p>Il n’est pas facile de tester manuellement des applications. Il est quasiment impossible de garantir que le test est effectué correctement à chaque fois tout en évitant les erreurs humaines, sans parler du temps et des dépenses considérables. C’est pourquoi l’automatisation est désormais utilisée tout au long du processus de test, depuis l’orchestration de l’infrastructure jusqu’au code de test.</p>'}, {'', ""<p>Les développeurs doivent être chargés de rédiger des tests unitaires et des tests d'intégration. Les professionnels de la qualité doivent se charger de la rédaction des tests d'interface utilisateur de bout en bout. Les scénarios de test doivent être créés par les propriétaires de produits. La phase de découverte des tests, généralement effectuée manuellement, serait un prérequis à la phase d'automatisation.</p>""}, {'', '<h3>Mise en œuvre en action</h3>'}, {'', '<p>La phase de test peut être réalisée avec différents outils et services existants. À titre d’exemple, examinons l’une des offres les plus populaires disponibles, Amazon Web Services (AWS).</p>'}, {'', ""<p>Cette entité propose AWS CodePipeline, un service de livraison continue (CD) entièrement géré pour créer des pipelines, orchestrer et intégrer des mises à jour dans votre infrastructure et vos applications. Sans surprise, il fonctionne avec leurs autres services DevOps, notamment AWS CodeDeploy, AWS CodeCommit et AWS CodeBuild. Il fonctionne également bien avec des fournisseurs d'actions tiers comme Jenkins et Github.</p>""}, {'', ""<p>Par conséquent, les fonctionnalités d'AWS CodePipeline incluent des fonctionnalités telles que\xa0:</p>""}, {'', ""<li>Option de détection\xa0: cela démarre un pipeline basé sur l'emplacement source des artefacts, un sous-produit du développement utilisé pour des tâches allant des descriptions de fonctions aux évaluations des risques. AWS recommande d'utiliser les webhooks Github, ainsi que les événements Amazon CloudWatch pour les artefacts stockés.</li>""}, {'', '<li>Désactiver la transition\xa0: une fonctionnalité de transition relie les étapes d’un pipeline et peut être activée par défaut. Si vous ne souhaitez pas passer automatiquement à de nouvelles étapes, cliquez simplement sur le bouton «\xa0Désactiver la transition\xa0» pour interrompre l’exécution en cours du pipeline.</li>'}, {'', ""<li>Ajout d'étapes\xa0: avec AWS CodePipeline, vous pouvez modifier un pipeline pour introduire une nouvelle étape, mettre à jour une étape existante ou supprimer entièrement une étape. Une page de modification vous permet d'ajouter des actions en série ou en parallèle à des activités existantes. Cette fonctionnalité rend un pipeline plus flexible et plus facile à développer.</li>""}, {'', ""<li>Action d'approbation\xa0: l'utilisation de cette fonctionnalité permet de gérer les étapes du pipeline. Par exemple, si vous attendez l'approbation d'une personne pendant le déploiement, cela suspendra le pipeline jusqu'à ce que l'approbation soit accordée.</li>""}, {'', '<h3>Pas de repos pour les tests</h3>'}, {'', '<p>Aucune application ne devrait être mise sur le marché sans une phase de test. Lors du développement de cette dernière, minimisez l’interaction humaine dans les processus, faites appel à l’automatisation et recherchez les outils qui permettront de tout réaliser. N’oubliez pas que l’ensemble de l’écosystème de développement (codeurs, ingénieurs, personnel d’assurance qualité) doit être impliqué et avoir un intérêt dans les tests. Il appartient à chacun de s’assurer que la phase de test est en place, flexible et que les résultats sont à toute épreuve.</p>'}]"
CloudBees acquiert Launchable pour faire progresser les tests à l'aide de l'IA,"[{'', ""<p>CloudBees a annoncé aujourd'hui l'acquisition de Launchable, un fournisseur d'une plateforme d'automatisation des tests, pour permettre aux équipes DevOps d'améliorer à la fois la sécurité des applications et la qualité des logiciels. Les conditions financières de l'acquisition ne sont pas divulguées.</p>""}, {'', ""<p>Launchable utilise largement les algorithmes d'apprentissage automatique et les capacités d'intelligence artificielle générative (IA) pour rationaliser les processus de test, par exemple en fournissant l'accès à un copilote pour garantir que le bon test est exécuté au bon moment. De plus, si la plateforme détermine qu'un composant logiciel va probablement échouer à une partie d'un test, elle alertera les équipes DevOps de ce fait plutôt que de perdre du temps à exécuter une série de tests avant qu'un échec inévitable ne se produise.</p>""}, {'', ""<p>Sacha Labourey, directeur de la stratégie de CloudBees, a déclaré que l'ajout de la plateforme Launchable offre aux organisations des capacités de test augmentées par l'intelligence artificielle (IA) qui peuvent être facilement ajoutées aux flux de travail DevSecOps existants.</p>""}, {''}, {'', '<p>En général, les tests d’applications restent l’un des goulots d’étranglement coûteux de tout cycle de vie de développement logiciel (SDLC). Les outils d’IA devraient réduire considérablement le temps consacré aux tests inutiles et aux flux de travail inefficaces, car les équipes DevOps sauront quels tests sont les plus importants.</p>'}, {'', '<p>En outre, ils pourront lancer automatiquement des tests dès qu’une modification est apportée au code dans le cadre d’un flux de travail DevOps plus vaste, afin de garantir que les tests ne soient pas ignorés simplement parce qu’ils risquent de prendre trop de temps à exécuter. Lorsqu’un test échoue, ces mêmes outils d’IA permettent de faire apparaître plus facilement la cause profonde du problème de manière à ce qu’il soit plus simple à résoudre pour les développeurs.</p>'}, {'', ""<p>Launchable rapporte que les clients existants tels que BMW et GoCardless ont constaté une réduction de 50 % des heures machine, une réduction de 90 % des temps d'exécution des tests et une réduction de 40 % des temps de construction en s'appuyant sur l'IA pour automatiser les flux de travail de test.</p>""}, {'', '<p>L’IA accélère déjà le rythme auquel le code est écrit. Le défi consiste désormais à appliquer l’IA pour accélérer le rythme auquel des volumes croissants de code peuvent circuler dans les pipelines DevSecOps. L’objectif global est d’améliorer la productivité des développeurs en réduisant le travail qui, au fil du temps, augmente l’épuisement professionnel des développeurs et des ingénieurs logiciels qui les soutiennent, a déclaré Labourey.</p>'}, {'', '<p>Il faudra peut-être un certain temps avant que l’IA ne soit utilisée de manière généralisée dans tous les flux de travail DevOps, mais les organisations qui sont à l’avant-garde de l’adoption constatent des gains de productivité. Il est peu probable que l’IA remplace le besoin d’équipes DevOps. Après tout, le code et les suggestions générés par ces outils doivent toujours être examinés par des professionnels DevOps pour éviter que des hallucinations occasionnelles ne soient incorporées dans un environnement de production.</p>'}, {'', '<p>Cependant, une chose est sûre : grâce à l’essor de l’IA, le rythme auquel les applications sont développées et déployées est sur le point d’augmenter de manière exponentielle sans nécessairement avoir à augmenter considérablement la taille des équipes DevOps. Le problème est que si toutes ces applications ne sont pas correctement testées, ce rythme de déploiement accéléré pourrait tout aussi bien finir par être une bonne chose.</p>'}]"
PDG de CrowdStrike : 97 % des systèmes Windows sont à nouveau en ligne après une panne,"[{'', ""<p>Selon le directeur général de l'entreprise de cybersécurité, plus de 97 % des postes de travail Windows qui ont été soudainement perturbés il y a une semaine par une mise à jour logicielle problématique de CrowdStrike sont de nouveau en ligne, mais les conséquences de la panne mondiale continueront de se faire sentir.</p>""}, {'', '<p>Dans un message sur LinkedIn, le PDG de CrowdStrike, George Kurtz, a écrit que les efforts de récupération du fournisseur ont été aidés par « le développement de techniques de récupération automatique et par la mobilisation de toutes nos ressources pour soutenir nos clients ».</p>'}, {'', '<p>Microsoft estime qu’au total, 8,5 millions de PC et autres appareils Windows – soit moins de 1 % de toutes les machines Windows – ont été mis hors service et ont affiché l’écran bleu de la mort (BSOD) après l’envoi de la mise à jour défectueuse aux capteurs Falcon de CrowdStrike. Les appareils Linux et Mac n’ont pas été affectés par la mise à jour.</p>'}, {'', '<p>Aux quelques utilisateurs qui tentent encore de se reconnecter, Kurtz a écrit que l’entreprise « ne se reposera pas tant que nous n’aurons pas complètement récupéré. Chez CrowdStrike, notre mission est de gagner votre confiance en protégeant vos opérations. Je suis profondément désolé pour la perturbation que cette panne a causée et je présente mes excuses personnelles à toutes les personnes touchées ».</p>'}, {'', ""<p>Dans un rapport préliminaire post-incident (PIR) du 24 juillet, Kurtz a écrit que son outil Content Validator, qui est un élément clé d'un processus de test de mise à jour en plusieurs étapes, a validé une instance de modèle qui avait un contenu problématique qui a déclenché la panne de Windows pour être déployée en production. Le validateur de contenu aurait dû détecter le problème, a-t-il écrit.</p>""}, {'', '<p>CrowdStrike a publié un correctif et le fournisseur et Microsoft ont travaillé pour remettre les systèmes en marche, mais certains appareils ont mis plus de temps à revenir en ligne.</p>'}, {'', '<h3>Un problème persistant</h3>'}, {'', '<p>Les perturbations se poursuivent de plusieurs manières. Parmi les secteurs les plus touchés figurent les services financiers, les soins de santé, les services d’urgence et les compagnies aériennes. La plupart des compagnies aériennes ont pu se rétablir en quelques jours, mais Delta est celle qui a mis le plus de temps à revenir à la normale. Le 22 juillet, quatre jours après le crash, Delta a annulé 1 160 vols, selon USA Today, et ce nombre a régulièrement diminué, tombant à 47 le 25 juillet.</p>'}, {'', '<p>Cependant, Delta – la plus grande compagnie aérienne du monde – devra désormais faire face à une enquête du ministère américain des Transports. Le secrétaire aux Transports Pete Buttigieg a déclaré dans un message sur X (anciennement Twitter) qu’il voulait « s’assurer que la compagnie aérienne respecte la loi et prenne soin de ses passagers pendant les perturbations généralisées qui se poursuivent. Tous les passagers des compagnies aériennes ont le droit d’être traités équitablement, et je veillerai à ce que ce droit soit respecté. »</p>'}, {'', ""<p>Delta a déclaré dans un communiqué qu'elle essayait de répondre aux besoins des passagers dont les vols ont été annulés ou retardés, notamment en payant les frais engagés par les clients qui ont payé pour d'autres moyens de transport. Elle a également déclaré que la compagnie aérienne continuerait à offrir des bons de repas, des transports terrestres et des chambres d'hôtel aux passagers « dont le voyage a été perturbé par des vols annulés ou considérablement retardés ».</p>""}, {'<h3>De lourdes pertes, mais peu d’aide de la part des assurances</h3>', ''}, {'', '<p>Les clients touchés par la situation devront également s’orienter vers l’assurance cyber. Parametrix, dont l’activité comprend les services d’assurance cloud, a déclaré dans un rapport que les entreprises américaines du Fortune 500 – dont environ un quart ont été touchées – subiront des pertes pouvant atteindre 5,4 milliards de dollars. Cela dit, les polices d’assurance cyber ne couvriront probablement que 10 à 20 % de ce coût « en raison des importantes rétentions de risque de nombreuses entreprises et des limites de police faibles par rapport aux pertes potentielles dues aux pannes », a écrit Parametrix.</p>'}, {'', '<p>La panne « nous en dit plus sur les moyens par lesquels les assureurs et les réassureurs peuvent diversifier leurs portefeuilles de cyber-risques afin de minimiser les impacts potentiels du cyber-risque systémique », a déclaré Jonatan Hatzor, cofondateur et PDG de Parametrix. « Cependant, notre analyse ne montre pas l’ensemble de la situation en matière de diversification. Un assureur cyber axé sur les très grandes entreprises subira certainement une perte CrowdStrike bien plus importante par rapport aux primes qu’un assureur ayant un portefeuille important de PME. »</p>'}, {'', '<p>Les maux de tête ne sont pas réservés aux utilisateurs. Le Congrès souhaite que Kurtz, de CrowdStrike, témoigne lors d’une audience, affirmant dans une lettre que « les Américains méritent de savoir en détail comment cet incident s’est produit et les mesures d’atténuation prises par CrowdStrike ».</p>'}, {'', '<h3>Les cartes-cadeaux de 10 $ ne servent à rien</h3>'}, {'', ""<p>Un autre casse-tête a été la carte-cadeau Uber Eats de 10 $ envoyée aux membres du personnel et aux partenaires qui ont aidé à résoudre le problème et à remettre en marche les systèmes concernés. CrowdStrike leur aurait dit dans un e-mail que l'entreprise comprenait que la panne avait entraîné un surcroît de travail et des maux de tête. Certains n'ont pas été impressionnés.</p>""}, {'', '<p>Sur Reddit, une personne a écrit : « Il aurait été préférable de ne rien donner aux gens, mais maintenant Crowdstrike suggère que les heures que les gens ont investies pour corriger leur erreur ne valent que 10 $ ? »</p>'}, {'', ""<p>« Est-ce que c'est pour vous dire que nous vous avons fait enregistrer plus de 40 heures de réparations d'urgence, alors voilà, vous avez moins d'un demi-déjeuner à notre charge ? Sérieusement, c'est insultant », a écrit un autre.</p>""}, {'', '<p>Une personne a écrit : « Je prendrai tout ce que je pourrai obtenir, je suppose. Puis-je avoir un chapeau aussi ? Je veux le porter avec mon t-shirt Solarwinds. Je me drape dans mes horreurs. »</p>'}, {""<h3>De plus en plus d'escrocs se lancent dans la mêlée</h3>"", ''}, {'', ""<p>Le chaos créé par le crash a donné aux cybercriminels l'occasion de lancer des opérations de phishing et une myriade d'autres escroqueries dans l'espoir de voler de l'argent ou des informations aux victimes en se faisant passer pour du personnel de support technique de CrowdStrike ou d'autres sociétés ou en promettant des solutions au problème.</p>""}, {'', '<p>Les chercheurs de CrowdStrike ont identifié une campagne dans laquelle un acteur malveillant utilise un domaine de phishing comprenant le nom de l’entreprise et Office 365 pour se faire passer pour CrowdStrike et diffuser des fichiers ZIP et RAR malveillants contenant un chargeur Microsoft Installer. Si la cible ouvre le fichier, le chargeur exécute Lumma Stealer, un malware de vol d’informations, contenant CypherIt, un chargeur fortement obscurci utilisé pour entraver l’analyse statique.</p>'}, {'', ""<p>Lumma Stealer est utilisé pour collecter des données à partir des navigateurs, telles que les identifiants, les cookies et les extensions de navigateur. Les chercheurs ont ajouté que, d'après l'horodatage de la création, l'acteur de la menace a très probablement créé l'échantillon le lendemain de l'identification de la mise à jour du contenu problématique et du déploiement du correctif.</p>""}]"
Cinq leçons apprises à la dure face à l’écran bleu mondial de la mort,"[{'', '<p>En tant que professionnel de la gestion de produits, je suis formé pour comprendre les difficultés des clients, en particulier ceux qui rencontrent des problèmes de temps d’arrêt en raison d’une mauvaise qualité des logiciels. Vendredi dernier, j’ai vécu le problème de première main lorsque je suis arrivé tôt à l’aéroport d’Heathrow, pour découvrir que la panne de Microsoft avait cloué au sol des vols dans le monde entier. Mon vol de Londres n’a été retardé que de quelques heures, mais mon vol de correspondance a été complètement annulé. Comme c’était le dernier vol de la journée vers ma ville natale, j’ai dû trouver une chambre d’hôtel pour la nuit, mais toutes les chambres dans un rayon de 50 kilomètres de l’aéroport étaient complètes. Tout cela est dû à un bug dans un petit fichier pas beaucoup plus gros que cet article, qui a eu un impact sur des millions de personnes à travers le monde.</p>'}, {'', '<p>La plupart des versions de logiciels contiennent des défauts. Je n’ai jamais vu de code de production qui ne présentait aucun problème, en particulier dans les applications d’entreprise. Les découvertes qui sont publiées en production sont généralement des bugs cosmétiques ou mineurs qui affectent une fonctionnalité rarement utilisée. Cependant, des défauts comme celui qui a fait tomber les compagnies aériennes sont une toute autre situation. Il est maintenant temps de réfléchir aux leçons que nous pouvons tirer de cet événement.</p>'}, {'', '<p>Leçon 1 : le décalage vers la droite n’est PAS facultatif. Le décalage vers la droite est le concept que vous devez tester en production, après la sortie. On peut se demander si cela a été fait dans le cas de la panne de la semaine dernière. Même si les tests ont été effectués dans les environnements de pré-version, vous ne pouvez pas être sûr que vos environnements de pré-version sont identiques à ceux de production. Vous devez au moins effectuer des tests de détection en production. Mieux encore, exécutez régulièrement des tests de régression. Même lors de tests en production, tester un seul processus ou composant peut ne pas suffire. Ce qui nous amène à la leçon suivante.</p>'}, {'', ""<p>Deuxième leçon : l'intégration et les tests de bout en bout du système sont indispensables. La plupart des applications d'entreprise actuelles sont construites à partir d'un ensemble complexe de services et de systèmes interconnectés. Chaque service isolé peut fonctionner exactement comme prévu, mais lorsque vous le testez avec tous les autres éléments mobiles, vous pouvez constater que de petits retards ici et là perturbent le processus de bout en bout. Ces problèmes liés au temps sont exacerbés par des volumes inhabituellement élevés, ce qui nous amène à la leçon suivante.</p>""}, {'', ""<p>Troisième leçon : les tests de performance et de charge sont également importants. Les tests de performance et de charge peuvent ne pas sembler importants dans des circonstances normales, mais lors de la reprise après une panne, on assiste généralement à une vague d'utilisateurs essayant de poursuivre le travail retardé. On pourrait considérer cela comme un effet en cascade, mais la situation se présente souvent à la fin du mois et du trimestre pour certaines entreprises.</p>""}, {'', '<p>Dans le cas de l’incident de la semaine dernière, un grand nombre de vols annulés a entraîné une augmentation du volume sur le système de réservation des compagnies aériennes. Un système qui n’a peut-être pas été affecté par le bug réel est affecté par un niveau d’activité inhabituel. Les tests de charge ne sont pas une tâche facile et il n’est peut-être pas nécessaire de les effectuer régulièrement, mais vous ne devez pas attendre qu’une catastrophe se produise pour apprendre qu’un volume supérieur de 20 % à la moyenne rendra un système inutilisable.</p>'}, {'', '<p>Quatrième leçon : vous n’êtes pas obligé de diffuser le logiciel à tout le monde en même temps. Deux concepts auraient permis d’éviter une crise mondiale. Le premier est le « dogfooding », c’est-à-dire le fait de manger sa propre nourriture pour chien. Il s’agit de la pratique consistant à utiliser son propre logiciel avant de le diffuser à d’autres. De cette façon, en cas de problèmes majeurs, vous les détectez rapidement et vous limitez les souffrances au sein de votre propre organisation.</p>'}, {'', ""<p>Le deuxième concept est appelé « versions canari ». Tout comme les mineurs emmenaient autrefois des canaris dans les mines de charbon pour les avertir d'une condition mortelle, vous pouvez également diffuser du code à un petit sous-ensemble d'utilisateurs externes pendant une courte période pour garantir qu'une version fonctionne en dehors de votre organisation. Une fois encore, vous limitez l'impact négatif.</p>""}, {'', '<p>Cinquième leçon : le coût des pannes de système a des répercussions en cascade. Il ne s’agit pas seulement de la perte de productivité pendant le temps d’arrêt, mais aussi de l’effet domino. Par exemple, un temps d’arrêt dans le système de saisie des commandes peut entraîner des problèmes avec le système de gestion des stocks, ce qui peut retarder les expéditions et avoir un impact sur le chiffre d’affaires et les résultats financiers. La perte de revenus et de bénéfices peut amener les actionnaires et les clients à voter avec leurs pieds.</p>'}, {'', ""<p>La perte de productivité est aggravée par la nécessité de faire des heures supplémentaires pour rattraper le retard. Pour les travailleurs horaires, cela représente un coût direct pour l'entreprise. Pour les employés salariés, comme les développeurs et les testeurs, cela signifie un impact négatif sur leur satisfaction au travail et sur le temps passé loin de leur famille. L'augmentation du turnover dans le secteur informatique a également un coût.</p>""}, {'', ""<p>La baisse de la satisfaction client est un autre coût indirect de la mauvaise qualité qui n'est pas toujours directement lié à une panne. Même si vos concurrents ont été touchés par le même incident, vos clients ne le savent peut-être pas. Ils voyageaient avec vous ce jour-là.</p>""}, {'', ""<p>La prochaine fois que vous négocierez un budget pour les outils et les ressources de test, n'oubliez pas qu'il y a non seulement des coûts importants liés aux temps d'arrêt, mais aussi de nombreux coûts indirects. Parfois, je pense que le coût des outils et du personnel de test devrait être classé dans la catégorie des assurances, car c'est le cas. Le fait que les bugs entraînent très rarement des temps d'arrêt signifie que la douleur n'est généralement pas aiguë. Nous vivons avec cela. Nos clients vivent avec cela. Jusqu'au jour où cela vous met à terre.</p>""}, {'', '<p>N’attendez pas que la douleur soit insupportable. Investissez dans des personnes, des processus et des outils pour vous assurer de ne jamais avoir à expliquer pourquoi un bug dans un petit fichier a eu un impact sur le monde entier.</p>'}]"
CrowdStrike : un logiciel de test défectueux a provoqué un crash mondial de Windows,"[{'', '<p>Un bug dans un outil de test a validé de manière incorrecte une mise à jour de contenu du logiciel Falcon de CrowdStrike, provoquant l’envoi d’un « contenu problématique » dans un fichier à des millions d’appareils Windows et déclenchant une panne mondiale des systèmes informatiques dont les ramifications se font encore sentir.</p>'}, {'', ""<p>Dans un rapport préliminaire publié mercredi, la société de cybersécurité a déclaré que son outil Content Validator, qui fait partie d'un processus en plusieurs étapes pour fournir des mises à jour de configuration de contenu au capteur Falcon, contenait deux instances de modèle fournissant du contenu à réponse rapide. L'une des instances contenait le contenu problématique, mais sur la base des résultats des contrôles effectués plus tôt dans le processus, « ces instances ont été déployées en production », a écrit CrowdStrike.</p>""}, {'', ""<p>Le résultat fut que lorsque le capteur reçut le contenu du fichier de canal 291 et le chargea dans l'interpréteur de contenu, cela provoqua une lecture de mémoire hors limites qui déclencha une exception inattendue qui « ne pouvait pas être gérée correctement, entraînant un crash du système d'exploitation Windows » et l'écran bleu de la mort (BSOD).</p>""}, {'', ""<p>Selon Microsoft, 8,5 millions de systèmes Windows dans le monde ont été touchés par la panne, qui a touché de nombreux secteurs comme le tourisme, la santé et les services financiers et a entraîné l'immobilisation d'avions, le report d'opérations chirurgicales et le retard des opérations bancaires. Certaines entreprises sont encore en phase de rétablissement, Delta Airlines continuant d'annuler des vols cinq jours plus tard.</p>""}, {'', '<p>La panne a également fait chuter le cours de l’action de CrowdStrike et a donné aux cybercriminels l’occasion de lancer des escroqueries en exploitant le crash.</p>'}, {'', ""<p>En outre, le Congrès exerce désormais un contrôle strict sur cette affaire : les responsables du Comité de la sécurité intérieure et du Sous-comité de la cybersécurité et de la protection des infrastructures de la Chambre des représentants ont envoyé cette semaine une lettre donnant au PDG de CrowdStrike, George Kurtz, jusqu'à mercredi pour planifier une audience avec le sous-comité.</p>""}, {'', '<p>« Bien que nous apprécions la réponse de CrowdStrike et sa coordination avec les parties prenantes, nous ne pouvons ignorer l’ampleur de cet incident, que certains ont qualifié de la plus grande panne informatique de l’histoire », ont écrit Mark Green (R-TN), président du Comité de la sécurité intérieure, et Andrew Garbarino (R-NY), président du sous-comité. « Sachant que les Américains ressentiront sans aucun doute les conséquences durables et réelles de cet incident, ils méritent de savoir en détail comment cet incident s’est produit et les mesures d’atténuation prises par CrowdStrike. »</p>'}, {'', ""<p>Le rapport PIR de CrowdStrike fournit une analyse détaillée des problèmes survenus le 19 juillet, indiquant que les hôtes Windows exécutant la version 7.11 du capteur de CrowdStrike qui étaient en ligne pendant une période de 90 minutes ce matin-là ont reçu la mise à jour du problème. Les systèmes qui se sont connectés après ou qui n'étaient pas connectés pendant cette période n'ont pas été affectés. De plus, les systèmes Mac et Linux n'ont pas été affectés.</p>""}, {'', ""<p>CrowdStrike envoie des mises à jour de configuration du contenu de sécurité à ses capteurs de deux manières, notamment via le contenu du capteur qui est livré directement avec le capteur. Ce contenu n'est pas mis à jour de manière dynamique à partir du cloud et comprend des types de modèles, qui ont des champs prédéfinis écrits dans le code que les ingénieurs de détection des menaces peuvent utiliser dans le contenu de réponse rapide. Les types de modèles « passent par un processus d'assurance qualité approfondi, qui comprend des tests automatisés, des tests manuels, des étapes de validation et de déploiement », a écrit le fournisseur.</p>""}, {'', ""<p>Le contenu de réponse rapide est utilisé pour répondre rapidement aux changements dans le paysage des menaces et peut être mis à jour de manière dynamique en dehors du capteur Falcon. Le contenu est fourni sous forme d'instances de modèle qui correspondent à des comportements spécifiques que le capteur peut voir, détecter ou empêcher et qui disposent d'un ensemble de champs correspondant au comportement souhaité. Trois systèmes clés sont utilisés pour tester et déployer le contenu de réponse rapide, notamment le système de configuration de contenu, qui crée des instances de modèle et inclut le validateur de contenu.</p>""}, {'', '<p>Les deux autres sont l’interpréteur de contenu sur le capteur, qui permet au moteur de détection du capteur de détecter et de prévenir les activités malveillantes.</p>'}, {'', ""<p>CrowdStrike a indiqué qu'en février, il a introduit un nouveau type de modèle InterProcessCommunication (IPC) pour détecter de nouvelles techniques d'attaque. Le mois suivant, le type de modèle IPC a été soumis à un test de résistance dans un environnement de test comprenant des systèmes d'exploitation et des charges de travail. Après avoir réussi le test de résistance et avoir été validé pour l'utilisation, l'instance de modèle IPC et trois autres ont été déployées en avril et ont fonctionné comme prévu en production.</p>""}, {'', '<p>Deux instances de modèle IPC supplémentaires ont été déployées le 19 juillet – y compris celle avec le contenu problématique – sur la base des tests effectués avant le déploiement initial du type de modèle en mars, des vérifications effectuées dans le validateur de contenu et du fait que les instances de modèle IPC précédentes ont été déployées sans déclencher de problèmes dans les systèmes Windows, a écrit CrowdStrike.</p>'}, {'', ""<p>En réponse, le fournisseur a déclaré qu'il améliorait les tests de contenu de réponse rapide en utilisant des types de tests supplémentaires, notamment des tests de développement local et des tests de mise à jour et de restauration de contenu, en ajoutant davantage de contrôles de validation à Content Validator pour le contenu de réponse rapide et en améliorant la gestion des erreurs existante dans Content Interpreter.</p>""}, {'', ""<p>De nouveaux contrôles ont également été introduits dans le déploiement du contenu de réponse rapide, notamment le déploiement progressif des mises à jour, l'amélioration de la surveillance et l'octroi aux utilisateurs d'un meilleur contrôle sur le moment et le lieu de déploiement des mises à jour.</p>""}]"
4 raisons pour lesquelles les leaders technologiques devraient donner la priorité à la phase de test et de simulation pour un meilleur développement,"[{'', ""<p>L'enquête Stack Overflow Developer Survey 2023 révèle que 60 % des développeurs utilisent des tests automatisés. Mais la vérité est que les tests automatisés et les simulations doivent être le domaine le plus prioritaire de votre SDLC pour éliminer les frictions pour votre équipe de développeurs.</p>""}, {'', '<p>Il ne s’agit pas seulement de disposer des outils nécessaires, mais de cultiver une culture dans laquelle les tests sont considérés comme une partie intégrante du processus de développement, et non comme une considération secondaire. Ce changement de mentalité peut considérablement améliorer la qualité des logiciels, réduire les coûts et améliorer les performances globales de l’entreprise. Voici les quatre raisons pour lesquelles les tests devraient être le domaine le plus prioritaire de votre cycle de développement logiciel.</p>'}, {'', '<h3>1. Les tests garantissent un logiciel de haute qualité</h3>'}, {'', ""<p>En tant qu'ancien développeur devenu PDG, je suis convaincu que la pierre angulaire d'une expérience utilisateur exceptionnelle est de garantir la qualité de nos logiciels. Notre priorité absolue est, et doit toujours être, d'améliorer la satisfaction et la confiance de nos utilisateurs finaux, ce qui signifie que la mise en œuvre d'un cadre de test robuste est cruciale dans notre quête de qualité.</p>""}, {'', ""<p>Ce cadre constitue votre première ligne de défense. Il vous aide à identifier et à corriger les bugs dès le début du processus de développement, minimisant ainsi le risque de problèmes majeurs lors de la mise en service du logiciel. Il s'agit de garantir que vos produits fonctionnent parfaitement et répondent aux attentes des utilisateurs finaux, ce qui est essentiel pour maintenir la fiabilité et augmenter la satisfaction des clients.</p>""}, {'', ""<p>Il existe également un effet de feed-forward, qui consiste à maintenir des normes élevées de qualité du code et de fonctionnalité. Avec les tests intégrés, le code est toujours au plus haut niveau requis, tout code inférieur échoue aux tests et est rejeté. Ainsi, votre base de code devient, par définition, de haut niveau, et tout nouveau développeur de votre équipe peut voir la norme et ce qui est nécessaire pour l'atteindre.</p>""}, {'', '<p>En mettant l’accent sur l’importance de tester, de simuler et de résoudre les problèmes avant qu’ils n’affectent vos utilisateurs, vous protégez votre réputation et améliorez la fidélisation de vos clients. Cette approche proactive réduit considérablement les coûts qui seraient autrement engagés pour résoudre les problèmes après la sortie du produit.</p>'}, {'', '<p>En résumé, en tant que leaders technologiques, notre engagement envers des tests rigoureux est non négociable. Il ne s’agit pas seulement de trouver des bugs ; il s’agit d’instaurer la confiance, de garantir la fiabilité et de favoriser une culture d’excellence qui imprègne tous les niveaux de notre organisation.</p>'}, {'', '<h3>2. Tests automatisés -> Des développeurs plus heureux</h3>'}, {'', '<p>Les tests dans le développement de logiciels peuvent parfois être considérés comme une tâche ardue par les développeurs, principalement parce que les méthodes de test traditionnelles nécessitent une intervention manuelle importante. Les développeurs se retrouvent souvent à écrire ou à mettre à jour de nombreux tests, même pour des modifications mineures du code, et la responsabilité de maintenir ces tests peut être écrasante et générer des frictions.</p>'}, {'', ""<p>Cependant, lorsque les tests sont correctement abordés avec l'automatisation, ils se transforment en un outil puissant qui améliore la productivité des développeurs et crée un environnement de codage sans friction. En donnant la priorité aux tests automatisés, les développeurs ne redoutent plus le processus mais l'adoptent. Cela vous permet d'éliminer les obstacles et de réduire les aspects fastidieux du processus de développement, permettant aux développeurs de se concentrer sur ce qu'ils font le mieux : créer et améliorer des logiciels.</p>""}, {'', '<p>Pour commencer, les tests automatisés inspirent confiance aux développeurs quant aux changements qu’ils mettent en œuvre. La peur d’introduire des bugs dans la production peut amener les développeurs à passer trop de temps à vérifier manuellement leur travail. Les tests automatisés agissent comme un filet de sécurité fiable, offrant aux développeurs la liberté de refactoriser et d’innover sans craindre de perturber les fonctionnalités existantes. Cette confiance permet d’adopter des approches plus créatives et plus audacieuses en matière de développement de produits.</p>'}, {'', ""<p>De plus, l'automatisation des tests améliore considérablement l'efficacité du débogage. Lorsque des problèmes surviennent, les frameworks de tests automatisés permettent d'identifier le problème rapidement et avec précision. Ce processus simplifié réduit non seulement le temps consacré au débogage, mais minimise également les temps d'arrêt, permettant ainsi aux développeurs de se concentrer davantage sur l'amélioration du produit plutôt que sur sa réparation.</p>""}, {'', '<h3>3. De meilleurs tests soutiennent davantage les pratiques Agile et DevOps</h3>'}, {'', ""<p>Le feedback continu est l'élément vital du développement agile. Les tests et simulations automatisés s'intègrent aux pipelines CI/CD pour un feedback rapide pour l'équipe. Cela signifie que les problèmes sont détectés tôt, souvent quelques minutes après la validation du code.</p>""}, {'', '<p>Il ne s’agit pas seulement de trouver des bugs, mais de créer un environnement de développement où la qualité est constamment surveillée et améliorée. Ce développement itératif devient possible grâce à des pratiques de test robustes. Sans tests complets, chaque itération risque d’introduire de nouveaux bugs ou des régressions. Grâce à cela, les équipes peuvent déployer des mises à jour en toute confiance, sachant que les fonctionnalités de base resteront intactes.</p>'}, {'', '<p>Ces pratiques favorisent une culture DevOps dans laquelle le développement et les opérations travaillent main dans la main et où ces départements traditionnellement cloisonnés s’alignent sur ce qui constitue un « logiciel fonctionnel ». En donnant la priorité aux tests et aux simulations automatisés dans vos pratiques agiles et DevOps, vous créez un écosystème dans lequel la qualité est construite dès le départ, les développeurs sont habilités à innover rapidement et votre organisation peut s’adapter rapidement aux besoins changeants de l’entreprise.</p>'}, {'', '<h3>4. Les tests améliorent la collaboration et le partage des connaissances</h3>'}, {'', '<p>Cela peut paraître étrange. Comment l’ajout de tests peut-il aider les développeurs à collaborer et à partager leurs connaissances\xa0?</p>'}, {'', ""<p>C'est facile. Les tests sont de la documentation. Ils constituent le meilleur type de documentation car ils représentent le résultat attendu de toute fonction ou composant. Ils constituent une documentation en direct du comportement du code, aidant ainsi les nouveaux membres de l'équipe à comprendre le système. Les tests fournissent une documentation claire sur la manière dont les différentes parties du système doivent fonctionner, servant de point de référence fiable pour les développeurs.</p>""}, {'', '<p>Cette compréhension commune favorisée par des tests complets peut réduire considérablement les malentendus et les conflits au sein de l’équipe, ce qui conduit à une collaboration plus fluide. Lorsque les développeurs écrivent des tests, ils découvrent également des cas limites ou des problèmes potentiels qui n’auraient peut-être pas été apparents autrement, améliorant ainsi encore les connaissances collectives de l’équipe sur les subtilités du système.</p>'}, {'', ""<p>Les tests contribuent également à créer un environnement de développement cohérent au sein de votre organisation technique. Les simulations créent un environnement prévisible pour le développement et les tests, améliorant ainsi la collaboration en équipe. Cette cohérence permet aux développeurs de travailler en toute confiance sur différentes parties du système, sachant que leurs modifications ne risquent pas de perturber de manière inattendue d'autres composants.</p>""}, {'', ""<p>Lorsque de nouveaux membres de l'équipe rejoignent ou que les développeurs changent de projet, des tests et des simulations complets réduisent considérablement la courbe d'apprentissage, leur permettant de devenir plus productifs et de contribuer efficacement à la base de code.</p>""}, {'', '<h3>Conclusion</h3>'}, {'', '<p>Si je dois vous laisser une chose, c’est qu’il est important de noter que les tests sont nécessaires pour toute architecture logicielle moderne. Les microservices et les applications cloud natives sont si complexes aujourd’hui que les tests sont nécessaires pour garantir que chaque service fonctionne et interagit comme prévu.</p>'}, {'', ""<p>Il est essentiel de donner la priorité aux tests et aux simulations tout au long du cycle de développement (et de les déplacer vers la gauche) : cela transcende les bonnes pratiques pour devenir un impératif concurrentiel. Les leaders technologiques qui prônent une culture de test rigoureuse permettent à leurs organisations de produire des produits de qualité supérieure, de s'adapter rapidement aux changements du marché et de développer des systèmes durables et évolutifs.</p>""}, {'', '<p>La véritable question n’est plus de savoir si vous pouvez vous permettre de donner la priorité aux tests, mais plutôt de savoir si vous pouvez vous permettre de les négliger.</p>'}]"
De l'évolutivité à la vitesse : l'IA générative a donné une impulsion aux tests,"[{'', '<p>En ingénierie de la qualité, l’IA générative (GenAI) est devenue une force transformatrice, bouleversant fondamentalement les paradigmes de test classiques. Traditionnellement, les modèles d’IA utilisaient des données existantes pour la classification et la prédiction et étaient souvent appliqués à la priorisation et à la consolidation des tests. Cependant, l’intégration rapide de l’IA générative au cours des dernières années a déplacé la base vers de nouvelles solutions de test – le prochain niveau dans la course à l’aptitude de l’IA.</p>'}, {'', '<h3>GenAI a modifié les tests pour améliorer activement la qualité</h3>'}, {'', '<p>Par le passé, la qualité des tests était une préoccupation majeure, nécessitant une intégration précoce de l’assurance qualité dans le cycle de vie du développement. Désormais, avec GenAI, l’accent est passé de la simple assurance à l’ingénierie active de la qualité. La principale distinction réside dans l’approche : l’IA classique implique une intervention humaine et des processus manuels, tandis que GenAI automatise et innove en matière de méthodologies de test.</p>'}, {'', '<p>Envisagez de traiter la qualité des exigences dès le début du cycle de vie du développement logiciel. À l’aide de l’IA classique, un analyste métier peut définir des exigences pour couvrir diverses interprétations, ce qui peut entraîner certaines ambiguïtés et des échecs potentiels. Avec GenAI, ce type d’ambiguïté est non seulement rapidement identifié, mais également corrigé.</p>'}, {'', '<p>Prenons l’exemple d’un détaillant qui teste différents types de chaussures. Si vous demandez alors : « Qu’entend le détaillant par « chaussures différentes » ? » Il peut s’agir de différents types de chaussures, comme des baskets, des talons ou des tailles, ou de détails comme le confort, la largeur, etc. En fait, cela peut signifier un certain nombre de choses différentes. Les modèles GenAI peuvent automatiquement comprendre le contexte du client et du secteur, et remédier à l’exigence pour éliminer toute ambiguïté.</p>'}, {'', '<p>Un autre exemple est la consolidation de cas de test similaires. Par le passé, les modèles d’IA traditionnels pouvaient identifier les cas de test en double ou similaires, mais une intervention humaine était nécessaire pour supprimer ou fusionner ces cas de test en double ou similaires. GenAI va encore plus loin en automatisant le processus de consolidation, réduisant ainsi le besoin d’intervention manuelle et garantissant une plus grande efficacité des tests.</p>'}, {'', '<h3>Création automatique de cas de test</h3>'}, {'', ""<p>En repoussant les limites au-delà de la prédiction ou de l'analyse, GenAI s'étend désormais à la création automatique d'artefacts de test tels que des scénarios de test, des cas de test, des fichiers de fonctionnalités et même des scripts d'automatisation. Alors que le monde des développeurs était assez avancé avec des environnements de développement intégrés intelligents (IDE) et des générateurs de code, le monde de l'assurance qualité était encore limité à l'automatisation avec peu d'IA dans les tests.</p>""}, {'', '<p>Avec l’introduction de GenAI en 2023, l’adoption de l’IA dans les tests a connu une croissance exponentielle. GenAI a démocratisé l’IA dans les tests. Si quelqu’un intègre une exigence validée, non ambiguë et de haute qualité dans les modèles GenAI actuels, des scénarios de test ainsi que des cas de test bien définis, des fichiers de fonctionnalités et des scripts Selenium automatisés peuvent être générés d’un simple clic. Cette transformation a considérablement accéléré les processus de test, transformant ce qui prenait auparavant des semaines en une tâche automatisée rapide réalisée en quelques jours.</p>'}, {'', '<h3>Il ne s’agit pas de remplacer les testeurs humains</h3>'}, {'', '<p>Il faut le répéter https://devops.com/smartbear-adds-more-generative-ai-testing-tools-to-platform/ — l’utilisation de GenAI ne vise pas à remplacer la main-d’œuvre humaine, mais à améliorer nos capacités. La pénurie de testeurs d’automatisation expérimentés entraîne une perte de revenus pour l’entreprise. Cependant, avec GenAI, les ingénieurs juniors peuvent désormais exploiter la puissance de l’automatisation activée par l’IA de génération, en effectuant des tâches avec les connaissances intégrées d’un architecte chevronné.</p>'}, {'', '<p>Les prouesses de Gen AI ne sont pas arbitraires ; elle a appris à partir de milliards de points de données. En combinant les connaissances traditionnelles aux capacités de l’IA, de nouvelles solutions apportent évolutivité et rapidité aux tests. Cette transformation n’est pas seulement une amélioration ; c’est une révolution totale qui ouvre de nouvelles possibilités en matière de tests. Au-delà de la génération automatisée de cas de test, GenAI a étendu son impact à la création de données synthétiques, apportant une nouvelle dimension à l’ensemble du processus de test.</p>'}, {'', ""<h3>Il est temps pour les testeurs d'adopter GenAI</h3>""}, {'', '<p>De la résolution des ambiguïtés à l’automatisation de la création de cas de test, GenAI a fait entrer les tests dans une nouvelle ère qui s’accélère. Les économies de temps et d’argent, ainsi que l’efficacité accrue en font une force transformatrice dans le paysage des tests. Bien que les implications futures de GenAI soient vastes et quelque peu inconnues, nous comprenons comment elle a non seulement élevé les tests, mais aussi ouvert des perspectives qui semblaient autrefois impossibles. Le lien entre l’expertise humaine et les capacités de GenAI remodèle le paysage des tests, promettant un avenir dans lequel les tests ne sont pas seulement une question d’assurance, mais aussi de génération de qualité avec rapidité et à grande échelle.</p>'}]"
Une plongée en profondeur dans les tests instables,"[{'', ""<p>Dans le domaine des logiciels, les tests sont indispensables pour garantir la qualité, car ils garantissent que votre application fonctionne comme prévu, quelles que soient les modifications apportées au code source pour se conformer aux exigences changeantes. Cependant, vous avez peut-être rencontré une catégorie spécifique de tests instables ; ces tests sont instables et imprévisibles car ils peuvent réussir ou même être dans des conditions identiques, c'est-à-dire avoir la même configuration sans modification du code, des données ou de l'environnement. Cet article traite des tests instables, des raisons pour lesquelles ils se produisent et de certaines bonnes pratiques pour les éviter.</p>""}, {'', '<h3>Aperçu des tests floconneux</h3>'}, {'', ""<p>Un test instable est défini comme un test qui peut réussir ou échouer indépendamment des modifications apportées au code, aux données ou à l'environnement. Cette incohérence dans les résultats des tests peut freiner le développement en suscitant l'incrédulité et retarder les déploiements en production en raison de la nécessité d'un débogage inutile. Ce phénomène intrigue les développeurs et sape leur confiance dans les tests ; par conséquent, une approche systématique est nécessaire pour traiter ce problème.</p>""}, {'', '<p>Les tests instables sont incohérents, car un test peut échouer à un moment donné, puis réussir à un autre, tout en utilisant un environnement de test et une base de code statiques. De nombreuses raisons expliquent cette incohérence, notamment des problèmes de synchronisation tels que des conditions de concurrence et la dépendance à des systèmes externes qui peuvent se comporter de manière imprévisible, entre autres.</p>'}, {'', '<h3>Impact sur le développement de logiciels</h3>'}, {'', '<p>Les tests irréguliers peuvent avoir un impact considérable sur le flux de travail du cycle de vie du développement logiciel, ce qui entraîne une perte de temps et de ressources lorsque les équipes recherchent des erreurs non déterministes, peu fiables et intrinsèquement difficiles à trouver. Voici les principaux domaines dans lesquels les tests irréguliers peuvent avoir un impact sur un processus SDLC typique\xa0: • Livraison de logiciels retardée • Confiance réduite dans les résultats des tests • Coûts de maintenance accrus • Couverture des tests réduite • Effort de débogage accru • Obstacles au CI/CD</p>'}, {'', '<h3>Causes courantes des tests floconneux</h3>'}, {'', '<p>Pour déterminer une stratégie appropriée pour minimiser l’impact, nous devons d’abord comprendre pourquoi les tests deviennent instables.</p>'}, {'', ""<p>• Problèmes de concurrence : lorsque les tests sont exécutés simultanément, c'est-à-dire lorsque plusieurs tests se disputent des ressources partagées en même temps, des blocages et des conditions de concurrence peuvent se produire et ceux-ci peuvent à leur tour conduire à des résultats instables.• Dépendances externes : lorsque vos tests nécessitent une interaction avec des systèmes externes tels que des API ou des bases de données, cela introduit une instabilité en raison de la latence du réseau ainsi que des temps de réponse différents.• Logique non déterministe : lorsque vos tests reposent sur des éléments aléatoires tels que des dates, des heures ou des entrées utilisateur, c'est-à-dire tout ce qui ne peut pas être prédit avec certitude, ils peuvent avoir des résultats différents.• Environnement instable : lorsque l'environnement dans lequel les tests sont effectués manque d'isolation appropriée, il peut y avoir des différences dans les performances des applications, les configurations et les taux de disponibilité, ce qui peut éventuellement amener un test à fonctionner une fois mais à échouer une autre fois dans des conditions identiques.</p>""}, {'', '<h3>Comment détecter les tests floconneux</h3>'}, {'', ""<p>Il existe plusieurs stratégies que vous pouvez adopter pour détecter les tests instables, comme l'utilisation de différentes méthodes et outils pour trouver des modèles d'incohérence et de manque de fiabilité dans les résultats qu'ils génèrent.</p>""}, {'', ""<p>Analyse des résultats de tests historiquesL'examen des résultats de tests historiques est une approche fiable pour découvrir les tests non fiables. Vous pouvez le faire pour identifier les irrégularités ou les modèles dans vos ensembles de données tout en comprenant les tendances ou les événements courants qui peuvent être utiles pour estimer la probabilité d'un échec de test.</p>""}, {'', ""<p>Vous pouvez également exploiter les outils d'intégration continue dotés de fonctionnalités intégrées de détection des tests irréguliers pour identifier les tests qui ont un comportement incohérent. En utilisant de tels outils, vous pouvez détecter les tests irréguliers à un stade précoce du processus SDLC, ce qui vous permet d'économiser du temps et des efforts dans l'identification manuelle des tests irréguliers.</p>""}, {'', ""<p>Exécuter les tests plusieurs foisVous pouvez exécuter vos tests plusieurs fois à l'aide de frameworks de test ou dans le cadre d'un pipeline CI/CD pour déterminer la variabilité des résultats des tests. Si rien n'a été modifié dans le code ou l'environnement, mais que les résultats des tests indiquent des anomalies et des incohérences, cela constitue un bon indicateur de défaillance.</p>""}, {'', ""<p>Surveillance et documentationUne autre stratégie consiste à garder un œil sur l'historique d'exécution des tests pour déterminer les éventuelles anomalies dans les résultats des tests au fil du temps. En enregistrant des indicateurs tels que les taux d'échec, vous pouvez comprendre dans quelle mesure les tests sont cohérents, stables et fiables.</p>""}, {'', '<h3>Comment corriger les tests irréguliers</h3>'}, {'', '<p>Voici les principales stratégies que vous pourriez adopter pour corriger les tests instables.</p>'}, {'', ""<p>Isoler le testTout d'abord, vous devez identifier et mettre en quarantaine le test instable. Ensuite, répliquez-le pour déterminer la cause première, c'est-à-dire pourquoi un test devient instable. N'oubliez pas de réinitialiser ou de nettoyer l'état avant et après chaque test.</p>""}, {'', '<p>Évitez d’utiliser des données aléatoires. Étant donné que les données aléatoires peuvent entraîner un comportement imprévisible, vous devez vous assurer que votre test ne dépend pas de données aléatoires ou inattendues. Il serait utile d’utiliser des valeurs fixes ou prédéfinies pour la saisie utilisateur et des algorithmes ou méthodes déterministes pour générer ou traiter les données. Si vous avez besoin de données aléatoires, assurez-vous de les enregistrer de manière appropriée pour permettre une réexécution des tests.</p>'}, {'', ""<p>Rendez vos tests robustesVos tests doivent être équipés de tentatives, de délais d'attente ou d'attentes pour gérer les problèmes de réseau ou de performances. Ils doivent également pouvoir être exécutés dans des environnements et des conditions variés. Créez des assertions destinées à vérifier un résultat ou un comportement attendu en vérifiant les plages, les modèles et d'autres parties pertinentes correctement conçues à cet effet.</p>""}, {'', ""<p>Éliminer les dépendances externesVous pouvez utiliser des simulations, des stubs ou des faux tests pour reproduire le comportement d'un système externe sans utiliser de dépendances réelles. Vous devez vous assurer que vos tests ne dépendent pas de facteurs externes et n'affectent pas d'autres tests.</p>""}, {'', '<p>Comment maintenir une suite de tests exempte de tests instablesPour créer une suite de tests exempte de tests instables, vous devez être proactif et suivre certaines pratiques recommandées.</p>'}, {'', ""<p>Supprimer les tests en doubleBien qu'il soit essentiel de réviser les tests, il est tout aussi important de se débarrasser des tests répétitifs, car ils ralentissent le processus de test. La maintenance régulière des tests garantit l'exactitude et la fiabilité, rendant ainsi les résultats des tests plus précis et exploitables.</p>""}, {'', ""<p>Surveillance continueMettez en place un système de surveillance qui surveille en permanence l'exécution et les résultats des tests afin d'identifier rapidement les écarts et de les éliminer du processus de test. Vous devez également fournir à votre équipe les outils nécessaires (outils de surveillance, systèmes de reporting et matériel nécessaire) pour exécuter les tests.</p>""}, {'', ""<p>Donnez la priorité aux tests instables. Donnez-leur la priorité en fonction du niveau de risque commercial, de l'effort nécessaire pour les corriger et du calendrier des tests. Il est beaucoup plus intéressant de se concentrer sur les tests qui valident les flux de travail critiques de l'entreprise. Les tests rarement utilisés dans un flux de travail d'entreprise doivent être de faible priorité et ignorés. De plus, certains tests instables nécessitent beaucoup de temps et d'efforts pour être corrigés, ce qui doit être supprimé lors de la maintenance des tests.</p>""}, {'', ""<p>Analyse des indicateurs de testVous devez conserver des enregistrements des problèmes courants pour aider vos pairs à tirer des leçons des problèmes et des solutions passés. Pour obtenir des informations, identifier les tendances et les modèles et prendre les bonnes décisions. Il serait utile que vous collectiez des indicateurs pertinents tels que les temps d'exécution des tests, les taux d'échec et les modèles de défaillance. Il serait également utile que vous dispensiez une formation sur la rédaction de tests fiables et robustes, sur ce que sont les tests instables et sur la façon de les gérer.</p>""}, {'', '<h3>Conclusion</h3>'}, {'', ""<p>Bien qu'il soit difficile d'éradiquer les tests instables, vous pouvez toujours en retracer l'origine et les gérer rapidement. La gestion des tests instables est une approche itérative continue qui vous permet d'identifier, de comprendre et de corriger les tests intermittents ou imprévisibles. Vous pouvez atténuer les défis posés par les tests instables en adoptant les stratégies et les meilleures pratiques décrites dans cet article.</p>""}]"
Agents de test : plus qu'un copilote,"[{'', ""<p>On a beaucoup parlé de l'adoption de copilotes de codage pour les développeurs. Ce que l'on sait moins, c'est que les copilotes peuvent également écrire des scripts de test et traduire des tests d'un langage de script à un autre. Les copilotes augmentent la productivité pour les deux cas d'utilisation, mais ce sont généralement des outils passifs qui doivent être alimentés avec des exigences précises pour obtenir les résultats souhaités.</p>""}, {'', '<p>Un nouveau niveau d’assistant émerge, qui amène cette capacité à un état plus actif, car la technologie de l’IA est intégrée directement dans les outils de développement et de test.</p>'}, {'', '<p>Un responsable de l’assurance qualité d’une entreprise technologique de premier plan a parfaitement résumé la situation : « La capacité de l’IA à non seulement exécuter des tests, mais aussi à en tirer des enseignements et à s’adapter, transforme notre approche de l’assurance qualité. C’est comme avoir un membre de l’équipe en constante évolution qui garantit la robustesse et la fiabilité de nos versions. »</p>'}, {'', ""<p>Ces agents de test commencent à apparaître dans la nature et sont voués à évoluer rapidement au cours des prochains mois et des prochaines années. Ils répondront à certains des principaux défis auxquels les entreprises sont confrontées dans le développement d'applications métier.</p>""}, {'', ""<h3>Élaboration d'un plan de test</h3>""}, {'', '<p>Le premier défi est que les personnes qui comprennent ce que l’application est censée faire ne sont généralement pas compétentes en matière de développement de tests. Les nouveaux agents de test relèveront ce défi en travaillant avec des experts en la matière (SME) pour élaborer un plan de test basé sur l’exploration des nouvelles fonctionnalités par ces derniers.</p>'}, {'', '<p>Le deuxième défi est le fait que les tests ne sont pas réalisés une seule fois. La première version d’un test ne durera pas longtemps avant de devoir être mise à jour. Pour paraphraser von Moltke l’Ancien, « les plans de tests fonctionnels ne survivront pas au premier contact avec une mise à niveau de la plateforme », en particulier pour les SaaS d’entreprise. Pour les équipes de développement de tests traditionnelles, cela signifie qu’il y a un retard constant dans les retouches. Mais les agents de test peuvent régénérer une nouvelle version du test aussi facilement qu’ils ont écrit la première. Le troisième défi consiste à exécuter les bons tests au bon moment. Les meilleures entreprises créent des suites de régression qui peuvent tester la plupart des fonctionnalités importantes de leurs applications métier avant de les publier.</p>'}, {'', '<p>Tout va bien jusqu’à ce que vous réalisiez que 90 % de ces tests ne peuvent pas échouer compte tenu de l’ampleur des modifications apportées. Cette surdose coûte du temps et de l’argent. Ne serait-il pas formidable que votre système de test soit suffisamment intelligent pour savoir quels tests doivent être exécutés et lesquels peuvent être ignorés ? Les agents de test correctement intégrés au système CI/CD seraient en mesure de faire ce choix.</p>'}, {'', '<h3>Minimiser les risques</h3>'}, {'', ""<p>En relevant ces défis, les agents de test modifient efficacement le calcul du retour sur investissement pour l'automatisation des tests. Les tests créés par les agents sont moins coûteux à maintenir, ce qui réduit l'investissement. Ils ne s'exécutent qu'en cas de besoin, ce qui réduit encore les coûts. Étant donné que la PME est impliquée dans le processus de création, les tests sont plus susceptibles de détecter les problèmes les plus critiques, minimisant ainsi le risque d'indisponibilité des applications. Gagnez, gagnez et gagnez.</p>""}, {'', '<p>Tout cela semble formidable, mais il doit y avoir un inconvénient. Quels sont les risques ?</p>'}, {'', '<p>Le risque à court terme est de penser qu’un agent de test est entièrement automatique. Nous y parviendrons peut-être bientôt, mais à court terme, il est préférable de considérer ces agents comme un « membre de l’équipe qui garantit que nos versions sont robustes et fiables ». Les humains impliqués dans la boucle ont la responsabilité de gérer le processus et de garantir le bon résultat. Même les meilleurs LLM ont encore des hallucinations de temps en temps, donc jusqu’à ce que ces agents établissent un historique, faites-leur confiance mais vérifiez.</p>'}]"
La plateforme d'automatisation Sapient.ai exploite l'IA pour créer des tests unitaires,"[{'', ""<p>Sapient.ai a lancé aujourd'hui une plateforme d'automatisation des tests qui utilise l'intelligence artificielle (IA) et crée automatiquement des tests unitaires au fur et à mesure du développement des applications.</p>""}, {'', ""<p>Rishi Singh, PDG de la société, a déclaré que Sapient Codeless utilise de grands modèles de langage (LLM) qui ont été spécialement formés pour créer des tests unitaires et les exécuter automatiquement selon les besoins. Il analyse le code puis génère automatiquement des tests déclaratifs en fonction des entrées et des sorties des méthodes utilisées pour créer l'application.</p>""}, {'', ""<p>De plus, Sapient Codeless s'adapte automatiquement aux modifications de la base de code, garantissant que les tests restent à jour d'une manière qui élimine le besoin de maintenance continue des tests.</p>""}, {'', ""<p>L'objectif global est de simplifier le suivi de la quantité de code à tester à mesure que de plus en plus d'organisations utilisent des assistants d'IA pour écrire du code, a noté Singh.</p>""}, {'', '<p>Cette approche présente l’avantage supplémentaire de réduire considérablement la quantité de code de test que les équipes DevOps devraient gérer en plus de tout le reste du code qu’elles gèrent déjà, a-t-il ajouté. Dans certaines organisations, les équipes DevOps doivent gérer jusqu’à cinq fois plus de code de test standard que de code réel qui finit par se retrouver dans une application, a déclaré Singh.</p>'}, {''}, {'', '<p>Alors que le rythme de développement des applications continue de s’accélérer, il est clair que les approches manuelles existantes pour créer des tests unitaires ne seront pas évolutives. On s’attend à ce que de nombreuses organisations, grâce à l’essor de l’IA, créent et déploient plus d’applications au cours des deux prochaines années qu’elles ne l’auraient fait au cours de la dernière décennie.</p>'}, {'', '<p>Cependant, si la plupart de ces applications ne sont pas testées plus en profondeur avant d’être déployées, la plupart des équipes DevOps se retrouveront à essayer de déboguer et de dépanner plus d’applications que jamais, bien longtemps après leur déploiement dans un environnement de production, a noté Singh.</p>'}, {'', ""<h3>Les plateformes d'automatisation basées sur l'IA simplifient les choses</h3>""}, {'', '<p>Il n’est pas évident de déterminer dans quelle mesure les entreprises doivent effectuer davantage de tests ou se concentrer davantage sur l’exécution du bon test au bon moment. On perd beaucoup de temps à exécuter des tests dans une séquence qui ne révèle un échec qu’à un stade avancé du processus. En théorie, les plateformes d’automatisation dotées d’IA devraient faciliter l’identification plus rapide du code susceptible d’échouer à un test spécifique. En effet, les équipes DevOps devraient pouvoir exécuter plus facilement le bon test au bon moment.</p>'}, {'', '<p>En attendant, le débat sur la question de savoir qui doit exécuter quel type de test à un moment donné continue sans relâche. De nombreux développeurs sont heureux d’exécuter des tests qui font apparaître des problèmes au fur et à mesure qu’ils écrivent du code, mais ne sont pas aussi impliqués lorsque les tests sont exécutés, bien longtemps après avoir passé à un autre projet. Dans de nombreux cas, ils préfèrent voir une équipe DevOps gérer une partie importante du processus de test à leur place.</p>'}, {'', '<p>Quelle que soit l’approche adoptée, une chose est sûre : la qualité globale des applications déployées doit être améliorée. Le problème est désormais de trouver un moyen d’atteindre cet objectif sans augmenter le niveau global de travail déjà requis.</p>'}]"
SmartBear ajoute davantage d'outils de test d'IA générative à sa plateforme,"[{'', ""<p>Cette semaine, SmartBear a étendu ses efforts pour intégrer l'intelligence artificielle générative (IA) à son portefeuille d'automatisation des tests afin d'inclure les données de test et les contrats d'interface de programmation d'application (API).</p>""}, {'', ""<p>Ce dernier ajout à la famille d'outils d'IA générative SmartBear HaloAI automatise un ensemble de tâches manuelles dans le cadre d'un effort plus vaste visant à réduire le travail requis pour tester les applications, en exploitant les grands modèles de langage fondamentaux initialement développés par Open AI.</p>""}, {'', ""<p>Dan Faulkner, directeur des produits chez SmartBear, a déclaré que l'entreprise s'efforçait de maîtriser des techniques telles que la génération augmentée de récupération (RAG) pour permettre aux développeurs d'utiliser le langage naturel pour créer automatiquement des tests valides basés sur des données collectées via sa plateforme. L'objectif est d'augmenter le niveau de déterminisme qui peut être appliqué aux tests en utilisant une plateforme d'IA générative qui, par définition, fournit une approche probabiliste pour générer du contenu et désormais des données synthétiques pour les tests, a-t-il noté.</p>""}, {'', ""<p>Plus tôt cette année, SmartBear a acquis Reflect, un fournisseur d'une plate-forme de test sans code pour les applications Web qui exploite l'IA générative, pour relancer ses efforts.</p>""}, {'', '<p>La génération de données de test par IA pour la plateforme TestComplete de l’entreprise sera disponible en version bêta le mois prochain. Les tests de contrats augmentés par IA pour sa plateforme PactFlow seront testés en version bêta de juillet à août. Le mois dernier, SmartBear a ajouté un outil d’IA pour générer des tests API qui élimine le besoin pour les développeurs d’écrire et de déboguer des scripts.</p>'}, {'', '<p>En général, l’utilisation du langage naturel rendra les tests d’application plus accessibles aux parties prenantes des applications qui souhaitent participer au processus de test d’application, a noté Faulkner.</p>'}, {'', ""<p>L'IA générative devrait également permettre de trouver plus facilement le juste équilibre entre le transfert de certaines responsabilités de test vers les développeurs, lorsque cela est approprié, et l'exécution de tests qui seraient mieux adaptés à la conduite par des ingénieurs DevOps, a-t-il ajouté.</p>""}, {'', ""<p>En fin de compte, les organisations devraient être en mesure de transférer la responsabilité des tests à la fois vers la gauche et vers la droite pour améliorer la qualité globale des applications qu'elles déploient, a noté Faulkner.</p>""}, {'', '<p>L’adoption de l’IA générative n’en est qu’à ses débuts. Cependant, il ne faudra pas longtemps avant que ces outils soient largement utilisés non seulement pour générer du code, mais aussi pour automatiser les flux de travail DevOps. Le prochain défi majeur consistera à orchestrer tous les assistants IA optimisés pour effectuer des tâches spécifiques, telles que le test des API qui seront bientôt intégrées à ces flux de travail.</p>'}, {'', '<p>En attendant, les équipes DevOps devront déterminer dans quelle mesure elles peuvent étendre leurs flux de travail existants de manière à intégrer des assistants IA plutôt que de choisir de remplacer leurs plateformes existantes. Quelle que soit l’approche choisie, les ingénieurs DevOps découvriront bientôt qu’ils ont accès à une gamme d’assistants IA formés pour automatiser des tâches spécifiques qu’ils devront orchestrer de manière asynchrone à chaque étape d’un pipeline pour permettre aux organisations de déployer plus de logiciels plus rapidement.</p>'}, {'', '<p>Le défi est que la quantité de logiciels qu’une entreprise déploiera au cours des prochaines années dépassera probablement de loin celle qu’elle aurait pu déployer au cours de la dernière décennie. Cependant, moins les logiciels sont testés avant d’être déployés, plus il est probable que les ingénieurs DevOps se retrouveront à passer plus de temps que jamais à dépanner des applications bien longtemps après leur déploiement initial.</p>'}]"
Une enquête révèle l'ampleur de la crise de sécurité des applications Web,"[{'', ""<p>Une enquête menée auprès de 349 professionnels de la cybersécurité aux États-Unis et au Royaume-Uni révèle que si 60 % d'entre eux travaillent pour des organisations qui mettent à jour leurs applications Web au moins une fois par semaine, près des trois quarts (75 %) testent leurs applications Web une fois par mois ou moins souvent.</p>""}, {'', ""<p>Menée par CyCognito, un fournisseur de solutions de détection de sécurité des applications Web, l'enquête a révélé que le nombre d'applications Web dans leur environnement était trop important pour permettre des tests adéquats, près de 75 % d'entre elles laissant plus de 40 % de la surface d'attaque non testée.</p>""}, {'', ""<p>Plus d'un tiers (35 %) des personnes interrogées ont déclaré que leur organisation était confrontée à un événement de sécurité majeur impliquant une application Web au moins une fois par semaine. Plus d'un quart (26 %) ont déclaré qu'elles étaient confrontées à un incident majeur impliquant une application Web une fois par semaine.</p>""}, {'', '<p>En outre, plus de la moitié des répondants (53 %) ont indiqué avoir des difficultés à corriger les vulnérabilités découvertes par les tests d’applications Web. Plus de la moitié (54 %) des répondants ont du mal à corriger les vulnérabilités révélées par leurs tests de sécurité d’applications Web. Près d’un tiers (28 %) sont tout à fait d’accord pour dire qu’ils ne sont pas en mesure d’exploiter facilement les résultats des tests de vulnérabilité.</p>'}, {'', ""<p>L'enquête identifie les principaux obstacles à des tests d'applications Web adéquats, notamment le volume d'API dans les environnements de production (67 %) et le temps nécessaire pour tester et surveiller les modifications (66 %).</p>""}, {'', '<p>Du côté positif, près des deux tiers (65 %) ont déclaré qu’ils prévoyaient d’accroître l’automatisation de leurs flux de travail de test de sécurité des applications Web.</p>'}, {'', ""<p>Selon Rob Gurzeev, PDG de CyCognito, le manque de tests sur l'ensemble du portefeuille d'applications Web est essentiellement une question de chiffres. Les entreprises ont plus d'applications en cours de développement et de déploiement qu'elles ne peuvent raisonnablement espérer tester, à moins qu'elles n'investissent davantage dans l'automatisation, a-t-il ajouté.</p>""}, {'', '<h3>Aucun processus formel pour tester les applications Web de production</h3>'}, {'', '<p>Plus difficile encore, dans de nombreuses organisations, il n’est pas toujours évident de savoir à qui incombe la responsabilité de garantir la sécurité des applications Web, a noté Gurzeev. Plus d’un quart des participants à l’enquête (26 %) travaillent pour des organisations qui ne disposent d’aucun processus formel de test des applications Web de production. Près d’un quart (24 %) ont indiqué que leur organisation ne disposait pas d’un processus formel de transfert lorsque les applications Web étaient livrées en production et que les équipes de sécurité devenaient responsables de leur test, de leur surveillance et de leur protection. Un pourcentage encore plus élevé (27 %) a déclaré que les unités commerciales individuelles ne disposaient pas de processus permettant d’impliquer l’équipe de sécurité dans le déploiement des applications Web. Un nombre similaire (27 %) n’avait aucun processus pour tester la sécurité des applications Web une fois en production.</p>'}, {'', ""<p>Pour tous les types de tests, environ 60 à 70 % des organisations effectuent des tests tous les mois ou moins souvent. Environ 30 à 40 % de tous les tests sont effectués tous les trimestres ou moins souvent. Plus des trois quarts des répondants (77 %) s'attendent à ce que leur fournisseur de cloud effectue au moins quelques tests et correctifs de sécurité.</p>""}, {'', '<p>Il ne fait aucun doute qu’il existe de nombreuses possibilités d’amélioration des flux de travail DevSecOps dans la plupart des organisations. En fait, les gouvernements du monde entier commencent à mettre en place des réglementations qui obligeront les organisations qui déploient des logiciels à se montrer beaucoup plus responsables de la sécurité des applications.</p>'}, {'', '<p>Plus difficile encore, grâce aux progrès de l’intelligence artificielle, le nombre d’applications Web qui seront déployées dans les années à venir ne fera qu’augmenter de manière exponentielle. Si ce n’est pas déjà le cas, il est clair que la taille globale du portefeuille d’applications à sécuriser dépasse largement la capacité des organisations à les sécuriser et à les gérer efficacement.</p>'}]"
ContextQA se tourne vers IBM pour l'IA afin d'automatiser les tests,"[{'', ""<p>ContextQA intègre la plateforme IBM watsonx.ai pour la création, l'accès et le déploiement de modèles d'intelligence artificielle (IA) dans sa plateforme d'automatisation low-code/no-code pour tester le front-end des applications.</p>""}, {'', ""<p>Auparavant, ContextQA s'appuyait initialement sur Amazon Web Services (AWS) mais a décidé de passer à IBM pour réduire les coûts.</p>""}, {'', ""<p>Deep Barot, PDG de ContextQA, a déclaré qu'en plus de fournir un meilleur support, IBM travaille plus étroitement avec ContextQA pour élargir le nombre de cas d'utilisation où l'IA peut être appliquée.</p>""}, {'', '<p>En fin de compte, l’objectif n’est pas tant d’augmenter le nombre de tests exécutés que de permettre aux équipes DevOps d’exécuter plus facilement le bon test au bon moment, a-t-il ajouté. À terme, les modèles d’IA devraient être capables d’exécuter 80 % des tests les plus courants, ce qui laisserait aux équipes DevOps plus de temps pour exécuter des tests de cas d’utilisation supplémentaires qui n’auraient peut-être jamais été exécutés auparavant, a noté Barot.</p>'}, {''}, {'', '<p>En théorie, les modèles d’IA devraient améliorer la qualité globale des applications déployées. Cependant, l’enjeu n’est pas seulement de s’assurer que davantage d’applications sont testées de manière approfondie, mais également de s’assurer que les tests sont effectués dans le bon ordre. En effet, les équipes DevOps doivent être capables d’exploiter différentes classes de modèles d’IA pour orchestrer des processus de test plus intelligents dans le contexte d’un flux de travail DevOps plus large.</p>'}, {'', '<p>Selon Barot, plus l’application créée et déployée est complexe, plus la capacité d’orchestration devient essentielle. Cela est d’autant plus important qu’à mesure que de plus en plus de tests sont effectués à l’aide de modèles d’IA, le coût global des tests aura tendance à augmenter. En outre, les progrès de l’IA devraient simplifier la création et le déploiement d’un nombre d’applications plus important que jamais, qui doivent toutes être minutieusement testées avant d’être déployées dans un environnement de production.</p>'}, {'', '<p>On ne sait pas exactement pendant combien de temps les équipes DevOps vont s’intéresser aux modèles d’IA spécifiques utilisés pour effectuer une tâche spécifique, mais pour l’instant, la plupart des équipes informatiques sont très intéressées de savoir à quels LLM elles pourraient exposer des données sensibles lorsque des problèmes de sécurité et de conformité surviennent, a noté Barot.</p>'}, {""<h3>Identifier les opportunités d'automatisation rendues possibles par l'IA dès maintenant</h3>"", ''}, {'', '<p>Il faudra peut-être un certain temps avant que l’IA ne soit appliquée de manière généralisée aux tests d’applications, mais la question est désormais de savoir quand plutôt si. Historiquement, chaque fois qu’une équipe DevOps prenait du retard, elle avait naturellement tendance à réduire le temps alloué aux tests. Le problème est qu’au fil du temps, la réduction des tests finit par entraîner une baisse globale de la qualité des logiciels, à une époque où les utilisateurs finaux sont moins tolérants aux bugs et aux défauts.</p>'}, {'', '<p>Espérons qu’un jour prochain, le nombre de problèmes que les équipes DevOps doivent résoudre régulièrement diminuera à mesure que la qualité des logiciels déployés s’améliorera. En attendant, les équipes DevOps doivent évaluer les flux de travail DevOps existants pour identifier les opportunités d’automatisation rendues possibles par l’IA. Le problème n’est pas tant que l’IA va remplacer le besoin de professionnels DevOps dans un avenir proche, mais plutôt qu’elle détermine les tâches à déléguer aux machines de manière à permettre aux équipes DevOps de créer et de déployer des applications à une échelle sans précédent.</p>'}]"
Défis des tests ETL et comment les surmonter,"[{'', ""<p>Les processus d'extraction, de transformation et de chargement (ETL), qui sont essentiels à l'intégration des données, constituent la clé de voûte de la consolidation des données provenant de sources multiples dans un référentiel unifié. Malgré leur rôle essentiel, les processus ETL sont sujets à des difficultés, en particulier pendant la phase de test, lorsque la garantie de la qualité, de l'intégrité et des performances des données devient primordiale.</p>""}, {'', ""<p>Les tests ETL sont essentiels pour identifier et corriger les erreurs, les incohérences et les inefficacités avant que les données ne soient finalisées à des fins d'analyse et de prise de décision. Cet article examine les obstacles courants rencontrés lors des tests ETL et fournit des stratégies concrètes pour surmonter ces défis de manière efficace, garantissant ainsi un processus d'intégration de données transparent et fiable.</p>""}, {'<h3>Comprendre les tests ETL</h3>', ''}, {'', ""<p>Les tests ETL sont un élément essentiel du processus d'intégration des données, conçu pour valider la transformation, l'extraction et le chargement de données provenant de diverses sources dans une base de données cible ou un entrepôt de données désigné. Son objectif principal est de garantir que les données transférées via le pipeline ETL sont exactes, cohérentes et complètes. Cela implique de vérifier que tous les enregistrements sont correctement extraits des systèmes sources, que les transformations sont conformes aux règles et à la logique métier, et que le chargement final dans le système cible reflète précisément le résultat escompté sans aucune perte ou corruption de données.</p>""}, {'', ""<p>Les tests ETL sont essentiels pour maintenir la qualité des données, ce qui est fondamental pour des analyses et une veille stratégique fiables. Ils englobent plusieurs activités vitales, notamment les contrôles d'exhaustivité des données, la validation de la transformation des données et la vérification du flux de données de bout en bout, toutes visant à identifier et à atténuer les anomalies de données et à garantir l'intégrité et la facilité d'utilisation des données commerciales critiques.</p>""}, {'', '<h3>Défis courants en matière de tests ETL</h3>'}, {'', ""<p>Les tests ETL sont confrontés à plusieurs défis qui peuvent compliquer le processus d'intégration des données, ce qui a un impact sur la précision et la fiabilité des analyses et des données de veille économique. Ces défis incluent :</p>""}, {'', ""<p>• Logique de transformation complexe : la validation de la logique métier qui transforme les données peut être complexe, en particulier lorsqu'il s'agit de règles complexes et de sources de données multiples. Pour garantir que toutes les transformations sont correctement appliquées, il faut une compréhension détaillée des données et des processus métier qu'elles prennent en charge.</p>""}, {'', ""<p>• Volume et évolutivité des données : avec la croissance exponentielle des données, tester l'évolutivité et les performances des processus ETL sous de gros volumes devient une tâche ardue. Les testeurs doivent s'assurer que le processus ETL peut gérer la charge de données actuelle et évoluer en fonction de la croissance future.</p>""}, {'', ""<p>• Problèmes de qualité des données : les problèmes de qualité des données inhérents, tels que les valeurs manquantes, les doublons et les incohérences entre les systèmes sources, posent des défis considérables. L'identification et la résolution de ces problèmes au cours du processus ETL sont essentielles pour maintenir l'intégrité de l'entrepôt de données.</p>""}, {'', ""<p>• Intégration avec plusieurs sources de données : le processus ETL implique souvent l'intégration de données provenant de sources disparates, chacune avec son propre format et ses propres normes. Assurer une intégration transparente et une représentation cohérente des données dans toutes les sources nécessite une planification et des tests méticuleux.</p>""}, {'', ""<p>• Performances et optimisation : il est essentiel de tester les goulots d'étranglement des performances et d'optimiser le processus ETL pour plus de rapidité et d'efficacité, en particulier pour les besoins de traitement des données en temps réel. L'identification de l'équilibre optimal entre performances et utilisation des ressources est un défi crucial.</p>""}, {'', ""<p>Relever ces défis avec succès exige une approche stratégique des tests ETL, englobant une planification minutieuse, des techniques de test avancées et une compréhension approfondie des données et du contexte commercial qu'elles servent.</p>""}, {'<h3>Stratégies pour surmonter les défis des tests ETL</h3>', ''}, {'', ""<p>Pour surmonter les défis liés aux tests ETL, il faut une stratégie complète qui garantisse l'intégrité des données, les performances et l'évolutivité. Voici quelques stratégies efficaces\xa0:</p>""}, {'', ""<p>• Outils de test automatisés : l'automatisation du processus de test ETL peut améliorer considérablement l'efficacité et la précision. Les outils qui prennent en charge la validation et la comparaison automatisées des données peuvent identifier rapidement les écarts et les erreurs, réduisant ainsi les efforts manuels et le risque d'oubli.</p>""}, {'', ""<p>• Outils de profilage et de qualité des données : l'utilisation précoce d'outils de profilage des données permet d'identifier les problèmes de qualité des données tels que les incohérences, les doublons et les valeurs aberrantes. L'intégration d'outils de qualité des données pour nettoyer et normaliser les données avant qu'elles n'entrent dans le pipeline ETL garantit un processus de transformation plus propre et des résultats de meilleure qualité.</p>""}, {'', ""<p>• Une approche de test modulaire : la division du processus ETL en modules ou composants plus petits et plus faciles à gérer permet des tests plus ciblés et plus efficaces. Cette approche permet aux testeurs d'isoler et de résoudre les problèmes plus efficacement, en s'assurant que chaque partie du processus fonctionne correctement avant de passer à la suivante.</p>""}, {'', ""<p>• Analyse comparative des performances : l'établissement d'analyses comparatives des performances du processus ETL permet d'identifier les goulots d'étranglement et les inefficacités. La réalisation de tests de charge et de stress sous différents volumes de données et scénarios garantit que le processus ETL peut répondre aux exigences du monde réel.</p>""}, {'', ""<p>• Intégration et tests continus : la mise en œuvre d'un pipeline d'intégration continue (CI) pour les processus ETL permet de détecter rapidement les erreurs et les problèmes d'intégration. Cette approche permet de tester et de valider en permanence les données au fur et à mesure de leur progression dans le pipeline ETL, facilitant ainsi un retour d'information immédiat et une résolution plus rapide des problèmes.</p>""}, {'', '<p>• Collaboration humaine : encourager la collaboration entre les ingénieurs de données, les testeurs et les analystes commerciaux garantit une compréhension approfondie de la logique métier et des exigences de qualité des données. Cette approche collaborative permet de concevoir des cas de test plus efficaces et de mieux comprendre la logique de transformation.</p>'}, {'', '<p>En adoptant ces stratégies, les organisations peuvent relever les défis courants rencontrés lors des tests ETL, ce qui conduit à des efforts d’intégration de données plus fiables et, en fin de compte, à des informations commerciales plus précises et exploitables.</p>'}, {'', '<h3>Bonnes pratiques pour des tests ETL efficaces</h3>'}, {'', '<p>Pour garantir des tests ETL efficaces, l’adoption d’un ensemble de bonnes pratiques est essentielle\xa0:</p>'}, {'', '<p>• Élaborez un plan de test complet : commencez par un plan de test détaillé qui décrit les stratégies de test, les objectifs et les critères pour chaque phase du processus ETL. Ce plan doit couvrir tous les aspects, de la vérification de la source de données à la logique de transformation et aux tests de charge dans la base de données cible.</p>'}, {'', ""<p>• Utiliser des données de test réalistes : utilisez un échantillon représentatif de données de production couvrant divers scénarios, y compris les cas extrêmes et les anomalies de données. Cette approche permet de découvrir les problèmes potentiels affectant l'intégrité et la facilité d'utilisation des données.</p>""}, {'', ""<p>• Automatisez autant que possible : l'automatisation des tâches de test répétitives et gourmandes en données augmente l'efficacité et la précision. Les tests de régression automatisés sont précieux pour les processus ETL en cours qui subissent des mises à jour ou des modifications.• Donnez la priorité à la qualité des données : intégrez des contrôles de qualité des données à chaque étape du processus ETL. Cela comprend la validation de l'exhaustivité, de l'exactitude et de la cohérence des données pour garantir que les données répondent aux normes prédéfinies.</p>""}, {'', ""<p>• Favoriser la collaboration au sein de l'équipe : encouragez la collaboration et la communication ouvertes entre les équipes de développement, de test et d'analyse commerciale. Une approche unifiée garantit une compréhension commune des objectifs ETL et améliore la qualité globale du processus de test.</p>""}, {'', '<p>L’adoption de ces meilleures pratiques peut considérablement améliorer les résultats des tests ETL, ce qui se traduit par des données plus fiables, plus précises et de meilleure qualité pour la veille économique et l’analyse.</p>'}, {'<h3>Derniers mots</h3>', ''}, {'', ""<p>L'intégration de tests ETL efficaces dans le processus d'intégration des données est essentielle pour garantir des résultats de données fiables et de haute qualité. Les organisations peuvent améliorer leurs efforts de tests ETL en relevant les défis courants avec des solutions stratégiques et en adhérant aux meilleures pratiques, ouvrant ainsi la voie à des analyses approfondies et à des décisions commerciales éclairées.</p>""}]"
Tricentis ajoute des copilotes IA supplémentaires à sa plateforme d'automatisation des tests,"[{'', ""<p>Cette semaine, Tricentis a mis à disposition du public un module complémentaire copilote pour sa plateforme d'automatisation des tests Tricentis Tosca. Ce module complémentaire simplifie la recherche, la compréhension et l'optimisation des tests via une interface de chat.</p>""}, {'', ""<p>Mav Turner, directeur des produits et de la stratégie chez Tricentis, a déclaré que la société ajoutait des copilotes à chacune de ses offres de produits en utilisant de grands modèles de langage (LLM) développés par Open AI. Auparavant, Tricentis avait lancé Tricentis Testim Copilot ; la société prévoit d'ajouter prochainement un Tricentis Copilot pour Tricentis qTest.</p>""}, {'', ""<p>Au fil du temps, ces assistants IA pourront collaborer sur des tâches entre eux et éventuellement avec des assistants IA fournis par d'autres fournisseurs d'autres plateformes, notamment SAP, a ajouté Turner.</p>""}, {'', ""<p>En attendant, les équipes DevOps peuvent utiliser Tosca Copilot pour trouver des cas de test inutilisés, des tests en double, des ressources non liées, des exécutions spécifiques et des tests liés à des éléments d'application. Turner a noté que les résumés rendus possibles par Tosca Copilot devraient simplifier l'intégration de testeurs supplémentaires par les équipes DevOps.</p>""}, {'', '<p>Les équipes DevOps peuvent également modifier n’importe quelle combinaison de ces tests via une invite d’IA générative plutôt que de devoir maîtriser directement le langage de requête Tosca existant. Cette capacité devrait également réduire considérablement le temps et les efforts actuellement nécessaires pour résoudre les défauts des tests, a déclaré Turner.</p>'}, {'', '<p>Globalement, Tricentis indique que le temps consacré aux activités de test complexes peut être réduit de moitié, par exemple en réduisant le nombre de tâches de test répétitives auparavant requises. En fait, Tricentis constate déjà une réduction de 16 à 43 % des taux d’échec des tests avec les outils d’IA de Tricentis et une augmentation allant jusqu’à 50 % de la génération de cas de test.</p>'}, {''}, {'', '<p>L’objectif n’est pas nécessairement d’augmenter le nombre de tests exécutés, mais plutôt de s’assurer que les bons tests sont effectués au bon moment pour améliorer la qualité des applications, a déclaré Turner.</p>'}, {'', '<p>Il sera toutefois plus facile pour n’importe quel membre d’une équipe DevOps, y compris les développeurs d’applications, de générer un test de manière itérative. C’est mieux que de devoir attendre qu’une équipe de test dédiée crée un test. L’IA générative devrait également permettre aux équipes DevOps de réutiliser plus facilement les tests, de les exécuter plus rapidement, de générer moins d’erreurs, de réduire les coûts et d’augmenter la productivité globale.</p>'}, {'', '<p>On ne sait pas encore dans quelle mesure l’IA générative démocratisera les tests d’applications, mais à mesure que les tests deviennent plus faciles à créer, il devrait y avoir plus de temps pour exécuter une plus large gamme de tests qui pourraient, par exemple, résoudre des problèmes de cybersécurité. La plupart des tests exécutés aujourd’hui font généralement apparaître des erreurs de programmation courantes et il existe toujours une tendance à sauter des tests chaque fois qu’un projet de développement d’application commence à prendre du retard.</p>'}, {'', '<p>Cependant, à mesure que les tests deviennent plus rapides à l’ère de l’IA, il devrait y avoir plus de temps pour exécuter une gamme plus large de tests. Le défi consiste à trouver la meilleure façon d’orchestrer ces tests sur un portefeuille d’applications qui ne fera que s’élargir à mesure que les outils d’IA permettront aux développeurs d’écrire du code plus rapidement et plus facilement.</p>'}]"
Aperçu des processus de tests de sécurité continus pour DevSecOps,"[{'', ""<p>Comme vous le savez probablement déjà, DevSecOps est une méthodologie de développement logiciel qui combine le développement (Dev), la sécurité (Sec) et les opérations (Ops) à toutes les phases du cycle de vie du développement logiciel (SDLC). Elle intègre les contrôles de sécurité dans le processus de développement et comble les écarts entre les équipes de développement, de sécurité et d'exploitation.</p>""}, {'', '<p>Grâce aux pratiques DevSecOps, vous pouvez créer un environnement plus sécurisé, sécuriser davantage les pipelines d’intégration et de livraison continue et produire des logiciels de haute qualité. En intégrant la sécurité dès le début du pipeline, les entreprises peuvent atteindre une productivité plus élevée. DevSecOps n’est pas une option ; compte tenu de la recrudescence des cyberattaques, il est devenu nécessaire.</p>'}, {'', ""<h3>Qu'est-ce que les tests de sécurité continus ?</h3>""}, {'', ""<p>Comme son nom l'indique, les tests de sécurité continus garantissent que les tests de sécurité ont lieu à chaque phase du cycle de vie du logiciel. Leur objectif est de protéger les applications contre les menaces et vulnérabilités potentielles en découvrant les risques, les menaces et les dangers de sécurité avant que le logiciel ne soit mis en production.</p>""}, {'', ""<p>Les tests de sécurité traditionnels vérifient si un algorithme fonctionne correctement à un moment donné. En revanche, les tests de sécurité continus détectent et corrigent les faiblesses et les failles de sécurité en permanence tout au long du cycle de vie de l'application.</p>""}, {'', ""<p>Les tests de sécurité continus évaluent l'infrastructure, les applications et les terminaux pour détecter d'éventuelles failles que les attaquants peuvent exploiter. Il s'agit d'une extension des tests continus, qui inspecte en permanence le code et les bibliothèques tierces pour détecter les problèmes de sécurité connus ou récemment découverts.</p>""}, {'', ""<p>Les outils peuvent aider le personnel à automatiser les contrôles de sécurité dans une application. Plusieurs options sont disponibles pour répondre aux différentes phases des processus de développement, d'intégration et de déploiement.</p>""}, {'', '<p>Des tests de sécurité réguliers garantissent le respect des normes du secteur. Plus important encore, ils obligent les développeurs à mettre en œuvre des mesures de sécurité de premier ordre dans leur code pour contrecarrer les menaces de sécurité potentielles à long terme.</p>'}, {'', ""<h3>Pratiques courantes pour l'intégration des tests de sécurité dans DevSecOps</h3>""}, {'', '<p>Le SLDC comporte plusieurs phases et il peut falloir un certain temps pour intégrer la méthodologie de développement traditionnelle aux processus plus récents. Quiconque souhaite intégrer les tests de sécurité dans DevSecOps doit commencer par ces pratiques.</p>'}, {'', '<h4>Exécution de contrôles de sécurité automatisés</h4>'}, {'', '<p>L’automatisation des contrôles de sécurité au cours du cycle de vie du développement logiciel est un élément clé de DevSecOps. Cette méthode permet de détecter les vulnérabilités à un stade précoce, lorsqu’il est plus facile, plus rapide et moins frustrant de résoudre les problèmes. Les contrôles de sécurité automatisés fonctionnent en arrière-plan, ce qui permet aux développeurs de se concentrer sur les autres éléments de leurs applications. C’est un peu comme si vous disposiez d’une paire d’yeux vigilants supplémentaires qui signalent les dangers potentiels.</p>'}, {'', ""<p>Quel que soit le logiciel choisi, les outils automatisés peuvent analyser le code à la recherche de vulnérabilités en temps réel pendant le processus de création ou à d'autres moments appropriés. Le retour d'information instantané permet aux équipes de résoudre les problèmes bien avant qu'ils ne deviennent des problèmes majeurs, garantissant ainsi la sécurité de la base de code.</p>""}, {'', '<h4>Intégration de la révision du code</h4>'}, {'', '<p>La révision du code est une tradition bien ancrée au sein des équipes de développement Agile, pour des raisons qui vont bien au-delà de la sécurité. C’est également un bon moyen d’intégrer des tests de sécurité continus dans le processus SDLC, en partie parce qu’il est déjà familier à de nombreuses équipes. L’intégration de la révision du code aux outils d’analyse des vulnérabilités fournit un retour immédiat sur les faiblesses de sécurité du code source.</p>'}, {'', '<h4>Améliorer la sensibilisation à la sécurité</h4>'}, {'', ""<p>Idéalement, votre organisation a déjà investi dans la formation pour aider les utilisateurs finaux et les développeurs à reconnaître les façons dont les applications et les pratiques commerciales peuvent les rendre vulnérables. Des formations régulières permettent aux développeurs de rester informés des nouvelles menaces et encouragent le partage d'informations entre les équipes. Plus ils en savent, mieux ils peuvent identifier les menaces de sécurité potentielles et réagir rapidement et efficacement.</p>""}, {'', '<h4>Surveillance continue</h4>'}, {'', '<p>Le DevSecOps ne s’arrête pas au lancement du logiciel. Que se passe-t-il une fois l’application mise en production ? La surveillance continue consiste à surveiller une application contre les menaces de sécurité potentielles en temps réel en prêtant attention aux journaux, aux événements et au trafic réseau. Elle aide les organisations à détecter immédiatement les menaces potentielles, ce qui permet d’éviter les failles de sécurité ou au moins d’y réagir rapidement.</p>'}, {'', '<h4>Modélisation des menaces</h4>'}, {'', '<p>Il faut parfois anticiper les risques. La modélisation des menaces consiste à identifier en amont les menaces potentielles pour la sécurité, pas seulement ce qui se trouve dans le code, mais aussi ce que quelqu’un pourrait essayer de faire pour accéder à l’application ou en tirer profit. Cela se fait souvent en examinant la conception et l’architecture d’une application pour détecter les vecteurs d’attaque potentiels, souvent à l’aide d’outils sophistiqués.</p>'}, {'', '<h3>N’hésitez pas : déployez dès maintenant des tests de sécurité continus</h3>'}, {'', '<p>Le succès de DevSecOps, l’intégration de la sécurité dans DevOps, nécessite un changement de perspective, ainsi que de nouvelles ressources et méthodes. Il serait judicieux d’adopter l’état d’esprit collaboratif et agile de DevOps pour rendre le processus de développement fluide et transparent et garantir que la sécurité soit aussi fluide et discrète que possible.</p>'}]"
SmartBear applique l'IA générative à l'ensemble de son portefeuille d'outils API,"[{'', ""<p>SmartBear a ajouté des capacités d'intelligence artificielle (IA) générative à son portefeuille d'outils pour la création, le test et la surveillance d'interfaces de programmation d'applications (API).</p>""}, {'', ""<p>Dan Faulkner, directeur des produits et de la technologie chez SmartBear, a déclaré que SmartBear HaloAI s'appuie initialement sur de grands modèles de langage (LLM) d'Open AI. Cependant, l'entreprise prévoit d'utiliser plusieurs LLM de différents fournisseurs à mesure que les cas d'utilisation continuent d'évoluer.</p>""}, {'', ""<p>SmartBear, plutôt que de créer des LLM, concentre ses efforts sur l'utilisation des données qu'il collecte pour exploiter les capacités de plusieurs plateformes d'IA génératives qui coûteraient des millions de dollars à reproduire, a-t-il ajouté.</p>""}, {'', ""<h3>Les capacités de GenAI s'appuient sur les investissements antérieurs dans l'IA</h3>""}, {'', '<p>Disponible en version bêta, SmartBear HaloAI s’appuie sur les investissements antérieurs de l’entreprise en matière d’IA, notamment l’acquisition récente de Reflect, un fournisseur d’un outil d’IA générative pour automatiser la gestion des tests. L’IA générative a déjà été utilisée pour automatiser des cas de test sans avoir à écrire et déboguer les scripts auparavant requis. Une équipe d’assurance qualité (QA) qui devait créer 500 tests manuels d’une durée moyenne de cinq minutes par test a pu exécuter automatiquement ces tests en cinq secondes, économisant ainsi 20 heures de test par cycle de régression.</p>'}, {'', '<p>L’objectif global est de permettre aux équipes DevOps existantes de créer et de tester plus facilement des API à un moment où il existe encore une pénurie de professionnels de l’informatique possédant ces compétences spécifiques, a noté Faulkner.</p>'}, {'', '<p>En général, SmartBear s’oriente vers l’agrégation des outils et des plateformes qu’elle fournit dans une série de centres de solutions qui faciliteront la création, le test, la publication et la surveillance des logiciels, a noté Faulkner. SmartBear HaloAI simplifiera ensuite l’automatisation des processus sur tous les éléments qui composent une solution, a-t-il ajouté.</p>'}, {'', '<p>Il sera particulièrement important de trouver un moyen d’automatiser les tests de code, car à mesure que de plus en plus de développeurs s’appuient sur des outils d’IA à usage général tels que ChatGPT pour écrire du code, la qualité du code écrit est susceptible de diminuer, a noté Faulkner. Les plateformes d’IA générative ont été formées à l’aide de codes de qualité variable provenant d’Internet, de sorte que la qualité du résultat fourni peut varier considérablement, a-t-il noté.</p>'}, {'', '<p>Selon Faulkner, la seule façon de remédier à ce problème sera de tester en continu le code à l’aide de plateformes qui génèrent des tests à l’aide d’exemples validés par le fournisseur d’une plateforme d’automatisation des tests. En effet, SmartBear fournit la « sauce spéciale » nécessaire pour atteindre cet objectif à grande échelle, a-t-il ajouté.</p>'}, {'', '<p>L’adoption de l’IA générative n’en est qu’à ses débuts. Cependant, il ne faudra pas longtemps avant que ces outils soient largement utilisés non seulement pour générer du code, mais aussi pour automatiser les flux de travail DevOps. Le prochain défi majeur consistera à orchestrer tous les assistants IA optimisés pour effectuer des tâches spécifiques, telles que le test des API, qui seront bientôt intégrés à ces flux de travail.</p>'}, {'', '<p>En attendant, les équipes DevOps devront déterminer dans quelle mesure elles peuvent étendre leurs flux de travail existants de manière à intégrer des assistants IA plutôt que de devoir remplacer leurs plateformes existantes. Après tout, le débat ne se limite plus à déterminer les avantages de l’IA, mais s’intéresse également au coût réel de cette transition.</p>'}]"
Une introduction douce à la surveillance et à l'optimisation continues,"[{'', ""<p>La surveillance DevOps fournit une image complète et actualisée de l'état de l'environnement de production et des détails sur ses services, son infrastructure et ses applications. En collectant des données à partir de journaux et de mesures, vous pouvez surveiller la conformité et les performances à chaque étape du cycle de vie du développement logiciel.</p>""}, {'', '<p>La surveillance ne concerne pas uniquement les problèmes de production. Elle englobe plusieurs procédures, telles que la planification, le développement, les tests, le déploiement et l’exploitation.</p>'}, {'', '<h3>Un aperçu des types de surveillance</h3>'}, {'', '<p>Les utilisations de la surveillance continue se développent au même rythme que la taille des piles technologiques des entreprises. De nombreuses entreprises commencent par suivre des indicateurs fondamentaux, tels que l’utilisation du processeur ou le comportement des clients.</p>'}, {'', '<p>Surveillance de l’infrastructure : vous pouvez collecter et analyser les données de l’infrastructure informatique interne de votre organisation et utiliser ces informations pour améliorer les performances ou d’autres indicateurs. Parmi les éléments à surveiller figurent les réseaux, les serveurs, le matériel et les logiciels informatiques, les centres de données, les systèmes d’exploitation et le stockage. Les outils de surveillance de l’infrastructure les plus courants incluent SolarWinds, ManageEngine et Prometheus.</p>'}, {'', '<p>Surveillance du réseau : la surveillance du réseau se concentre sur la recherche d’erreurs, l’évaluation de l’efficacité des composants et l’amélioration de leur utilité. Tout sur le réseau est surveillé, y compris les pare-feu, les serveurs, les machines virtuelles et les routeurs. Un système de surveillance réseau dynamique peut aider à éviter les erreurs et les pannes qui pourraient nuire aux performances. Spiceworks, Cacti et Wireshark sont quelques-uns des utilitaires les plus connus.</p>'}, {'', '<p>Surveillance des performances des applications (APM) : le logiciel fonctionne-t-il suffisamment rapidement ? Si ce n’est pas le cas, d’où vient le problème ? Vous pouvez obtenir des mesures d’exécution sur les performances d’une application, telles que la disponibilité de l’application, la sécurité et la surveillance des journaux. Les solutions APM telles que DataDog, Uptrends et Splunk sont des outils courants pour explorer de nombreux types d’informations, notamment les réponses API, l’état de l’application back-end, le volume des transactions et les mesures de temps.</p>'}, {'', '<p>Suivi des coûts : le pipeline DevOps comporte de nombreux éléments, chacun pouvant être coûteux. Toute organisation qui souhaite contrôler ses coûts (c’est-à-dire tout le monde, n’est-ce pas ?) estime qu’un suivi continu de l’utilisation des ressources est un besoin essentiel. Ces indicateurs permettent de prévoir le coût global et de maximiser l’utilisation des ressources tout au long des étapes DevOps.</p>'}, {'<h3>Pourquoi la surveillance DevOps est importante</h3>', ''}, {'', '<p>La surveillance DevOps étant proactive, elle détecte les opportunités et les lacunes pour améliorer les performances des applications avant que les symptômes des défauts ne deviennent apparents. En mettant l’accent sur les domaines potentiels d’automatisation, la surveillance améliore encore la chaîne d’outils DevOps. À l’aide d’un code piloté par API, une surveillance système appropriée offre des informations pertinentes qui vous permettent de voir chaque élément de votre pile d’applications. Le processus de surveillance est amélioré lorsque des crochets de code sont intégrés à la logique de l’application.</p>'}, {'', ""<p>Automatisation : l'amélioration de la communication entre les équipes de développement et d'exploitation est le principe central de DevOps. Cependant, la coordination entre les équipes peut être interrompue en cas de manque de connectivité entre les outils. Par conséquent, vous pouvez suivre les validations et les demandes d'extraction pour suivre les problèmes Jira et alerter l'équipe de développement sur son canal de communication préféré, ou vous pouvez utiliser l'automatisation pour permettre une vue unifiée de l'ensemble du pipeline de développement.</p>""}, {'', '<p>Visibilité et transparence : un workflow comporte des milliers d’éléments mobiles, chacun fonctionnant à une taille différente et connaissant une latence et une redondance variables en raison de l’introduction de microservices et de micro frontends. Le CI/CD permet aux développeurs d’apporter des modifications fréquentes à leur code, ce qui ajoute à la complexité d’un système de production. Par conséquent, les équipes ont besoin d’une vision de l’écosystème pour réparer tout dommage causé à l’expérience utilisateur dès qu’il se produit.</p>'}, {'', '<p>Expérience de qualité : une équipe DevOps qui utilise des technologies de surveillance continue pour gérer ses systèmes peut minimiser les temps d’arrêt du système et les interruptions d’activité. Cela relève la barre de la qualité de l’expérience informatique pour les parties prenantes internes et externes, telles que les membres du personnel, les partenaires commerciaux et les clients. Cela optimise les performances commerciales au fil du temps dans chaque département de l’entreprise.</p>'}, {'', '<h3>Effectuer correctement la surveillance DevOps</h3>'}, {'', '<p>Chaque organisation a des habitudes légèrement différentes. Néanmoins, il existe quelques principes universellement applicables.</p>'}, {'', ""<p>Définissez des objectifs clairs : quel est l'objectif général de la mise en œuvre de la surveillance DevOps ? S'agit-il d'améliorer les performances du système, de résoudre des problèmes ou d'améliorer l'expérience utilisateur ? L'identification de ces objectifs vous aide à relier vos objectifs de surveillance aux résultats visés.</p>""}, {'', ""<p>Sélectionnez les outils de surveillance appropriés : l'équipe DevOps doit prendre en compte certaines variables, notamment la prise en charge des tâches de surveillance courantes, l'évolutivité, la convivialité et l'intégration. Assurez-vous qu'ils peuvent s'adapter aux besoins changeants de vos flux de travail DevOps.</p>""}, {'', '<p>Collectez des données appropriées : concentrez-vous sur la collecte et l’évaluation des indicateurs critiques. Évitez les volumes de données massifs. Toutes les données ne sont pas utiles et disposer de trop d’informations peut prêter à confusion. L’équipe DevOps doit classer ces indicateurs en fonction de leur impact direct sur les objectifs. Cela permet d’améliorer la sécurité, de réduire les taux d’erreur, d’accélérer les temps de réponse et d’optimiser l’utilisation des ressources.</p>'}, {'', '<p>Documentez tout : si vous souhaitez vraiment instaurer une culture de collaboration, documentez correctement vos procédures de suivi et encouragez le partage des connaissances entre les équipes. Cette stratégie favorise la responsabilisation et l’appropriation des procédures et activités de suivi par les membres de l’équipe.</p>'}, {'', ""<p>Examinez en permanence les résultats : l'analyse et l'amélioration continues doivent faire partie du processus. Évaluez votre plan de surveillance pour vous assurer qu'il est adaptable et qu'il correspond à vos objectifs. Utilisez les informations recueillies et les commentaires des utilisateurs pour affiner vos méthodes de surveillance.</p>""}, {'', ""<h3>Quelques exemples de cas d'utilisation pour la surveillance DevOps</h3>""}, {'', ""<p>Sans aucun doute, la surveillance DevOps présente plusieurs avantages pour toute entreprise. Mais son utilisation appropriée est nécessaire à son succès total. Voici quelques cas d'utilisation de la surveillance DevOps.</p>""}, {'', ""<p>Surveillance des workflows Git\xa0: des conflits de base de code peuvent survenir lorsque de nombreux développeurs travaillent sur le même projet. Git peut résoudre ces problèmes en utilisant des restaurations et des validations. Le processus Git surveille ces conflits et maintient un développement continu. Instrumentation de code\xa0: le processus d'ajout de code à un programme pour suivre ses performances et ses fonctionnalités est connu sous le nom d'instrumentation de code. L'observation des valeurs contextuelles et la surveillance des appels de pile sont essentielles. Les processus DevOps peuvent être évalués pour leur efficacité et leurs défauts. Dans cette situation, les tests et l'identification des bogues sont des facteurs critiques. Journaux d'intégration et de déploiement continus\xa0: cela facilite le dépannage des déploiements ayant échoué et permet de résoudre les difficultés. Consultez les fichiers journaux générés par les systèmes d'intégration continue, en particulier leurs avertissements et leurs erreurs, ainsi que les journaux de déploiement continu pour surveiller l'état général du pipeline de développement.</p>""}, {'', '<h3>Réflexions finales</h3>'}, {'', ""<p>Les services gérés par DevOps évoluent rapidement, tout comme les solutions de surveillance, compte tenu de la complexité et de la profondeur croissantes du développement logiciel. Prendre une décision éclairée concernant vos projets de développement peut vous obliger à choisir le meilleur système de surveillance qui comprenne les nombreuses parties d'une application et la manière dont elles interagissent. Il est donc conseillé de faire appel à des prestataires de services compétents pour vous assurer de prendre la bonne mesure au bon moment afin d'obtenir le retour sur investissement maximal.</p>""}]"
Tricentis utilise l'IA générative pour automatiser les tests d'applications,"[{'', ""<p>Cette semaine, Tricentis a ajouté une fonctionnalité d'intelligence artificielle générative (IA), baptisée Tricentis Copilot, à sa plateforme d'automatisation des tests d'applications. Elle vise à réduire la quantité de code que les équipes DevOps doivent créer manuellement.</p>""}, {'', '<p>Tricentus Copilot est basé sur une instance du modèle de langage large (LLM) créé par Open AI et déployé sur le cloud Microsoft Azure. Il s’agit de la première itération de ce qui deviendra à terme plusieurs assistants d’IA : Tricentis Testim Copilot, qui permet d’utiliser le langage naturel pour décrire un test qui est ensuite généré automatiquement en JavaScript. D’autres solutions Tricentis Copilot pour les plateformes Tricentis Tosca et Tricentis qTest seront ajoutées plus tard cette année.</p>'}, {'', ""<p>Mav Turner, directeur des produits et de la stratégie chez Tricentis, a déclaré que les interfaces utilisateur que la société a créées pour chaque plateforme continueront également d'évoluer, afin de simplifier le lancement des invites appropriées au cours de n'importe quel flux de travail.</p>""}, {'', ""<p>L'objectif est de faciliter la création de tests pour améliorer la qualité des applications, a déclaré Turner. Par exemple, les organisations qui utilisent les éditions bêta de Tricentis Copilot ont déjà constaté une augmentation de 20 à 50 % du nombre de tests créés, tout en réduisant les taux d'échec des tests de 16 à 43 % jusqu'à présent, a-t-il ajouté.</p>""}, {''}, {'', '<p>Il ne fait aucun doute que l’IA générative facilite considérablement la création de tests, ce qui devrait permettre aux équipes DevOps d’exécuter davantage de tests tout au long du cycle de vie du développement logiciel (SDLC). Plutôt que de devoir toujours attendre que des équipes de test dédiées écrivent le code requis, il sera de plus en plus possible pour n’importe quel membre d’une équipe DevOps de générer un test, y compris les développeurs d’applications, qui devraient tester le code au fur et à mesure de sa création.</p>'}, {'', '<p>L’IA générative devrait également permettre aux équipes DevOps de réutiliser plus facilement les tests une fois créés et de comprendre comment ils sont exécutés grâce aux capacités de synthèse offertes par les plateformes d’IA générative qui pourront également fournir des recommandations pour améliorer le code de test. Collectivement, ces capacités permettront d’exécuter les tests plus rapidement, d’avoir moins d’erreurs, de réduire les coûts et d’augmenter la productivité.</p>'}, {'', '<p>Ces fonctionnalités peuvent toutes être fournies d’une manière qui n’entraîne pas l’utilisation d’une partie du code de test pour entraîner ultérieurement une mise à jour du LLM de base fourni par OpenAI, a noté Turner. À plus long terme, Tricentis continuera de rechercher les LLM qui pourraient être les mieux appliqués à un cas d’utilisation donné d’une manière transparente pour une équipe DevOps qui pourrait ne pas être intéressée par le LLM utilisé pour automatiser une tâche. Actuellement, cependant, cela n’a pas beaucoup de sens économique pour Tricentis de créer son propre LLM, a déclaré Turner.</p>'}, {'', '<p>On ne sait pas encore dans quelle mesure l’IA générative démocratisera les tests d’applications, mais à mesure que ces tests deviendront plus faciles à créer, il devrait y avoir plus de temps pour exécuter des tests plus complexes qui pourraient, par exemple, résoudre des problèmes de cybersécurité. La plupart des tests exécutés aujourd’hui font généralement apparaître des erreurs de programmation courantes. Cependant, à mesure que les tests deviennent plus rapides à l’ère de l’IA, il devrait y avoir plus de temps pour exécuter une gamme plus large de tests afin de garantir les meilleures expériences d’application possibles.</p>'}]"
Une enquête révèle que l'IA joue un rôle plus important dans l'automatisation des tests,"[{'', ""<p>Une enquête menée auprès de 1 028 professionnels de l'informatique et développeurs d'applications au Royaume-Uni, aux États-Unis, en Allemagne et à Singapour révèle que près de la moitié (47 %) d'entre eux utilisent encore des tests manuels pour les applications mobiles. Plus d'un tiers (38 %) ont indiqué que leur organisation pourrait économiser entre la moitié et les trois quarts (51-75 %) du budget alloué aux tests par an en automatisant entièrement les tests des applications mobiles.</p>""}, {'', '<p>Réalisée par le cabinet d’études de marché Censuswide pour le compte de Tricentis, fournisseur d’une plateforme d’automatisation des tests, l’enquête révèle également qu’un peu moins de la moitié des personnes interrogées (49 %) ont indiqué que leur organisation appliquait déjà l’intelligence artificielle (IA) aux tests d’applications. 21 % prévoient d’appliquer l’IA dans les six prochains mois. Près des trois quarts (74 %) ont déclaré que le sentiment général de leur organisation à l’égard de l’IA dans les tests de développement de logiciels mobiles était positif.</p>'}, {'', ""<p>Les personnes interrogées s'attendent également à ce que l'IA améliore la qualité des applications mobiles (37 %), augmente la productivité (36 %), améliore l'expérience de l'utilisateur final (34 %) et réduise le nombre de vulnérabilités et/ou de bugs (32 %) dans leurs applications.</p>""}, {'', '<p>Mav Turner, responsable des produits et de la stratégie chez Tricentis, a déclaré que plutôt que de continuer à s’appuyer sur des services de test coûteux, de plus en plus d’organisations cherchent à réduire leurs coûts en automatisant une plus large gamme de flux de travail de test dans le cadre d’un flux de travail DevOps. En fait, l’enquête révèle qu’un peu moins d’un tiers des répondants (32 %) s’attendent à ce que leur organisation investisse plus d’un million de dollars pour automatiser davantage les tests.</p>'}, {'', '<p>À mesure que la modernisation des processus de test se poursuit, le retour sur investissement dans le développement d’applications mobiles ne fera que s’améliorer, a noté Turner.</p>'}, {'', ""<p>L'enquête identifie les principaux avantages de l'investissement dans l'automatisation des tests, à savoir une productivité accrue (32 %), une augmentation des revenus (31 %), une rétention accrue des utilisateurs (28 %) et une compatibilité accrue entre les appareils (28 %).</p>""}, {'', ""<p>Les principaux obstacles rencontrés par les organisations lorsqu'elles s'efforcent d'atteindre cet objectif sont les priorités concurrentes (28 %), le manque de technologie et de talent (25 %), le temps (25 %) et le coût (24 %), selon l'enquête.</p>""}, {'', '<p>87 % des personnes interrogées ont déclaré que la qualité des applications mobiles était essentielle à leur activité, et 90 % ont indiqué qu’une mauvaise qualité des applications mobiles leur coûtait jusqu’à 2,49 millions de dollars de pertes de revenus par an. Cependant, un peu plus d’un quart (27 %) ont déclaré qu’ils estimaient que la stratégie actuelle de développement et de test des applications mobiles de leur organisation dépassait les attentes.</p>'}, {'', '<p>Dans le cadre des efforts d’automatisation des tests, on ne sait pas exactement dans quelle mesure la responsabilité des tests est transférée aux développeurs, mais il ne fait aucun doute que de plus en plus de personnes sont exposées aux résultats plus tôt dans le cycle de vie du développement logiciel. L’objectif est de fournir des capacités de test en continu sans perturber excessivement l’écriture du code. Il devient également plus simple pour les développeurs d’exploiter des outils d’IA générative pour fournir des résumés de tests ainsi que des recommandations pour améliorer le code. Le résultat final devrait être des applications de meilleure qualité qui nécessitent moins de dépannage une fois déployées dans un environnement de production.</p>'}, {'', '<p>Dans le même temps, alors que les organisations continuent de dépendre de plus en plus des applications mobiles pour mener un large éventail d’initiatives de transformation numérique, le coût des tests continuera d’être dérisoire par rapport au montant potentiel des pertes de revenus qui pourraient survenir lorsque les utilisateurs finaux n’invoquent pas une fonctionnalité ou une capacité spécifique ou, plus généralement, abandonnent tout simplement l’application.</p>'}]"
L'essor du low-code/no-code dans DevOps,"[{'', '<p>L’évolution constante du paysage technologique a entraîné un changement de paradigme dans le développement et le déploiement de logiciels. L’une des principales tendances qui gagne du terrain est l’intégration de plateformes low-code/no-code au sein de l’écosystème DevOps. Cet article explore la manière dont ces plateformes révolutionnent la manière dont les applications sont développées, déployées et gérées, favorisant la collaboration entre les développeurs et les équipes opérationnelles.</p>'}, {'', '<p>1. Démocratiser le développement :</p>'}, {'', ""<p>Les plateformes low-code/no-code permettent aux personnes ayant une expérience limitée en codage de participer activement au processus de développement d'applications. Cette démocratisation du développement accélère la livraison de logiciels en permettant aux analystes commerciaux, aux concepteurs et à d'autres non-développeurs, parfois appelés développeurs citoyens, de contribuer directement à la création d'applications.</p>""}, {'', '<p>2. Accélération du délai de mise sur le marché :</p>'}, {'', ""<p>Le cycle de vie traditionnel du développement logiciel implique souvent de longs processus de codage, ce qui entraîne des retards dans la publication des versions. Les plateformes low-code/no-code permettent un prototypage et un développement rapides grâce à des interfaces visuelles, réduisant ainsi considérablement le temps nécessaire pour faire passer les applications du concept à la production. Cette accélération s'aligne sur les principes de DevOps, favorisant une livraison continue et une mise sur le marché plus rapide.</p>""}, {'', '<p>3. Améliorer la collaboration :</p>'}, {'', ""<p>DevOps vise à éliminer les silos et à favoriser la collaboration entre les équipes de développement et d'exploitation. Les plateformes low-code/no-code comblent le fossé entre ces rôles traditionnellement distincts en fournissant un terrain d'entente où les parties prenantes techniques et non techniques peuvent collaborer de manière transparente. Cet environnement collaboratif favorise une meilleure communication, une meilleure compréhension et un meilleur alignement des objectifs.</p>""}, {'', '<p>4. Flexibilité dans le déploiement :</p>'}, {'', ""<p>Les solutions low-code/no-code sont conçues pour être indépendantes de la plateforme, ce qui permet le déploiement d'applications dans différents environnements, y compris sur site et dans le cloud. Cette flexibilité s'aligne sur le principe DevOps de l'infrastructure en tant que code (IaC), permettant aux équipes de déployer et de gérer des applications de manière cohérente sur diverses infrastructures.</p>""}, {'', '<p>5. Réduire la dépendance aux compétences spécialisées :</p>'}, {'', ""<p>Dans un environnement DevOps, il est essentiel de réduire les goulots d'étranglement et les dépendances vis-à-vis d'individus ou de rôles spécifiques. Les plateformes low-code/no-code permettent aux équipes d'être plus autonomes, réduisant ainsi la dépendance à l'égard de compétences de codage spécialisées ou de formations DevOps. Cela contribue à son tour à une culture DevOps plus résiliente et adaptable.</p>""}, {'', '<p>6. Défis et considérations :</p>'}, {'', '<p>L’adoption du low-code/no-code dans DevOps apporte de nombreux avantages, mais elle présente également des défis. Cette section aborde des considérations telles que la sécurité, l’évolutivité et le besoin potentiel de personnalisation au-delà des capacités de la plateforme.</p>'}, {'', ""<p>7. Cas d'utilisation réels\xa0:</p>""}, {'', ""<p>Découvrez des exemples concrets d'organisations qui ont intégré avec succès le low-code/no-code dans leurs workflows DevOps. Mettez en évidence les résultats positifs, les leçons apprises et l'impact sur leur cycle de vie global de développement logiciel.</p>""}, {'', '<p>Conclusion:</p>'}, {'', '<p>L’essor des plateformes low-code/no-code dans DevOps remodèle la manière dont les logiciels sont développés et déployés. En favorisant la collaboration, en accélérant les cycles de développement et en réduisant les dépendances vis-à-vis des compétences spécialisées, ces plateformes s’alignent parfaitement sur les principes de DevOps. Alors que les entreprises continuent d’adopter cette tendance, la synergie entre low-code/no-code et DevOps est sur le point de redéfinir l’avenir de la distribution d’applications.</p>'}]"
Oracle cherche à accélérer le rythme de l'innovation Java,"[{'', '<p>Avec la dernière version de Java, il devrait devenir plus simple pour les équipes DevOps qui créent et déploient des applications avec le langage de programmation le plus utilisé dans l’entreprise d’innover plus rapidement.</p>'}, {'', ""<p>Georges Saab, vice-président senior d'Oracle Java Platform, a déclaré que Java 22 est unique dans l'histoire de Java dans le sens où il est spécifiquement conçu pour permettre aux développeurs d'invoquer des fonctionnalités disponibles en version bêta et en préversion tout en continuant à travailler avec les autres fonctions prises en charge dans le vénérable langage de programmation. L'objectif global est d'accélérer le rythme de l'innovation dans les environnements basés sur les applications Java, a-t-il ajouté.</p>""}, {'', ""<p>La dernière édition du Java Development Kit (JDK), par exemple, donne accès en avant-première aux fonctionnalités développées dans le cadre d'une initiative du projet Amber qui simplifie l'expression de chaînes qui incluent des valeurs calculées lors de l'exécution tout en améliorant la sécurité des programmes qui composent des chaînes à partir de valeurs fournies par l'utilisateur et les transmettent à d'autres systèmes.</p>""}, {'', ""<p>Parallèlement, une initiative du projet Loom, également disponible en version préliminaire, rationalise la gestion et l'annulation des erreurs d'une manière qui améliore l'observabilité à l'aide d'une interface de programmation d'application (API) qui permet une concurrence structurée, tandis qu'une capacité Scoped Values \u200b\u200boffre un moyen de partager des données immuables au sein et entre les threads.</p>""}, {'', ""<p>Une initiative du projet Panama ajoute une API vectorielle qui promet de compiler des instructions au moment de l'exécution lorsque, par exemple, on utilise des techniques de génération augmentée de récupération (RAG) pour étendre les modèles d'intelligence artificielle (IA).</p>""}, {'', ""<p>En termes de fonctionnalités supplémentaires désormais généralement prises en charge, Java 22 ajoute une API pour permettre aux programmes Java d'interagir en toute sécurité avec le code et les données exécutés en mémoire en dehors de l'environnement d'exécution Java.</p>""}, {'', ""<p>Plus important encore, du point de vue des performances des applications, la dernière itération du langage rationalise les processus de collecte des déchets en mémoire pour réduire le nombre de fois où une application Java pourrait autrement avoir besoin d'être mise en pause.</p>""}, {'', ""<p>Malgré le nombre de langages de programmation alternatifs existants, la majorité des applications d'entreprise continuent d'être développées en Java. Si de nombreux développeurs connaissent au moins plusieurs langages de programmation, la plupart ont tendance à privilégier un seul langage de programmation principal. Les développeurs Java, en particulier, ont montré peu d'envie d'abandonner ce langage, même si d'autres langages de programmation, tels que JavaScript, sont apparus et sont soit plus simples à utiliser, soit, comme dans le cas de Rust, peuvent offrir des capacités de sécurité plus robustes.</p>""}, {'', '<p>Il est moins évident de savoir à quel rythme les développeurs mettent à niveau leurs applications vers la dernière version. Dans certains cas, les développeurs utilisent encore la version 8, 11 ou, plus récemment, 17. Il faudra peut-être un certain temps avant que la majorité des développeurs Java soient prêts à passer à Java 22. En outre, les équipes DevOps devront alors décider quand la masse critique sera suffisante pour justifier la mise à niveau des environnements d’exécution afin de prendre en charge une autre itération de Java.</p>'}, {'', '<p>D’une manière ou d’une autre, que ce soit via une édition de Java fournie par Oracle ou un autre fournisseur, le langage de programmation n’est pas prêt d’être supplanté. Le défi consiste désormais à fournir un support non seulement pour les différentes versions de Java qui peuvent être exécutées, mais aussi, inévitablement, pour tous les autres artefacts logiciels écrits dans différents langages qui circulent désormais également régulièrement dans les pipelines DevOps.</p>'}]"
Du chaos à la clarté : rationaliser DevSecOps à l'ère numérique,"[{'', '<p>De nos jours, sécuriser le cycle de vie du développement logiciel de bout en bout nécessite que les organisations déploient, maintiennent et maîtrisent un mélange cacophonique d’outils qui contribuent souvent davantage à créer des discordes qu’à apporter de l’harmonie aux processus DevSecOps. La raison en est simple : chaque outil utilisé pour sécuriser une chaîne d’approvisionnement logicielle exécute indépendamment des analyses et génère des alertes qui manquent de contexte, sont souvent redondantes ou se contredisent totalement.</p>'}, {'', '<p>Les développeurs et les ingénieurs logiciels qui prennent en charge ces applications doivent bien entendu corréler les flux constants d’alertes et traiter les vulnérabilités afin d’atteindre les seuils de sécurité requis pour propager la version dans un environnement en amont. La réalité est que toutes les vulnérabilités signalées comme élevées et critiques ne nécessitent pas d’être corrigées, et qu’il n’est pas non plus possible pour une équipe de traiter toutes les vulnérabilités. En moyenne, une équipe de développement a la capacité de traiter 10 % de son backlog de vulnérabilités au cours d’un mois donné. Il est donc impératif de prioriser le backlog de vulnérabilités en fonction de l’impact plutôt que de la gravité si nous voulons donner à ces équipes de développement une chance de réussir à améliorer leur posture de sécurité.</p>'}, {'', ""<p>Les alertes constantes provoquent également de la fatigue et introduisent un risque réel de faux négatifs. Celui qui s'est échappé !</p>""}, {'', ""<p>Les flux de travail DevSecOps d'aujourd'hui ne sont guère plus que des sections d'un orchestre jouant sans partition avec l'espoir qu'une méthodologie permettant de verrouiller systématiquement une chaîne d'approvisionnement logicielle se manifestera comme par magie.</p>""}, {'', '<p>Ce qui manque évidemment, c’est un cadre d’orchestration qui déclenche le flux de travail de sécurité en réponse aux changements au sein du SDLC. Idéalement, il fonctionne de manière transparente avec les flux de travail CI/CD, mais sans en dépendre, créant ainsi une symphonie capable de fournir une meilleure posture de sécurité pour l’organisation.</p>'}, {'', '<h3>Le problème avec DevSecOps</h3>'}, {'', '<p>Dans les environnements de développement d’applications cloud natifs basés sur des microservices, les équipes peuvent développer à l’aide de plusieurs technologies, chacune optimisée pour fournir un service spécifique. Chaque technologie peut nécessiter un outil d’analyse spécialisé, et il ne s’agit là que du code. Lorsque nous ajoutons à l’ensemble le binaire, le pipeline d’infrastructure, les données et l’identité, nous nous retrouvons avec une vaste gamme d’outils et un énorme ensemble de politiques par rapport auxquelles chaque changement doit être évalué.</p>'}, {'', '<p>Oui, vous pouvez analyser les conteneurs régulièrement avant de les déployer en production et cela peut être acceptable si vous déployez une version par mois. Cependant, même dans ce cas, vous pourriez affirmer qu’au moment où les vulnérabilités sont détectées, il est trop tard et vous avez déjà perdu la bataille de l’efficacité.</p>'}, {'', '<p>La raison pour laquelle vous avez opté pour une architecture basée sur les microservices est qu’elle est facile à mettre à l’échelle et rapide à créer et à déployer. Idéalement, vous souhaitez publier rapidement des fonctionnalités pour vos clients. Cela implique un degré de changement très élevé, ce qui signifie que l’évaluation ponctuelle que vous avez effectuée ne sera tout simplement pas adaptée à l’objectif en termes de protection de vos actifs. Chaque validation est susceptible d’exposer un nouveau risque, qui peut finir par être découvert trop tard s’il est laissé aux évaluations ponctuelles.</p>'}, {'', ""<p>En revanche, si la sécurité est orchestrée de manière transparente et asynchrone via des interfaces indépendantes des outils dans vos pipelines CI/CD, en fournissant les résultats requis pour sécuriser vos actifs numériques depuis le premier engagement jusqu'aux déploiements de production et au-delà, vous avez véritablement adopté DevOps. Dans ce scénario, chaque changement est évalué en temps réel et son impact est projeté sur le développement, les opérations et la sécurité avec un appel à l'action clair.</p>""}, {'', '<p>Cette approche fournit également un cadre plus extensible et évolutif pour les organisations à mesure qu’elles progressent dans leur parcours d’adoption de DevSecOps.</p>'}, {'', '<h3>Résumé</h3>'}, {'', ""<p>Aucune équipe de développement ne décide délibérément de créer et de déployer une application non sécurisée. La raison pour laquelle les applications présentant des vulnérabilités connues sont déployées si souvent est que la charge cognitive associée à leur découverte et à leur correction est tout simplement trop élevée. Le développeur moyen ne peut consacrer que 10 à 20 % de son temps à la correction des vulnérabilités. Le reste de son temps est consacré soit à l'écriture de nouveau code, soit à la maintenance de l'environnement de développement d'applications utilisé pour écrire ce code. Si les entreprises veulent des applications plus sécurisées, elles doivent trouver des moyens de permettre aux développeurs de corréler, de hiérarchiser et de contextualiser facilement les vulnérabilités au fur et à mesure de leur identification. La plupart du temps, lorsque les développeurs sont informés qu'une vulnérabilité a été découverte dans leur code, ils ont depuis longtemps perdu le contexte.</p>""}, {'', '<p>Les vulnérabilités doivent être immédiatement identifiées au moment de l’écriture du code, de la création des builds et de l’exécution des demandes d’extraction, et identifiées de manière à pouvoir être exploitées. Sinon, cette vulnérabilité risque de se retrouver au sommet de l’énorme pile de dettes techniques que les développeurs espèrent avoir le temps de traiter un jour.</p>'}, {'', '<p>À ce stade, ce n’est qu’une question de temps avant que les gouvernements du monde entier adoptent des lois qui obligeront les organisations à davantage se responsabiliser en matière de sécurité des logiciels qu’elles créent et déploient. Les équipes DevSecOps avisées reconnaissent déjà que les approches existantes de gestion des flux de travail DevSecOps devront être repensées pour répondre à ces exigences. Le défi et l’opportunité à présent sont de mettre en place un cadre d’orchestration de sécurité évolutif qui élimine les frictions dans les flux de travail DevSecOps et améliore l’efficacité grâce à des évaluations en temps réel, garantissant que votre logiciel est sécurisé par défaut.</p>'}]"
Il est temps d'étendre la visibilité DevOps à la périphérie du réseau,"[{'', '<p>Les problèmes de performances déroutent régulièrement les équipes DevOps après le déploiement d’une application, malgré le nombre de tests effectués avant le déploiement. Après une étude plus approfondie, le problème le plus souvent négligé est la nature distribuée de l’application elle-même. Les utilisateurs finaux qui accèdent aux applications à partir de plusieurs emplacements ne bénéficieront jamais du même niveau de service Internet. Ainsi, les logiciels qui fonctionnent parfaitement dans des endroits qui sont des pôles technologiques urbains majeurs, tels que New York, San Francisco ou Londres, n’offriront pas nécessairement la même expérience dans des régions plus éloignées, en particulier dans les zones rurales situées à l’autre bout du monde.</p>'}, {'', ""<p>Tous les services Internet ne sont pas égaux. Les problèmes de latence intermittente du réseau peuvent avoir un impact profond sur les performances des applications, simplement en raison des lois de la physique. Plus un utilisateur final est éloigné du centre de données où l'application est hébergée, plus il est probable que la latence du réseau affecte négativement les performances de l'application.</p>""}, {'', '<p>Malheureusement, la plupart des équipes DevOps n’ont aucune visibilité au-delà de l’environnement du centre de données où l’application est exécutée. Naturellement, la première étape pour obtenir ce niveau de visibilité commence à la périphérie du réseau.</p>'}, {'', '<h3>Visibilité de la pile Internet</h3>'}, {'', '<p>Une pile Internet est composée d’une large gamme de services, chacun pouvant avoir un impact négatif sur les performances des applications distribuées. Des réseaux privés virtuels (VPN) aux réseaux de diffusion de contenu (CDN) en passant par les serveurs et commutateurs DNS (Domain Name System), tous ces éléments ajoutent une latence qui, selon la manière dont le trafic réseau est acheminé, peut avoir un impact majeur sur les performances des applications. Chacun de ces services peut subir une panne ou, plus difficile à détecter, des dégradations intermittentes qui ont un impact imprévisible sur les performances des applications. Qu’il s’agisse d’une application SaaS (Software-as-a-Service) accessible dans le cloud ou d’une plateforme IoT (Internet des objets) exécutée à la périphérie du réseau, pour identifier le service Internet qui pourrait être à l’origine d’un problème, il faut pouvoir surveiller et observer de près ce trafic.</p>'}, {'', '<p>Sans visibilité sur la pile Internet, il devient impossible de faire émerger les informations nécessaires pour fournir le contexte nécessaire à l’optimisation et au dépannage d’une application spécifique. Tout le temps et les efforts consacrés à la création d’une application peuvent être vains simplement parce que personne n’a compris l’impact que la latence du réseau aurait sur l’application avant son déploiement. Même après le déploiement d’une application, tout changement dans la façon dont le trafic réseau est acheminé peut avoir des conséquences majeures. Sans aucun moyen de comprendre les changements qui ont pu se produire, il peut s’écouler des semaines ou des mois avant qu’une organisation se rende compte qu’elle doit enregistrer une demande de service ou changer de fournisseur de services.</p>'}, {'', '<p>Toute approche véritablement globale de l’observabilité doit clairement inclure une analyse des services Internet dont les organisations dépendent de manière cruciale pour garantir une expérience applicative cohérente. Selon la structure de l’équipe informatique, ces informations peuvent être intégrées dans une plateforme d’observabilité adoptée par l’organisation ou corrélées à l’aide d’une plateforme de surveillance des performances Internet (IPM).</p>'}, {'', '<h3>DevOps a besoin de NetOps</h3>'}, {'', '<p>Quelle que soit l’approche adoptée, il n’a jamais été aussi crucial pour les équipes d’exploitation réseau (NetOps) et DevOps de pouvoir aligner leurs approches de surveillance des environnements informatiques distribués. De plus en plus d’applications sensibles à la latence sont déployées. Dans un monde idéal, les équipes DevOps travaillant en étroite collaboration avec NetOps devraient être en mesure de provisionner et de modifier par programmation les services réseau selon les besoins. Tous les services Internet ne peuvent pas être ajustés via une interface de programmation d’application (API), mais la plupart des équipes NetOps ont accès à des consoles qui leur permettent de passer à différents niveaux de service si nécessaire. Au minimum, un fournisseur de services travaillera avec elles pour effectuer les modifications nécessaires.</p>'}, {'', '<p>Bien entendu, il devient plus difficile de négocier si l’équipe NetOps ne sait pas quel élément de la pile Internet doit être mis à niveau. Un fournisseur de services qui n’a généralement aucune visibilité sur l’application peut passer des semaines à essayer de déterminer quel élément de la pile Internet qu’il gère est en cause. Les équipes informatiques qui disposent de leurs propres moyens de surveillance d’un ensemble de services Internet seront en mesure de collaborer avec leurs fournisseurs de services pour résoudre ces problèmes beaucoup plus rapidement.</p>'}, {'', '<h3>Résumé</h3>'}, {'', ""<p>Les équipes informatiques les plus avisées sont parfaitement conscientes de la vulnérabilité des services Internet aux pannes et aux baisses de tension. Elles ont donc tendance à s'assurer que le trafic réseau peut être redirigé d'un service à un autre. Cette approche présente également l'avantage supplémentaire de conserver une certaine marge de manœuvre en matière de prix lorsqu'elles négocient les tarifs des services fournis.</p>""}, {'', '<p>Il convient également de garder à l’esprit que les fournisseurs de services réseau qui savent qu’un client est lié à un fournisseur ne sont peut-être pas aussi motivés à s’assurer que les services réseau fonctionnent à une efficacité optimale. La seule façon pour une équipe informatique de savoir quel niveau de service est fourni à un moment donné est, bien sûr, de générer un rapport IPM qui détaille précisément quels services étaient réellement disponibles à quel niveau de performance. Sinon, ils dépendent entièrement du rapport qu’un fournisseur de services présente avec sa facture mensuelle.</p>'}, {'', '<p>Les rapports générés par une plateforme IPM font également ressortir des informations qui, une fois présentées aux développeurs d’applications, créent une opportunité potentielle d’optimisation de leur code. Sans ce niveau d’analyse, chaque développeur supposera que les services réseau sont soit défaillants, soit mal gérés. Le défi et l’opportunité sont désormais de fournir des informations sur les performances Internet d’une manière que chaque partie prenante ne peut pas simplement utiliser mais, tout aussi crucialement, à laquelle elle doit faire implicitement confiance.</p>'}]"
L'informatique de pointe nécessite DevOps à grande échelle,"[{'', '<p>L’essor de l’informatique de pointe est sur le point de favoriser une convergence tant attendue des meilleures pratiques en matière de DevOps, d’ingénierie des données, de sécurité, de réseau, de technologie opérationnelle (OT) et d’opérations d’apprentissage automatique (MLOps), ce qui rendra à terme les équipes informatiques plus réactives que jamais aux besoins de l’entreprise.</p>'}, {'', ""<p>Historiquement, chacune de ces disciplines informatiques a eu tendance à travailler de manière isolée, avec des transferts délibérés entre les différentes équipes chargées de fournir et de maintenir divers services. Le défi est que, à mesure que de plus en plus d'applications sont déployées à la périphérie du réseau, les équipes informatiques doivent travailler main dans la main. Les applications doivent non seulement être déployées dans un environnement informatique beaucoup plus distribué, mais elles doivent également être régulièrement mises à jour et corrigées.</p>""}, {'', '<p>Parallèlement, des volumes croissants de données sont traités et analysés au point de collecte et de consommation. De plus en plus d’applications dynamiques exécutées à la périphérie du réseau transmettent des données d’analyse agrégées aux applications exécutées dans le cloud ou dans un environnement informatique sur site. Cette évolution nécessite une approche fondamentalement différente de la gestion du stockage dans les différents environnements informatiques de périphérie et les différents systèmes back-end fédérés de l’entreprise.</p>'}, {'', '<p>Les entreprises doivent généralement stocker leurs fichiers localement sur des plateformes de calcul en périphérie de réseau, tout en stockant des copies de ces fichiers dans le cloud à l’aide d’un service de stockage compatible S3 qui permet d’accéder à un stockage basé sur des objets peu coûteux pour permettre tout, de la protection des données à la gestion d’applications d’intelligence artificielle (IA). Cette capacité multiprotocole crée une opportunité non seulement de créer de nouvelles applications distribuées avec état, mais également de moderniser les applications existantes, quels que soient les protocoles utilisés pour stocker les données.</p>'}, {'', '<p>La plupart des plateformes informatiques de pointe sont aujourd’hui gérées par des équipes OT qui dépendent directement des dirigeants d’unités commerciales spécifiques. Cependant, à mesure que ces plateformes sont de plus en plus connectées aux réseaux, il devient impératif de les gérer de manière centralisée dans le cadre de tout effort visant à réduire le coût total de l’informatique. Après tout, l’élément le plus coûteux de l’informatique reste le coût de la main-d’œuvre nécessaire à sa gestion.</p>'}, {'', ""<p>Naturellement, le partage de données en temps quasi réel dans un environnement informatique distribué exerce une pression accrue sur les équipes d'exploitation réseau (NetOps). Au lieu de mettre à jour les applications par lots une fois par jour, les données diffusées en continu depuis des milliers de plates-formes informatiques de pointe doivent être synchronisées avec plusieurs applications pour faire apparaître les informations les plus récentes et les plus précises.</p>""}, {'', '<p>Le plus difficile est que la plupart de ces données sont utilisées pour former des modèles d’IA qui nécessitent en fin de compte le déploiement du moteur d’inférence associé créé à la périphérie. Pour traiter des téraoctets de données, la plateforme sous-jacente requise pour prendre en charge ces moteurs d’inférence devra également être mesurée en téraoctets. Au fil du temps, les modèles d’IA ont tendance à dériver ou, dans le cas de l’IA générative, à devenir complètement illusoires. Les data scientists devront travailler en étroite collaboration avec les équipes DevOps pour remplacer ces modèles d’IA car, contrairement à une application traditionnelle, ils ne peuvent pas être mis à jour via un correctif. L’ensemble du modèle d’IA doit être remplacé par un modèle qui est non seulement plus fiable, mais aussi, et tout aussi important, plus sûr.</p>'}, {'', '<p>Enfin, la nécessité de sécuriser les plateformes de calcul en périphérie est tout simplement cruciale. Les cybercriminels ont tendance à considérer ces plateformes comme des passerelles vers le reste de l’entreprise. Chaque nouvelle plateforme de calcul en périphérie déployée étend la taille de la surface d’attaque à défendre. À moins que les équipes de cybersécurité ne soient profondément impliquées dans la création et le déploiement d’applications et de plateformes de calcul en périphérie, la question n’est pas de savoir si une faille se produira, mais plutôt quand elle se produira.</p>'}, {'', '<p>Il faudra peut-être un certain temps avant que ces différents fiefs informatiques ne convergent, mais à ce stade, cela est presque inévitable. En fait, il sera bientôt difficile de faire la distinction entre l’informatique de pointe et le reste de l’environnement informatique, car les applications pilotées par événements sur plusieurs plates-formes deviendront davantage la norme que l’exception.</p>'}, {'', '<p>Les équipes DevOps, dans le cadre de leur engagement incessant en faveur de l’automatisation, devraient naturellement être à l’avant-garde de ces efforts. Plutôt que de limiter les principes DevOps à la manière dont les applications sont créées et déployées, le moment est clairement venu d’automatiser les flux de travail informatiques de bout en bout. La seule façon de gérer l’informatique de pointe à grande échelle par programmation est d’appliquer également les principes DevOps à grande échelle. Également connue sous le nom d’ingénierie de plateforme, cette approche permet aux organisations de gérer des environnements informatiques distribués à grande échelle sans avoir à embaucher une petite armée d’équipes informatiques pour tout gérer. Il y aura toujours un besoin d’expertise spécialisée, mais à mesure que l’informatique continue d’évoluer, les silos qui ralentissent le rythme de l’innovation devront disparaître.</p>'}, {'', '<p>Tous les membres d’une organisation informatique n’ont pas besoin de savoir gérer de manière experte chaque tâche, mais ils doivent être familiarisés avec les dépendances inhérentes qui existent entre les applications, le réseau, le stockage et la cybersécurité pour faire progresser les objectifs des entreprises qui n’ont jamais été aussi dépendantes de l’informatique.</p>'}, {'', '<p>Chaque organisation doit déterminer le rythme de convergence qui correspond le mieux à ses besoins, mais plus elle se produit rapidement, plus le retour sur investissement dans l’edge computing sera important. Le défi et l’opportunité, comme toujours, seront de gérer une nouvelle transition informatique majeure, où les problèmes à résoudre sont autant culturels que techniques.</p>'}]"
Comment l'IA générative permet des plateformes de tests continus unifiées,"[{'', '<p>Il est temps de disposer d’une plateforme de tests continus unifiée.</p>'}, {'', ""<p>Les plateformes et outils de test de logiciels existants sont spécialisés dans les activités de test pour un sous-ensemble des différentes étapes des flux de valeur. Le paysage des outils de test de logiciels comprend une large gamme de solutions, chacune avec ses points forts, axées sur des aspects spécifiques du développement, de la livraison et de l'exploitation des logiciels.</p>""}, {'', ""<p>Par exemple\xa0:• Les outils de test unitaire se concentrent sur les premières étapes du développement, permettant aux développeurs de tester des unités de code individuelles pour en vérifier l'exactitude.• Les outils de test d'intégration visent à tester les interactions entre différents modules ou services au sein d'une application.• Les outils de test système sont conçus pour tester de bout en bout l'ensemble du système avant sa mise en service.• Les outils de test de performance évaluent le comportement de l'application dans des conditions de charge et de stress.• Les outils de test de sécurité se concentrent sur l'identification des vulnérabilités au sein de l'application.• Les outils de test d'acceptation utilisateur (UAT) facilitent la phase de test finale, où les utilisateurs finaux valident la solution par rapport à leurs exigences.</p>""}, {'', ""<p>Le défi consistant à réunir ces différents besoins de test au sein d'une seule plateforme de tests continus est multiple. Une telle plateforme doit s'intégrer de manière transparente à une grande variété d'outils et d'environnements de développement, prendre en charge différentes méthodologies de test et être suffisamment flexible pour s'adapter à différents processus organisationnels et normes de qualité.</p>""}, {'', '<p>Bien qu’il existe des outils d’intégration continue/déploiement continu (CI/CD) qui intègrent plusieurs étapes de test, ils le font souvent en s’intégrant à des outils de test spécialisés plutôt qu’en proposant eux-mêmes une solution de test unifiée. Ces outils CI/CD sont plus proches de l’orchestration des différentes activités de test plutôt que de leur unification sous les capacités d’une seule plateforme.</p>'}, {'', '<p>Cependant, le concept d’une plateforme de tests continus entièrement unifiée, couvrant toutes les étapes, depuis les exigences jusqu’au déploiement et aux tests en production, représente une opportunité significative d’innovation dans le domaine des outils de développement logiciel. Pour y parvenir, il faudrait probablement tirer parti des avancées dans des domaines tels que l’IA générative, comme indiqué dans mon précédent blog Application de l’IA/ML aux tests continus pour créer des processus de test adaptables et intelligents capables de couvrir l’ensemble des besoins de test de manière cohérente.</p>'}, {'', ""<h3>Avantages d'une plateforme de tests continus unifiée</h3>""}, {'', ""<p>Efficacité et rapidité améliorées : une plateforme de test unifiée intègre les tests à toutes les étapes du cycle de vie du développement logiciel (SDLC), ce qui simplifie considérablement le processus de test. Cette intégration facilite les boucles de rétroaction automatisées et continues qui identifient et corrigent rapidement les défauts, permettant aux équipes de développement d'itérer et d'améliorer rapidement. En conséquence, les équipes peuvent publier de nouvelles fonctionnalités et correctifs plus rapidement, ce qui accélère la mise sur le marché du produit et améliore la réactivité aux besoins des clients et aux évolutions du marché.</p>""}, {'', ""<p>Qualité et fiabilité améliorées : en garantissant des tests complets et cohérents sur l'ensemble de l'application, une plateforme de test unifiée joue un rôle crucial dans l'identification et l'atténuation des problèmes au début du cycle de développement. Cette détection précoce permet de maintenir un niveau élevé de qualité et de fiabilité du logiciel, ce qui accroît la satisfaction et la confiance des utilisateurs dans le produit. L'application cohérente des normes de qualité à toutes les phases de test contribue à la robustesse et à la fiabilité du produit logiciel.</p>""}, {'', ""<p>Économies de coûts et maintenance réduite : l'automatisation du processus de test via une plateforme CT unifiée optimise non seulement l'utilisation des ressources, mais réduit également considérablement les coûts associés aux tests manuels et à la correction des défauts à un stade avancé. La détection précoce des défauts se traduit par des coûts de réparation inférieurs et le processus rationalisé réduit le délai global de mise sur le marché. De plus, les logiciels fiables et de haute qualité nécessitent moins de maintenance, ce qui réduit encore les coûts à long terme et libère des ressources pour les efforts d'innovation et de développement.</p>""}, {'', ""<p>Collaboration améliorée entre les équipes : une plateforme CT unifiée favorise une culture de collaboration et de transparence entre les équipes de développement, de test et d'exploitation. En fournissant un cadre et des outils communs pour toutes les activités de test, elle élimine les silos et permet une communication et une collaboration transparentes tout au long du cycle de développement logiciel. Cette collaboration améliorée garantit que les équipes sont alignées sur les objectifs du projet, peuvent partager leurs idées plus efficacement et travailler ensemble pour identifier et résoudre les problèmes plus efficacement, ce qui conduit à de meilleurs résultats.</p>""}, {'', '<p>Ensemble, ces avantages soulignent comment une plateforme de tests continus unifiée peut transformer le processus de développement logiciel, le rendant plus efficace, rentable et collaboratif tout en garantissant la livraison de produits logiciels fiables et de haute qualité.</p>'}, {'', '<p>Bien que de nombreux outils traitent de parties spécifiques du cycle de vie des tests, la vision d’une plateforme unique qui unifie de manière transparente toutes les étapes des tests, de la définition des exigences à la production, reste un objectif ambitieux. Il s’agit d’une lacune dans le paysage technologique actuel qui présente à la fois un défi et une opportunité de développement futur.</p>'}, {'', '<h3>Défis pour les plateformes de tests continus unifiées</h3>'}, {'', ""<p>Créer une plateforme de tests continus qui unifie les activités de test pour toutes les étapes du flux de valeur de bout en bout est un défi complexe en raison de plusieurs facteurs :1. Diversité des technologies et des outils : les environnements de développement de logiciels modernes sont très divers, intégrant divers langages de programmation, cadres et technologies. Créer une plateforme qui s'intègre parfaitement à toutes ces technologies est un défi.2. Points d'intégration complexes : les tests continus doivent s'intégrer à plusieurs étapes du pipeline de développement, notamment le développement, le déploiement et les opérations. Chacune de ces étapes peut utiliser des outils et des processus différents, ce qui rend difficile la création d'une solution unique.3. Variables des mesures de qualité : différentes équipes et différents projets peuvent avoir différentes définitions de la qualité, des critères de réussite et des mesures de performance. Une plateforme de tests unifiée doit être hautement personnalisable pour répondre à ces différents besoins.4. Gestion du changement : l'adoption d'une nouvelle plateforme nécessite des changements dans les processus et les flux de travail de l'organisation. La résistance au changement est courante dans les organisations, et la transition vers une nouvelle façon de tester peut être accueillie avec scepticisme et inertie.5. Évolutivité et performances : garantir que la plateforme puisse évoluer pour répondre aux besoins de test des grandes organisations avec des milliers de tests exécutés simultanément est un défi technique. Les problèmes de performances peuvent devenir un goulot d'étranglement, affectant l'efficacité globale du processus de développement. 6. Sécurité et conformité : l'intégration des tests à toutes les étapes du développement introduit également des défis de sécurité et de conformité. La plateforme doit garantir que les données sensibles sont protégées et que les pratiques de test sont conformes aux exigences réglementaires. 7. Contraintes de coûts et de ressources : le développement, la maintenance et la prise en charge d'une plateforme de tests continus unifiée nécessitent un investissement important. Les organisations peuvent hésiter à engager les ressources nécessaires sans preuve claire du retour sur investissement. 8. Évolution des pratiques : les pratiques et les outils de développement de logiciels évoluent constamment. Maintenir la plateforme à jour avec les dernières pratiques et technologies nécessite des efforts et une innovation continus.</p>""}, {'', ""<p>Malgré ces défis, la valeur des tests continus tout au long du cycle de développement logiciel est de plus en plus reconnue. Certaines entreprises et communautés open source progressent dans cette direction, en créant des solutions de test plus intégrées et plus flexibles. Cependant, la mise en place d'une plateforme entièrement unifiée qui réponde à tous ces défis est un effort continu et représente une opportunité significative d'innovation dans le secteur du développement et des tests de logiciels.</p>""}, {'', ""<h3>L'IA générative peut faciliter une plateforme de tests continus unifiée</h3>""}, {'', ""<p>L’IA générative peut jouer un rôle important pour surmonter les défis associés à la création d’une plateforme de tests continus qui unifie les activités de test pour toutes les étapes du flux de valeur de bout en bout. Voici comment l’IA générative peut relever chacun des défis :1. Diversité des technologies et des outils : l’IA générative peut être formée sur un large éventail de langages de programmation, de cadres et de technologies pour comprendre et générer du code ou des scripts de test. Cette capacité lui permet de s’adapter à différents environnements et de créer des supports de test compatibles avec divers outils et technologies.2. Points d’intégration complexes : l’IA peut analyser le flux de travail des pipelines de développement et suggérer des points d’intégration optimaux pour les tests. En apprenant à partir de différentes configurations CI/CD (intégration continue/déploiement continu), l’IA peut recommander les meilleures pratiques pour intégrer les tests de manière transparente dans les flux de travail existants.3. Différentes mesures de qualité : les modèles d’IA générative peuvent être personnalisés pour comprendre et appliquer différentes mesures de qualité et différents critères de réussite en fonction des exigences spécifiques du projet. En s’entraînant sur divers ensembles de données, ces modèles peuvent s’adapter à diverses définitions de la qualité et générer des tests ou des analyses pertinents.4. Français : Gestion du changement : l'IA peut aider au processus de gestion du changement en simulant les résultats de l'adoption de nouvelles plateformes de test, offrant ainsi des avantages fondés sur des preuves et atténuant la résistance au changement. De plus, les analyses pilotées par l'IA peuvent mettre en évidence les gains d'efficacité et les améliorations de qualité pour soutenir la transition. 5. Évolutivité et performances : l'IA générative peut optimiser les processus de test en identifiant les redondances et en suggérant des améliorations, améliorant ainsi les performances. En outre, l'IA peut allouer dynamiquement des ressources en fonction des besoins de test, garantissant l'évolutivité sans compromettre l'efficacité. 6. Sécurité et conformité : les modèles d'IA peuvent être formés pour identifier et signaler les problèmes potentiels de sécurité et de conformité dans le processus de test. En apprenant en permanence des dernières normes de sécurité et réglementations de conformité, l'IA peut contribuer à garantir que les pratiques de test répondent aux exigences nécessaires. 7. Contraintes de coûts et de ressources : en automatisant la génération et l'optimisation des cas de test, l'IA générative peut réduire considérablement l'effort manuel requis, réduisant ainsi les coûts et les demandes de ressources. L'IA peut également aider à hiérarchiser les efforts de test en fonction de l'évaluation des risques, garantissant que les ressources sont concentrées là où elles sont le plus nécessaires. Évolution des pratiques : les modèles d'IA générative sont intrinsèquement adaptables et peuvent apprendre en permanence des nouvelles pratiques de développement, des nouveaux outils et des nouvelles technologies. Cela garantit que la plateforme de test reste à jour avec les dernières avancées en matière de développement logiciel.</p>""}, {'', '<p>L’IA générative a le potentiel de transformer les tests continus en fournissant des solutions adaptatives, efficaces et intelligentes aux défis complexes de l’unification des activités de test sur l’ensemble du flux de valeur de bout en bout. Cependant, la réalisation de ce potentiel nécessite une conception minutieuse, une formation approfondie des modèles d’IA et une gestion continue pour garantir que les systèmes d’IA restent efficaces et adaptés à l’évolution des besoins en matière de tests.</p>'}, {'', ""<h3>Résumé : Appel à l'action</h3>""}, {'', '<p>La nécessité d’une plateforme de tests continus (CT) unifiée n’a jamais été aussi urgente. Les plateformes de tests actuelles, chacune experte dans son domaine, ne couvrent que des fragments du cycle de vie du développement logiciel (SDLC), ce qui conduit à un processus de test décousu et inefficace. Cette fragmentation ralentit non seulement le développement et les livraisons, mais compromet également la qualité et la sécurité du produit final. Le rêve d’une plateforme unique qui intègre de manière transparente toutes les étapes des tests, des exigences au déploiement et aux tests en production, représente un bond monumental vers l’efficacité, la sécurité et la qualité du développement logiciel.</p>'}, {'', '<p>Les défis liés à la création d’une telle plateforme sont multiples, allant de la diversité des technologies et des outils à la nature évolutive des pratiques de développement logiciel. Chaque défi, de l’intégration de technologies diverses et de la gestion du changement au sein des organisations à la garantie de l’évolutivité et de la conformité, ajoute de la complexité au développement d’une plateforme de test unifiée. Pourtant, les avantages potentiels de surmonter ces obstacles sont immenses, promettant une amélioration significative de la vitesse et de la qualité de la livraison des logiciels. La reconnaissance de ces avantages par l’industrie est de plus en plus grande, comme en témoignent les efforts de certaines entreprises et communautés open source qui évoluent vers des solutions de test plus intégrées et plus flexibles.</p>'}, {'', '<p>L’IA générative apparaît comme une lueur d’espoir dans cette quête, offrant des solutions innovantes aux défis multiformes de l’unification des activités de test. En exploitant la puissance de l’IA générative, l’industrie peut faire face à la diversité des outils, intégrer des étapes de test complexes, s’adapter à des mesures de qualité variables, gérer les changements organisationnels, évoluer efficacement, garantir la sécurité et la conformité et évoluer avec les pratiques de développement logiciel. La voie à suivre nécessite un effort concerté, mais les investissements dans les innovations en matière de tests pilotés par l’IA peuvent concrétiser la vision d’une plateforme de tests complète, unifiée et continue. Il ne s’agit pas seulement d’une opportunité d’amélioration, mais d’un appel à l’action pour que l’industrie redéfinisse l’avenir des plateformes d’ingénierie.</p>'}]"
Cognition Labs présente Devin AI Software Engineer,"[{'', ""<p>Cognition Labs, une startup dotée de 21 millions de dollars de financement, a présenté cette semaine ce qu'elle décrit comme le premier logiciel d'ingénierie au monde, surnommé Devin, basé sur l'intelligence artificielle (IA).</p>""}, {'', ""<p>Devin est capable de répondre à des commandes textuelles et peut se voir confier des tâches telles que l'évaluation des performances d'une application. Il élaborera ensuite un plan et configurera les outils requis à l'aide de sa propre interface de ligne de commande (CLI), d'un éditeur de code et d'un navigateur grâce auxquels il pourra accéder, lire et comprendre, par exemple, la documentation à l'aide d'un moteur de raisonnement et d'une capacité de planification à long terme basée sur les avancées de l'apprentissage par renforcement.</p>""}, {'', ""<p>Ces capacités permettent à Devin, par exemple, de créer un site Web, d'identifier et de corriger de manière autonome les bogues dans les bases de code, de déployer des applications et même de former d'autres modèles d'IA.</p>""}, {'', ""<p>Selon Cognition Labs, une évaluation comparative de Devin, utilisant un outil SWE-bench qui demande aux agents de résoudre des tâches, a révélé que Devin résolvait correctement 13,86 % des problèmes de bout en bout, dépassant de loin l'état de l'art précédent de 1,96 %. Même en leur donnant les fichiers exacts à éditer, les meilleurs modèles précédents ne pouvaient résoudre que 4,80 % des problèmes.</p>""}, {'', '<p>Mark Hinkle, PDG de Peripety Labs, une société de conseil, a déclaré qu’il était trop tôt pour dire quand Devin pourrait être prêt à être utilisé dans les environnements informatiques d’entreprise, mais les démonstrations ont montré à quel point les progrès rapides de l’IA sont sur le point de transformer la manière dont les logiciels sont créés et construits. L’expérience utilisateur est sensiblement différente de celle de GitHub Copilot ou de CodeWhisperer d’Amazon Web Services (AWS), qui se concentrent davantage sur l’aide aux développeurs pour écrire du code plutôt que sur l’exécution de tâches assignées, a-t-il noté.</p>'}, {'', '<p>On ne sait pas exactement quelle infrastructure est nécessaire pour exécuter Devin, ce qui, compte tenu de la pénurie actuelle d’unités de traitement graphique (GPU), pourrait s’avérer être un facteur limitant l’adoption, du moins à court terme, a ajouté Hinkle.</p>'}, {'', '<p>Indépendamment des capacités actuelles de Devin, auxquelles les ingénieurs logiciels ne peuvent accéder que sur invitation pour le moment, il est clair que les avancées dans les capacités de raisonnement des modèles d’IA permettront aux équipes DevOps d’assigner des tâches à un modèle d’IA comme elles le feraient avec n’importe quel autre membre de leur équipe. L’impact de cette capacité sur la demande d’ingénieurs logiciels reste à voir, mais il reste nécessaire de comprendre ce qu’il faut demander à Devin de créer et de vérifier comment les logiciels qu’il crée ont été construits. La seule chose qui est sûre, c’est que le rythme auquel les logiciels peuvent être créés et déployés est sur le point de s’accélérer.</p>'}, {'', '<p>Il ne fait aucun doute que Microsoft, AWS et d’autres fournisseurs d’outils d’ingénierie logicielle recherchent des capacités similaires. Ce n’est donc peut-être qu’une question de temps avant que les avancées en matière de raisonnement et de planification à long terme ne soient largement appliquées au développement de logiciels.</p>'}, {'', '<p>En attendant, les équipes DevOps pourraient vouloir réévaluer leurs plans stratégiques pour les années à venir, car il devient plus facile de créer des logiciels. Des projets qui auraient pu nécessiter de grandes équipes d’ingénieurs logiciels pourraient bientôt être réalisés par des équipes beaucoup plus petites. En retour, le nombre de projets de développement de logiciels qui pourraient être lancés par des organisations de toutes tailles augmentera à mesure que le travail traditionnellement requis continuera à être éliminé.</p>'}]"
CircleCI ajoute une capacité d'orchestration de versions à sa plateforme CI/CD,"[{'', ""<p>CircleCI a ajouté aujourd'hui une capacité d'orchestration des versions à sa plate-forme d'intégration continue/livraison continue (CI/CD) du même nom pour donner aux développeurs plus de contrôle sur les déploiements d'applications.</p>""}, {'', ""<p>Selon Rob Zuber, directeur technique de CircleCI, la fonctionnalité de publication de CircleCI permet aux équipes de développement de publier un sous-ensemble contrôlé de leur code dans un environnement de production en direct, de manière à fournir un retour immédiat sur les performances de ce code. Ce niveau de visibilité peut ensuite être utilisé pour déterminer si ce code doit être restauré à l'aide d'outils d'automatisation intégrés à la plateforme CI/CD de CircleCI, a-t-il ajouté.</p>""}, {'', '<p>En l’absence de cette capacité, a noté Zuber, il faut en moyenne aux équipes DevOps 45 minutes à une heure pour restaurer manuellement une application.</p>'}, {''}, {'', ""<p>Les premières plateformes prises en charge par les versions de CircleCI sont Kubernetes et Amazon SageMaker. Les versions de CircleCI sont également compatibles avec la plateforme open source Argo CD avec laquelle CircleCI a intégré sa plateforme l'année dernière.</p>""}, {'', '<p>CircleCI prévoit également d’ajouter la prise en charge des déploiements bleu-vert plus tard cette année, permettant aux équipes DevOps de déployer une version d’application plus progressivement pour en remplacer une autre.</p>'}, {'', '<p>La gestion de la continuité des activités varie souvent considérablement d’une organisation à l’autre. Dans les secteurs hautement réglementés, la continuité des activités est généralement gérée par une équipe centrale afin de garantir le respect des exigences de conformité. Dans d’autres cas, les développeurs sont directement responsables de la création et du déploiement de leur code. Quelle que soit l’approche, CircleCI permet aux organisations de définir un ensemble de garde-fous pour garantir le respect des meilleures pratiques, a noté Zuber. En effet, chaque organisation peut mettre en œuvre un ensemble de contrôles et d’équilibres adaptés à ses besoins spécifiques, a-t-il ajouté.</p>'}, {'', '<p>À mesure que DevOps continue d’évoluer, de plus en plus d’entreprises souhaitent pouvoir contrôler les déploiements à un niveau plus précis, par exemple en ne mettant à disposition qu’un nombre limité d’utilisateurs une nouvelle application ou une mise à jour. Une fois déployée, les développeurs ont besoin d’une vue plus globale non seulement sur les performances de l’application, mais aussi sur son impact sur l’entreprise, a déclaré Zuber. Si, par exemple, le nombre de connexions diminue après une mise à jour, un développeur a besoin de ces informations pour déterminer si cette mise à jour doit être annulée le plus rapidement possible, a-t-il ajouté.</p>'}, {'', '<p>Il n’est pas certain que de nombreuses organisations gèrent l’intégralité du flux de travail CI/CD de bout en bout. Si la plupart des équipes DevOps utilisent largement le CI pour créer une application, le déploiement des applications est encore souvent géré manuellement. Cependant, à mesure que les fonctionnalités de CD deviennent plus simples à utiliser sur les plateformes dotées d’interfaces standard, le nombre d’organisations automatisant le CD devrait augmenter régulièrement. En fait, cette capacité s’avérera bientôt essentielle car, grâce à l’essor de l’intelligence artificielle générative (IA), le rythme auquel les applications sont créées ne cesse de s’accélérer.</p>'}, {'', ""<p>En attendant, chaque organisation devra déterminer dans quelle mesure elle souhaite intégrer les flux de travail CI et CD. Cependant, plus ces processus seront étroitement intégrés, plus il sera simple pour les développeurs d'assumer l'entière responsabilité de la création et de la maintenance des logiciels qu'ils créent.</p>""}]"
L'outil CLI Flox simplifie la gestion des environnements de développement personnalisés,"[{'', ""<p>Flox a rendu aujourd'hui disponible au grand public une interface de ligne de commande (CLI) open source pour un outil homonyme qui permet aux développeurs de créer plus facilement plusieurs environnements de développement personnalisés.</p>""}, {'', ""<p>Dans le même temps, la société a révélé lors de la 21e édition annuelle de la Southern California Linux Expo (SCALE 21) qu'elle fournissait désormais l'accès à FloxHub, un référentiel gratuit permettant de partager des environnements de développement entre équipes.</p>""}, {'', ""<p>Flox est basé sur le même framework déclaratif utilisé pour invoquer l'outil de gestion et de configuration de paquets Nix. Il permet aux développeurs de créer des environnements contenant tout ce dont ils ont besoin pour créer des logiciels, y compris la création automatique d'une nomenclature logicielle (SBOM).</p>""}, {'', ""<p>Ross Turk, responsable du marketing et des relations avec les développeurs pour Flox, a déclaré que cette approche fournit aux développeurs un cadre pour gérer plusieurs environnements de développement qu'ils peuvent créer en utilisant les mêmes méthodes couramment utilisées pour invoquer les gestionnaires de packages au lieu de devoir maîtriser une approche moins familière pour gérer les environnements de développement, a-t-il ajouté.</p>""}, {'', ""<p>Cette fonctionnalité permet aux développeurs de répliquer plus facilement les environnements de développement sur plusieurs machines et, si nécessaire, de basculer de manière dynamique entre les projets d'une manière qui peut être contrôlée en permanence par une équipe DevOps centralisée. Au lieu d'exiger qu'une équipe DevOps applique le même environnement standard rigide à tous les projets de développement, chaque développeur est toujours libre de personnaliser son environnement en fonction de ses préférences personnelles.</p>""}, {'', '<p>De plus, les développeurs qui tentent de corriger un bug peuvent désormais facilement reproduire l’environnement de développement qu’ils utilisaient au moment où ils écrivaient le code qu’ils devaient réviser.</p>'}, {''}, {'', '<p>Les équipes DevOps se retrouvent de plus en plus souvent coincées entre des agendas concurrents. De nombreux responsables informatiques encouragent l’adoption de méthodologies d’ingénierie de plateforme pour centraliser la gestion des workflows DevOps dans l’espoir d’augmenter la productivité des développeurs et de réduire les coûts totaux. En théorie, les développeurs préféreraient que davantage de processus back-end soient gérés par ces équipes, mais pas au point de les obliger à utiliser un environnement de développement qui a été défini pour eux. Chaque développeur préfère généralement personnaliser son environnement de développement au fur et à mesure de l’évolution du projet.</p>'}, {'', '<p>L’une des principales raisons pour lesquelles les développeurs adoptent DevOps est sans doute qu’il leur donne plus de contrôle sur leurs environnements de développement. Le problème est que, lorsque chaque équipe définit son propre flux de travail DevOps, les organisations découvrent souvent plus tard qu’elles utilisent des licences pour des outils et des plateformes DevOps redondants.</p>'}, {'', '<p>En attendant, on ne sait pas vraiment dans quelle mesure l’ingénierie de plateforme pourrait améliorer la productivité des développeurs. Elle réduira sans aucun doute le temps que les développeurs passent à gérer les processus back-end, mais ce temps supplémentaire n’équivaut pas directement à un code de meilleure qualité livré plus rapidement. L’écriture de code est autant un art qu’une science, elle crée donc des niveaux d’inspiration qui ne se produisent pas toujours lorsqu’un développeur commence à écrire du code. Au lieu de cela, l’ingénierie de plateforme crée plus d’opportunités pour que l’inspiration surgisse, car les développeurs ne passent pas de temps sur d’autres tâches. Au minimum, elle devrait offrir plus de temps pour exécuter des tests sur le code produit.</p>'}, {'', ""<p>D'une manière ou d'une autre, à mesure que le développement des applications continue d'évoluer, la plupart des organisations trouveront le compromis qui répondra le mieux à leurs besoins. Le défi consiste désormais à réduire le temps qui s'écoule entre le moment où cet objectif est finalement atteint.</p>""}]"
Le poids de l’IaC sur les épaules de DevOps,"[{'', '<p>Il est souvent difficile pour les entreprises technologiques établies d’adopter des pratiques DevOps modernes autour de l’infrastructure en tant que code (IaC). Il ne s’agit pas tant d’adopter la syntaxe, mais plutôt la culture DevOps dont l’IaC fait partie pour les organisations d’ingénierie.</p>'}, {'', '<p>Les organisations ont souvent du mal à passer des modèles d’exploitation traditionnels à une culture DevOps collaborative, qui est un sous-produit de la transition des opérations d’infrastructure vers le code.</p>'}, {'', ""<p>Dans de nombreux cas, les tendances héritées persistent, tandis que les tâches IaC restent cloisonnées au sein des équipes DevOps centrées sur les opérations, ce qui est l'exact opposé des avantages de l'exploitation de technologies puissantes comme l'infrastructure en tant que code. Cela crée en fin de compte des goulots d'étranglement dans la vitesse de développement et l'itération du produit.</p>""}, {'', '<p>Avec tout cela à l’esprit, la question se pose : quels changements peuvent permettre un parcours IaC plus fluide ?</p>'}, {'', '<p>Le fait que les équipes DevOps assument l’intégralité de la charge IaC est exactement l’anti-modèle que nous cherchons à éviter lors de la véritable transition vers la culture DevOps dans nos organisations. De nombreuses organisations commencent à rencontrer ces problèmes familiers qui commencent à émerger :</p>'}, {'', ""<h3>1.) Les lacunes en matière de connaissances s'élargissent</h3>""}, {'', ""<p>Les développeurs, de par leur métier d'ingénieur logiciel, manquent souvent d'accès, de visibilité et de contexte sur les changements d'infrastructure. Pourtant, avec de plus en plus de besoins en matière d'infrastructures qui se déplacent vers la gauche, ils se retrouvent (jeu de mots voulu) avec des capacités insuffisantes pour gérer ces besoins croissants.</p>""}, {'', ""<p>Cette situation est encore plus compliquée lorsqu'ils sont confrontés à des autorisations cloud minimales. Les autorisations limitées rendent difficile l'expérimentation et la familiarisation avec les outils et fonctionnalités du cloud, comme ils le feraient avec le code et ses parties de la pile.</p>""}, {'', '<p>Parallèlement, les équipes DevOps, qui sont le reflet exact de leur rôle au sein de l’organisation, ne saisissent pas les besoins et les objectifs des applications. Cela se traduit souvent par un fossé grandissant de communication et de collaboration autour des initiatives IaC.</p>'}, {'', '<h3>2.) La collaboration en pâtit</h3>'}, {'', ""<p>Un outil courant qui aggrave le problème est la plateforme de gestion des tickets et d'assistance. Les développeurs, en raison de leur mode opératoire, n'ayant pas de compréhension commune du domaine, ont souvent recours à l'ouverture de tickets pour atteindre leurs objectifs. Cela crée une culture de communication inefficace entre les équipes via les systèmes de gestion des tickets.</p>""}, {'', '<p>Cela ne signifie pas que les plateformes de billetterie sont le problème, cela entraîne simplement des méthodes de communication inefficaces, car les développeurs ne savent pas toujours quelles questions poser.</p>'}, {'', '<p>Cela signifie que les ingénieurs DevOps fonctionnent en grande partie à l’instinct, ignorant généralement les exigences réelles des applications qui ne peuvent pas toutes être communiquées dans un simple ticket Jira. Cela se traduit par des solutions finales qui satisfont rarement les besoins dès la première tentative et prennent plus de temps à livrer.</p>'}, {'', '<h3>3.) Libération lente à rampante</h3>'}, {'', ""<p>Les équipes DevOps sont chargées de mener et d'orchestrer l'ingénierie des versions, en plus de la mise à disposition des environnements, de la maintenance, de la surveillance et d'autres tâches qui relèvent du domaine de l'ingénierie DevOps.</p>""}, {'', ""<p>C'est pourquoi les tâches DevOps peuvent devenir un goulot d'étranglement, car elles dictent non seulement le calendrier de déploiement (en raison de considérations importantes concernant le temps de disponibilité et les perturbations des clients, entre autres), mais sont également chargées de jongler avec les changements d'infrastructure dans de nombreux environnements multiples.</p>""}, {'', ""<p>Cela entraîne des retards imprévisibles dans la mise en place des environnements de développement et d'autres tâches orientées vers les développeurs qui frustrent les développeurs et bloquent les mises à jour de production et la vitesse de livraison.</p>""}, {'', ""<p>Reconnaître ces inefficacités et transférer ces responsabilités vers d'autres systèmes est devenu la méthode la plus courante pour les responsables DevOps de répartir les tâches IaC. Cela a permis aux développeurs d'acquérir suffisamment d'autonomie pour choisir les solutions adaptées à leurs besoins, tandis que les équipes DevOps ont fourni des conseils et une supervision sur la manière de mettre en œuvre concrètement ces solutions.</p>""}, {'', '<p>Cependant, comme tout glissement vers la gauche, cette évolution s’accompagne de son lot de défis uniques. L’adoption du paradigme DevOps se heurte à des obstacles fondamentaux qui ajoutent des complications et une complexité supplémentaires à ces transitions culturelles, notamment :</p>'}, {'', ""<li>L'étalement urbain incontrôlé</li>""}, {'', '<li>Coûts de la montgolfière</li>'}, {'', '<li>Problèmes de sécurité</li>'}, {'', '<p>D’une part, la répartition de la charge IaC allège la charge des équipes DevOps, mais l’inconvénient est qu’il devient difficile de comprendre quelles ressources sont réellement utilisées et lesquelles ont été créées temporairement à des fins de test.</p>'}, {'', ""<p>De nombreux propriétaires créent des ressources à la demande. Une fois qu'elles ne sont plus nécessaires, ces restes créent une confusion autour des dépendances et rendent les plateformes cloud désorganisées et difficiles à entretenir.</p>""}, {'', ""<p>Tout comme le fait de permettre à davantage de personnes de toucher à l'IaC entraîne une prolifération et un désordre accrus, un plus grand nombre d'utilisateurs avec une gouvernance réduite favorise également une prolifération insouciante en termes de coûts. Cela se traduit souvent par une accumulation de ressources en double et inutilisées, un gaspillage de budgets actuellement serrés, et chaque centime compte. En l'absence d'automatisation et de supervision, les environnements deviennent désordonnés et coûteux.</p>""}, {'', '<p>Les problèmes d’étalement peuvent également avoir un impact sur la sécurité, car l’extension des autorisations soulève des problèmes de sécurité valables qui s’intensifient lorsque les clouds deviennent désorganisés et difficiles à entretenir.</p>'}, {'', '<p>Les développeurs bien intentionnés peuvent mal configurer les ressources ou exposer des systèmes sensibles. Sans méthodes appropriées pour gérer les dérives ou les erreurs de configuration, cela peut représenter de réels risques pour les organisations et les systèmes. Un autre aspect important qui augmente également avec une surveillance réduite est le risque interne intentionnel.</p>'}, {'', '<p>OK, cela a dû être vraiment décourageant – et vous pensez probablement que vous devriez fuir avant de tenter une quelconque transition vers une responsabilité partagée.</p>'}, {'', '<p>Mais ne paniquez pas encore. Il est possible pour les équipes de redistribuer les responsabilités IaC tout en évitant ces pièges.</p>'}, {'', '<p>Vous trouverez ci-dessous quelques facteurs clés pour vous aider à rendre la transition plus fluide à court et à long terme\xa0:</p>'}, {'', '<li>Automatisez tout : si les pratiques DevOps nous ont appris quelque chose, c’est que la maintenance manuelle de l’environnement cloud n’est pas évolutive. L’automatisation a été l’épine dorsale d’une grande partie de l’évolution que nous avons connue en matière d’exploitation de l’infrastructure, et cela a été alimenté par la programmabilité et l’état d’esprit « tout en tant que code », de l’IaC à la politique en tant que code (PaC). Cette optimisation basée sur l’automatisation permet de réduire les ressources négligées grâce à des analyses et des réponses régulières et automatisées. Vous obtenez ainsi des économies de coûts et la prévention de l’étalement incontrôlable.</li>'}, {'', '<li>Renforcer l’autonomie grâce à la gouvernance – Vous vous souvenez de l’automatisation et de la gouvernance dont nous avons parlé ? L’application programmatique des politiques est un bon moyen de limiter la prolifération indésirable des ressources sans intervention manuelle. La gouvernance intervient pour gérer la correction automatique des erreurs de configuration ou d’autres anti-modèles qui ne correspondent pas aux politiques automatisées, ce qui simplifie la gestion de l’environnement à grande échelle. Il est important de noter que la gouvernance, si elle est bien mise en œuvre, peut être un outil permettant de responsabiliser les équipes, de briser les silos et d’encourager l’autonomie. La mise en place de garde-fous appropriés permet d’instaurer la confiance et de fournir des orientations utiles.</li>'}, {'', ""<li>Le contrôle d'accès basé sur les rôles (RBAC) limite les autorisations aux besoins appropriés, établissant des garde-fous importants qui peuvent aider à prévenir certains des problèmes dont nous avons parlé ci-dessus, notamment l'étalement urbain et les problèmes de sécurité.</li>""}, {'', ""<p>Le RBAC permettra aux développeurs d'obtenir la liberté nécessaire tout en minimisant les risques de sécurité. L'accès minimum requis encourage la responsabilité et la contrainte.</p>""}, {'', '<p>Maintenant que vous maîtrisez bien les principes, il est temps de les mettre en pratique !</p>'}, {'', ""<p>Heureusement, de nombreuses solutions sont à votre disposition. Vous pouvez vous lancer et les créer vous-même à l'aide d'outils performants comme Jenkins ou Atlantis.</p>""}, {'', ""<p>Alternativement, pour une approche plus globale, il existe d'excellents outils commerciaux de gestion IaC sur le marché. Ceux-ci peuvent vous aider à atteindre vos objectifs rapidement et avec une plus grande efficacité.</p>""}, {'', ""<p>À mesure que la complexité technologique augmente, aucune équipe ne peut gérer seule l'infrastructure. Les équipes de développement et d'exploitation doivent unir leurs compétences pour piloter les systèmes modernes et le code sous-jacent qui les alimente. Cela nécessite de combler les lacunes en matière de connaissances grâce à la collaboration et à la communication.</p>""}, {'', '<p>Grâce à un processus réfléchi, à l’automatisation de l’IaC, à des garde-fous de gouvernance et à des politiques d’accès appropriées, les dirigeants technologiques peuvent guider cette transition culturelle en douceur sans exposer l’organisation à des risques et des dépenses inutiles.</p>'}, {'', '<p>Si elle est bien menée, la responsabilité partagée de l’IaC augmentera la vélocité, l’agilité et l’autonomie, le trio de caractéristiques cruciales qui quantifient et qualifient les équipes d’ingénierie d’élite et différencient les entreprises dans un paysage concurrentiel.</p>'}, {'', '<p>Vous souhaitez en savoir plus sur env0 pour gérer votre IaC à grande échelle et en toute confiance ?</p>'}, {'', '<p>Arrêtez-vous au stand L12 à KubeCon EU pour parler à un expert ou voir une démonstration\xa0!</p>'}, {'', ""<p>Pour en savoir plus sur les sujets liés au cloud natif, rejoignez la Cloud Native Computing Foundation, le groupe Techstrong et l'ensemble de la communauté cloud native à Paris, en France, lors du KubeCon+CloudNativeCon EU 2024, du 19 au 22 mars 2024.</p>""}]"
Apprentissage automatique dans les tests prédictifs pour les environnements DevOps,"[{'', '<p>Dans le monde technologique actuel, en constante évolution, DevOps fait désormais partie intégrante du développement logiciel. Il met l’accent sur la collaboration, l’automatisation, l’intégration continue (CI) et la livraison continue (CD) pour améliorer la vitesse et la qualité du déploiement des logiciels. Les tests prédictifs sont un élément clé de ce paysage, où l’apprentissage automatique (ML) joue un rôle central.</p>'}, {'', ""<p>En exploitant les algorithmes ML, les tests prédictifs peuvent prévoir les problèmes potentiels, automatiser les processus de test et optimiser les stratégies de test, améliorant ainsi l'efficacité et la fiabilité des pratiques DevOps.</p>""}, {'<h3>Machine Learning : transformer les stratégies de test</h3>', ''}, {'', ""<p>Le ML a révolutionné les méthodes de test traditionnelles en introduisant des algorithmes adaptatifs capables d'apprendre à partir des données. Cette évolution permet la génération de cas de test dynamiques, l'analyse en temps réel et l'analyse prédictive.</p>""}, {'', '<p>Une étude de Gartner prévoit que d’ici 2025, les tests basés sur l’IA réduiront de 70 % le temps nécessaire à la génération et à l’exécution des tests. De telles avancées représentent un bond en avant majeur en matière d’efficacité des tests, ouvrant la voie à des solutions logicielles plus sophistiquées et plus fiables.</p>'}, {'', '<h3>Analyse prédictive et tests basés sur les risques</h3>'}, {'', ""<p>L'analyse prédictive dans les tests consiste à analyser les données historiques pour anticiper les problèmes futurs. Cette approche hiérarchise les efforts de test en fonction de la probabilité et de l'impact des défaillances potentielles.</p>""}, {'', '<p>Par exemple, un rapport de Capgemini souligne que l’analyse prédictive peut améliorer les taux de détection des défauts jusqu’à 45 %. Les équipes DevOps peuvent allouer les ressources plus efficacement en se concentrant sur les domaines à haut risque, garantissant ainsi que les problèmes critiques sont résolus rapidement.</p>'}, {""<h3>Optimiser l'automatisation des tests avec ML</h3>"", ''}, {'', ""<p>Les algorithmes ML excellent dans l'optimisation des stratégies d'automatisation des tests. Ces algorithmes peuvent adapter et améliorer les scripts de test en apprenant en continu à partir de nouvelles données, réduisant ainsi l'intervention manuelle.</p>""}, {'', '<p>Selon une étude réalisée par State of DevOps, les entreprises qui adoptent le ML pour l’automatisation des tests obtiennent un taux de réussite des changements supérieur de 45 %. Cette amélioration accélère le cycle de développement et réduit les risques d’erreurs se propageant en production.</p>'}, {'', '<h3>Rétroaction et apprentissage continus</h3>'}, {'', ""<p>L'un des piliers de DevOps est le feedback et l'amélioration continus. Le ML facilite cela en analysant constamment les résultats des tests pour affiner et améliorer les stratégies de test.</p>""}, {'', ""<p>Une étude récente de Forrester a révélé que les tests continus avec intégration du ML peuvent réduire le cycle de rétroaction jusqu'à 80 %. Ce mécanisme de rétroaction rapide permet aux équipes d'identifier et de corriger rapidement les problèmes, garantissant ainsi un pipeline de livraison de logiciels robuste et fiable.</p>""}, {""<h3>L'IA dans les tests de logiciels : une révolution</h3>"", ''}, {'', '<p>L’intégration de l’IA dans les tests logiciels est une révolution pour les environnements DevOps. Les algorithmes d’IA peuvent analyser de vastes quantités de données provenant de différentes étapes du processus de développement pour identifier des modèles et des anomalies. Cette capacité améliore la capacité à prédire les échecs et à automatiser les réponses.</p>'}, {'', '<p>Une étude d’IBM révèle que les tests améliorés par l’IA peuvent augmenter les taux de détection des défauts jusqu’à 30 %, améliorant ainsi considérablement la qualité globale des produits logiciels.</p>'}, {'', '<h3>Améliorer la collaboration et la communication avec ML dans DevOps</h3>'}, {'', '<p>La synergie entre ML et DevOps va au-delà des simples tests. Elle améliore considérablement la collaboration et la communication au sein des équipes. Les outils d’analyse basés sur le ML peuvent surveiller et analyser les modèles de communication, identifier les goulots d’étranglement et les domaines à améliorer. Par exemple, en utilisant le traitement du langage naturel, le ML peut catégoriser et hiérarchiser les problèmes en fonction de leur urgence et de leur pertinence, simplifiant ainsi le processus de prise de décision. Il en résulte un flux de travail plus cohérent et plus efficace, dans lequel les équipes peuvent anticiper les défis et coordonner leurs efforts plus efficacement.</p>'}, {'', '<p>Une étude menée par McKinsey suggère que les équipes qui exploitent l’IA et le ML dans leurs stratégies de communication constatent une augmentation de 20 % de la vitesse d’exécution des projets.</p>'}, {''}, {'', '<h3>Maintenance prédictive dans le déploiement de logiciels</h3>'}, {'', '<p>La maintenance prédictive, un concept emprunté à l’industrie manufacturière, gagne désormais du terrain dans DevOps. En appliquant des algorithmes de ML pour surveiller l’état des systèmes logiciels, les équipes DevOps peuvent prédire et prévenir les pannes potentielles du système avant qu’elles ne se produisent. Cette approche déplace l’accent de la maintenance réactive vers la maintenance proactive, minimisant les temps d’arrêt et améliorant la satisfaction des utilisateurs. Par exemple, le ML peut analyser les journaux et les mesures de performance pour identifier des modèles indiquant des problèmes futurs.</p>'}, {'', '<h3>Considérations éthiques et bonnes pratiques dans le DevOps piloté par ML</h3>'}, {'', '<p>Alors que le ML continue de s’imposer dans les environnements DevOps, les considérations éthiques et les meilleures pratiques doivent être prises en compte. Il est essentiel de veiller à ce que les algorithmes de ML soient transparents, impartiaux et conformes aux normes éthiques. Les équipes DevOps doivent être conscientes des problèmes de confidentialité des données et des risques potentiels associés à la prise de décision automatisée. L’établissement de lignes directrices pour une utilisation éthique du ML dans DevOps est essentiel pour maintenir la confiance et l’intégrité dans le processus de développement logiciel. Les leaders du secteur comme l’IEEE ont commencé à rédiger des lignes directrices éthiques pour l’IA et le ML dans le développement logiciel, soulignant l’importance d’un déploiement responsable et éthique de l’IA dans DevOps.</p>'}, {'', ""<h3>L'avenir de DevOps : les tests pilotés par l'IA</h3>""}, {'', '<p>À l’avenir, le rôle du ML dans les tests prédictifs devrait croître de manière exponentielle. À mesure que les algorithmes deviennent plus sophistiqués, ils offriront des informations plus approfondies et des prévisions plus précises, rationalisant ainsi davantage le processus DevOps. L’intégration de l’IA et du ML dans les tests n’est pas seulement une tendance, mais un changement fondamental dans la façon dont nous abordons la qualité et la fiabilité des logiciels dans les environnements DevOps.</p>'}, {'', '<p>À mesure que nous progressons, la convergence de l’IA et du ML avec les pratiques DevOps continuera d’évoluer, ouvrant de nouvelles possibilités et établissant des normes plus élevées pour le développement et le déploiement de logiciels.</p>'}]"
appCD lance une plateforme pour provisionner en toute sécurité une infrastructure cloud,"[{'', ""<p>appCD a lancé cette semaine une plateforme homonyme qui analyse une application sur le point d'être déployée pour générer automatiquement le code nécessaire à la mise en service de l'infrastructure informatique requise.</p>""}, {'', ""<p>Fraîchement sorti d'une levée de fonds de 6 millions de dollars en financement d'amorçage, le PDG d'appCD, Sachin Aggarwal, a déclaré que cette approche permet de créer systématiquement du code sécurisé pour l'approvisionnement de l'infrastructure informatique au lieu de demander aux développeurs avec peu ou pas de cybersécurité de l'écrire manuellement.</p>""}, {'', ""<p>Au lieu de cela, appCD examine le code Python ou Java pour comprendre l'intention, identifie les dépendances, puis déduit l'interface de programmation d'application (API), la configuration du service, l'entrée/sortie et d'autres variables d'environnement. Le code Terraform ou les graphiques Helm sont ensuite générés automatiquement sur la base de l'analyse statique du code qui a été renforcée à l'aide de techniques d'apprentissage par intelligence artificielle (IA).</p>""}, {'', ""<p>Cette approche permet également aux équipes d'ingénierie de la plateforme de gérer plus facilement de manière centralisée la mise en place de l'infrastructure informatique à l'aide d'un ensemble de politiques prédéfinies qui sont automatiquement mises en œuvre à chaque fois qu'une application est déployée pour garantir la sécurité par défaut, a-t-il ajouté.</p>""}, {'', ""<p>Les équipes DevOps peuvent également utiliser appCD pour visualiser l'environnement de déploiement avant et après le déploiement d'une application, a déclaré Aggarwal.</p>""}, {'', ""<p>Si les outils d'infrastructure en tant que code (IaC) ont accéléré la vitesse à laquelle l'infrastructure cloud peut être provisionnée, ils sont également souvent à l'origine des problèmes de sécurité qui affligent les environnements de cloud computing. Les développeurs configurent souvent mal l'infrastructure cloud, par exemple en laissant des ports ouverts par inadvertance. La plateforme appCD réduit le risque de telles erreurs, a noté Aggarwal.</p>""}, {'', ""<p>Cette capacité élimine également la nécessité d'attacher des spécialistes en cybersécurité à une équipe DevOps, car les problèmes sont automatiquement résolus par les garde-fous appliqués par appCD, a-t-il ajouté.</p>""}, {'', '<p>En théorie, du moins, il se pourrait bien qu’un jour l’IA améliore systématiquement la qualité du code utilisé pour créer et déployer des applications. Plus le code utilisé pour entraîner un modèle de langage étendu (LLM) est vérifié, plus le résultat devient fiable. En attendant, des plateformes telles qu’appCD combinent l’analyse statique avec l’apprentissage par renforcement de l’IA pour atteindre le même objectif dans un cas d’utilisation spécifique à la génération de code pour provisionner l’infrastructure informatique.</p>'}, {'', '<p>Chaque équipe DevOps devra naturellement déterminer la meilleure voie à suivre, mais à mesure que les réglementations relatives à la sécurisation des chaînes d’approvisionnement de logiciels deviennent plus strictes, ce n’est qu’une question de temps avant que les organisations soient obligées d’adopter les flux de travail DevSecOps. En attendant, les équipes DevOps doivent partir du principe qu’étant donné la probabilité que l’infrastructure cloud ait été mal configurée, il est presque certain qu’il y aura plusieurs incidents de sécurité cloud. En fait, les cybercriminels recherchent activement les erreurs de configuration qu’ils ont déjà créées pour les exploiter spécifiquement en quelques minutes.</p>'}, {'', '<p>En l’absence de moyens pour empêcher l’apparition de tous ces problèmes, la priorité immédiate est de remédier au plus grand nombre de problèmes possible avant que les cybercriminels n’exploitent ces vulnérabilités. Cependant, il est également important de tracer une ligne dans le sable pour garantir que toutes les infrastructures cloud qui seront mises en place à l’avenir seront beaucoup plus sécurisées qu’elles ne l’ont été jusqu’à présent.</p>'}]"
