Titres H1:
Comment apprendre Kubernetes (feuille de route compl√®te et ressources)
Tutoriel sur le cluster EKS Anywhere [D√©ployer le cluster en 7 √©tapes]

Titres H2:
Scripts Shell pour DevOps
How to Get Started With Shell Scripting?
What are the Best Free Shell Scripting Learning Resources?
Real-world Shell Scripting Use Cases
Shell Scripting Real-Time Scenarios
Shell Scripting Languages
Shell Scripting DevOps Interview Questions
Shell Scripting FAQs
Conclusion
Pr√©requis
Architecture de configuration
Cr√©er et cr√©er une image Docker d'application Java
Deploy Java & MySQL On Kubernetes
Step 7: Deploy HorizontalPodAutoscaler (HPA)
Step 8: Access the Java Application
Step 9: Clean Up
Conclusion
Qu'est-ce que la biblioth√®que partag√©e Jenkins¬†?
Shared Library Github Repo
Getting Started With Shared Library
Creating Shared Library
Real World Example
Unit Testing Shared Libraries
Conclusion
Sauvegarde Jenkins √† l'aide du plugin Thin Backup
Jenkins¬†Backup Using Disk Snapshots
Jenkins Manual Backup
Comment fonctionnent les agents Pod Jenkins Kubernetes¬†?
Configuration des pods de build Jenkins sur Kubernetes
Setting Up Kubernetes Namespace & Service Account
Jenkins Controller Setup in Kubernetes
Jenkins Kubernetes Plugin Configuration
Jenkinsfile With Pod Template
Multi Container Pod Template
Using Shared Persistent Volumes With Jenkins Docker Agent Pods
Building Docker Images On Kubernetes Cluster
Conclusion
Types de configuration Jenkins HA
Configuration de Jenkins HA avec groupe de mise √† l'√©chelle automatique
HA Setupon Kubernetes
Horizontal Scaling For Agents
Jenkins HA Setup
Pr√©requis
R√©f√©rentielde codes AWS VPC de Terraform
Workflow de cr√©ation de Terraform AWS VPC
Cr√©er un VPC √† l'aide de Terraform
Conclusion
Configurations de clusters Kubernetes
Kubelet Configurations
CoreDNS Configurations
Audit Logging Configuration
Kubernetes Configurations Video
Kubernetes Configurations Involved in Production Setup
Conclusion
Qu'est-ce qu'un plugin dans ChatGPT ?
Comment activer les plugins dans ChatGPT¬†?
Comment installer le plugin ChatGPT¬†?
Comment utiliser les plugins ChatGPT¬†?
Architecture du plug-in ChatGPT
Conclusion
√Ä propos des outils CI/CD
CI/CD pour les applications et l'infrastructure (IaC)
1. Gestion de la configuration
2. Gestion secr√®te
3. Suivez les principes DRY
4. Pipelines bas√©s sur Git PR
5. Consid√©rations relatives au r√©seau priv√©
6. Developer-Centric Workflows:
7. Develop Pipelines for Team
8. Leverage Ephemeral Build Agents
Qu'est-ce que Git ?
Git pour DevOps
Git Learning Roadmap
What are the Best Resources to Learn Git?
Git DevOps Interview Questions
Conclusion
Pr√©requis pour apprendre Kubernetes
D√©couvrir l'architecture Kubernetes
$1000+ Free Cloud Credits to Deploy Clusters
Kubernetes Cluster Setup
Learn About Cluster Configurations
Understand Kubeconfig File
Understand Kubernetes Objects And Resources
Learn About Pod & Associated Resources
Learn Pod Dependent Objects
Learn Ingress & Ingress Controllers
Learn End-to-end Microservices Application Deployment on Kubernetes
Learn About Securing Kubernetes Cluster
Learn About Kubernetes Configuration Management Tools
Learn About Kubernetes Operator Pattern
Learn Important Kubernetes Configurations
Learn Kubernetes Best Practices
The Best Resources to Learn Kubernetes Online
Kubernetes Learning GitHub Repository
What is the Best Way to Learn Kubernetes?
Real-World Kubernetes Case Studies
Quoi de neuf dans la derni√®re version de Kubernetes
Conclusion
Comment configurer les m√©triques d'√©tat de Kube sur Kubernetes
Meilleures certifications Kubernetes pour 2024 [Classement]
Tutoriel sur l'injecteur de Vault Agent¬†: injecter des secrets dans des pods √† l'aide de Vault Agent
Fichier Kubeconfig expliqu√© avec des exemples pratiques
Le cycle de vie des pods Kubernetes expliqu√© avec des exemples
Tutoriel sur le cluster EKS Anywhere [D√©ployer le cluster en 7 √©tapes]
Sauvegarde Kubernetes etcd √† l'aide d'etcdctl
Kubernetes etcd Restore Using Snapshot Backup
etcd Backup FAQs
Conclusion
Qu'est-ce que EKS Anywhere ?
Configuration du cluster de d√©veloppement EKS Anywhere
Conclusion

Titres H3:
How hard is it to learn Linux shell scripting?
Is scripting required for DevOps Engineers?
Quel langage de script est le meilleur pour DevOps¬†?
Le Shell Scripting est-il utilis√© pour l‚Äôautomatisation¬†?
√âtape 1¬†:¬†cr√©er l‚Äôapplication Java
√âtape 2¬†: cr√©er une image Docker de l'application
Step 3: Push the image to DockerHub
Step 1: Create Namespaces
Step 2: Create Secrets
Step 3: Create ConfigMap for MySQL
Step 4: Deploy MySQL Database
Step 5: Create ConfigMap for Java Application
Step 6: Deploy Java Application
1. Delete Java App Deployment
2. Supprimer MySQL
3. Supprimer le secret
4. Supprimer les espaces de noms
1.vars
2.src
3.resources
Step 1: Create a Shared Library Structure
Step 2: Create Custom Shared Library Code
Step 3: Create a Shared Library For Git Checkout
Step 4: Add Github Shared Library Repo to Jenkins
Step 5: Use Library in Declarative Pipeline
√âtape 1¬†: installez le plugin Think Backup.
√âtape 2¬†: Configuration du plug-in Thinbackup
√âtape 3¬†: Sauvegarde de la sauvegarde Jenkins
Step 1: Install Jenkins Kubernetes Plugin
Step 2:Create a Kubernetes Cloud Configuration
Step 3: Configure Jenkins Kubernetes Cloud
√âtape 1¬†: CD dans le r√©f√©rentiel clon√©
√âtape 2¬†: modifier le fichier vpc.tfvars
√âtape 2¬†: Initialiser Terraform et ex√©cuter le plan
√âtape 3¬†: Cr√©er un VPC avec Terraform Apply
√âtape 4¬†: Valider le VPC
√âtape 5 : Nettoyer les ressources
Manifestes de pod statique
Configurations du serveur API
Configurations ETCD
Certificats TLS
Kubeconfig Files
1. Pour avoir des discussions CI/CD significatives avec les d√©veloppeurs
2. Pour l'infrastructure en tant que code
3. Gitops
1. The official Kubernetes Basics Tutorial
2. DevOpsCube Kubernetes Tutorials
3. KillerCoda Interactive Tutorials
How to take etcd backup in Kubernetes?
√âtape 1¬†: Installer Docker Desktop
√âtape 2¬†: installer eksctl-anywhere
√âtape 3¬†: G√©n√©rer la configuration du cluster
√âtape 4¬†: D√©ployer le cluster
√âtape 5 : Valider le cluster
√âtape 6¬†: g√©n√©rer et d√©ployer les configurations du connecteur EKS
√âtape 7¬†: Valider l'enregistrement du cluster EKS Anywhere sur la console EKS

Contenu des Paragraphes:
Pour les ing√©nieurs DevOps en herbe, il est essentiel de conna√Ætre les scripts shell ou les scripts bash. Dans ceguide sur les scripts shell pour DevOps, je partagerai mes conseils et ressources pour apprendre les scripts shell Linux de la bonne mani√®re.
J'ai √©galement √©voqu√© l'importance des scripts shell dans monguide de formation des ing√©nieurs DevOps. Ce guide s'adresse √† tous ceux qui souhaitent apprendre les scripts shell de la bonne mani√®re, ce qui peut vous aider dans votre travail quotidien et dans vos entretiens DevOps. Il est tr√®s important d'avoir de la patience et de la discipline dans le processus d'apprentissage.
Si vous √™tes quelqu'un qui veut simplement faire avancer les choses, alors Google et Stackoverflow sont plus que suffisants üôÇ
Voici ce que nous allons voir dans ce blog.
La premi√®re question que vous pourriez vous poser est la suivante : quelle est l'importance des scripts Shell pour un ing√©nieur DevOps ? Cette question m'est venue de d√©butants comme de professionnels exp√©riment√©s de l'informatique.
La r√©ponse est que c'est tr√®s important. L'image suivante montre l'enqu√™te Stackoverflow 2021, o√π 27 % des r√©pondants ont d√©clar√© utiliser des scripts shell.
Mais la plupart du temps, on me demande s'il existe de nombreux outils d'automatisation et si nous devons encoreapprendre et √©crire des scripts shell. La r√©ponse est oui. Nous ne cr√©ons plus de scripts shell pour une automatisation √† part enti√®re, mais nous utilisons des scripts avec des outils d'automatisation et pour des t√¢ches ad hoc.
Par exemple, si vous utilisez l'option de donn√©es utilisateur AWS, il est possible que vous utilisiez un script shell √† l'int√©rieur. Un autre exemple est que, lors dela cr√©ation d'images AMI √† l'aide d'un packer, vous finirez par utiliser un script shell pour la configuration AMI. De plus, j'ai eu des cas o√π j'ai d√ª utiliserdes scripts shell avec des outils de gestion de configuration,des conteneurs, etc. Nous en parlerons plus en d√©tail dans les sections suivantes.
Les scripts shell sont √©galement utiles pour les t√¢ches de d√©veloppement r√©p√©titives. Par exemple, il peut s'agir de lancer une machine virtuelle Vagrant avec le logiciel essentiel ou de configurer l'environnement de d√©veloppement lui-m√™me.
Most importantly,hands-on scriptingand programming are becoming mandatory in preliminary interview rounds in DevOps interviews. So it is another crucial reason why you should learn shell scripting.
The prerequisite to getting started with shell scripting is hands-on experience with Linux. Therefore, before getting started with shell scripting, you should becomfortable working with Linux commands.
If you are totally new to the Linux world, you could start by spinning up a few Linux servers locally usingVagrantor on cloud platforms like AWS, Google Cloud, etc. Every platform offers free credits for beginners. You can check out thefree $100 credit from the digital oceanas well. It‚Äôs effortless to get started.
If you think you are comfortable with Linux, you can get started with Shell scripting basic tutorials. Also, I want you to do the following.
Create a Github repo, create folders for each concept you learn, and commit all your work scripts. It doesn‚Äôt matter if the script is available online. Have your own documentation. You can add references and credit websites/blog links in theREADMEsection. Once your learning is over, you can share it on Linkedin. Trust me; it will help you retain the knowledge and will help others as well.
You don‚Äôt need to pay for any expensive courses to learn Linux shell scripting. There is too much marketing around courses that promises to make you a DevOps Shell scripting ninja. However, I don‚Äôt have anything against courses; go for it if you feel comfortable learning via a paid course. I will add those resources as well.
I have listed down the best free shell scripting resources for you to get started. Go through all the resources once, pick one resource you feel comfortable with, and ensure you go through the material from start to finish. As I said earlier, mastering technology requires patience and discipline.
Follow the free resources. It has web-based content, web-based interactive tutorials, free courses, and pdf materials.
But if you say, hey, I am a person who likes guided courses, here are some of my recommendations.
Assuming you have learned all theshell scripting conceptsand probably written and executed shell scrips for learning purposes. The next question anyone would have is, how to learn real-world shell scripting use cases?
If you work in a company, you can find project documentation and infrastructure automation codes where existing projects use shell scripts.
If you don‚Äôt have access to project documents and code, here is what you can do.
Find the GitHub repo of the most common docker base images, For example, the Nginx base image.
There you will find an entrypoint folder with multiple scripts or anentrypoint.shscript file. Here is annginx example
Try to understand the shell script and its functionality.¬†In this process, you will figure out many concepts and logic that can be used while writing a shell script. (functions, conditionals, switch cases, and many more)
It is not just limited to Docker repositories, you can find scripts in many open-source community repositories.
It is always better to learn with some real-time scenarios in terms of DevOps engineer interviews. So I have come up with some real-world scenarios you can try out. I will keep updating this list.
Ensure you include the following concepts in the shell scripts you are writing.
First of all, there are no specific shell scripting languages. When it comes to Shell scripting, it refers tosh, bash, csh, tcsh. Here we are primarily talking about bash shell scripting. Bash is an interpreted scripting language for Unix-based systems.
Ashell scriptis a¬†computer program¬†designed to be run by the¬†Unix shell, a¬†command-line interpreter.
But scripting languages, in general, means multiple languages. The following are the common scripting languages.
Shell scripting DevOps interview questions differ from company to company.
For example, a Service based company would be just interested in your basic Linux and shell scripting knowledge. However, a product-based company might expect a good level of knowledge of Linux command line and shell scripting.
Nowadays, most companies would provide platforms like Hackerank to test your scripting skills. So it is necessary to practice shell scripting to solve problems.
Following are some of the DevOps interview shell script questions.
I will be updating the list with more generic interview questions soon.
Following are some of the frequently asked shell scripting questions by aspiring DevOps engineers.
Learning shell scripting is like learning any other technology. If you have a good foundational knowledge of Linux, you can learn shell scripting easily, provided you follow a disciplined learning path.
Yes. Scripting knowledge is very essential for a DevOps engineer. For the development environment till production, a DevOps engineer might have to create useful utilities using scripting.
Cela d√©pend du projet. Mais Bash, Powershell et Python sont les langages de script couramment utilis√©s dans les projets bas√©s sur DevOps. Groovy est essentiel si le projet utilise Jenkins.
Avec l'av√®nement de nombreux outils DevOps, il n'est plus n√©cessaire d'√©crire une automatisation compl√®te dans des scripts shell. Cependant, les scripts shell sont utilis√©s dans le cadre de ces outils d'automatisation pour prendre en charge quelques fonctionnalit√©s. Un exemple classique serait l'utilisation de scripts shell avec Hasicorp Packer pour cr√©er des images de machine virtuelle.
J'esp√®re que vous avez appr√©ci√© ce guide sur l'apprentissage des scripts Shell pour les ing√©nieurs DevOps.
Maintenant, j‚Äôaimerais conna√Ætre votre avis : quelle m√©thode ou ressource du guide d‚Äôaujourd‚Äôhui allez-vous essayer en premier ?
Allez-vous commencer par les bases de Linux¬†? Ou commencer √† vous concentrer sur les questions d'entretien
Faites-le-moi savoir en laissant un commentaire rapide ci-dessous d√®s maintenant.
Les entreprises traversent une transformation num√©rique et depuis des ann√©es, la fourniture de logiciels est un v√©ritable d√©fi. Nous constatons de nombreuses frictions et, √† cause de cela, de nombreuses entreprises ont essay√© d'√™tre agiles, mais tout le monde a adopt√© l'agilit√© de mani√®re locale.
Si vous examinez le cycle de vie total de la mani√®re dont une application passe de la machine d'un d√©veloppeur jusqu'√† un serveur de production, puis jusqu'au client final, l'ensemble de ce flux de travail est tout sauf Agile.
Depuis de nombreuses ann√©es, les organisations s‚Äôefforcent d‚Äôadopter Agile et de devenir Agile.
DevOpsest l√† pour vous aider.
Carte syst√©matiquesur la fa√ßon de r√©ussir avec DevOps
Vous devez toujours garder √† l'esprit que l'automatisationsans interventionest l'objectif, cela ne signifie pas que vous devez d√©ployer directement en production, mais si vous voulez le faire, vous devez pouvoir le faire. Cela devrait √™tre si simple que m√™me un responsable des op√©rations puisse le faire en appuyant simplement sur un bouton et sans passer parSSHsur plusieurs serveurs.
DevOps is broken into 4 different blocks,
En plus des 4 √©tapes, cela doit passer par tous les environnements comme indiqu√© sur l'image.
L‚Äôobjectif ici devrait √™tre de d√©placer l‚Äôautomatisation de votre organisation aussi loin vers la droite que possible.
L'automatisation repose sur ces 4 piliers fondamentaux,
De plus, si vous d√©butez votre parcours en tant qu‚Äôing√©nieur DevOps, vous devriez consulter leguide complet pour devenir ing√©nieur DevOps.
Dans ce blog, nous examinerons les √©tapes √† suivre pour cr√©er et d√©ployer une application Java avec la base de donn√©es MySQL sur le cluster Kubernetes.
Voici les conditions pr√©alables pour suivre ce guide.
Le flux de travail de cette configuration est donn√© dans le diagramme ci-dessous.
Vous utiliserez concr√®tement les objets cl√©s de Kubernetes suivants. Cela vous aidera √† comprendre comment ces objets peuvent √™tre utilis√©s dans des impl√©mentations de projets r√©els¬†:
Il couvre √©galement des concepts cl√©s tels que :
Commen√ßons par la configuration.
Remarque¬†:vous pouvez ignorer cette section si vous souhaitez uniquement tester le d√©ploiement de Kubernetes. Utilisez simplement l'image fournie dans le guide.
Vous trouverez ci-dessous le guide √©tape par √©tape pour cr√©er et d√©ployer des applications Java avec MySQL sur Kubernetes.
Clonez le d√©p√¥t Git ci-dessous, qui contient le code source pour cr√©er l'application. Nous utiliserons l'application Spring Boot de la clinique pour animaux de compagnie, disponible publiquement, pour cette configuration.
Maintenant, acc√©dez au r√©pertoirespring-petclinicet ex√©cutez la commande ci-dessous pourcr√©er l'application √† l'aide de maven.
Si vous souhaitez ignorer le test pendant la construction, utilisez l'-DskipTestsindicateur .
Une fois la construction termin√©e, vous pouvez trouver le fichier JAR de l'application dans ledossierspring-petclinic/target
Pourcr√©er l'image Dockerde l'application, cr√©ez un Dockerfile en utilisant le contenu ci-dessous dans le r√©pertoirespring-petclinic.
Ce dockerfile utilisetechiescamp/jre-17:1.0.0comme image de base celle sur laquelle JRE est install√© et il copie le fichier JAR du dossier cible et le colle √† l'int√©rieur de l'image docker dans ledossier/app en tant quejava.jar.
Il expose √©galement le port 8080, car l'application Java s'ex√©cute sur le port 8080.
Run the below command from the same directory where theDockerfileis present to build the docker image
kube-petclinic-app:3.0.0is the name and tag I have given to my docker image.
Run thedocker imagescommand to check if your docker image has been created successfully.
Before pushing the image to the DockerHub repository, you have to tag the image that you want to push, use the below to tag the image
In this commandkube-petclinic-app:3.0.0is the name of the image I build andtechiescamp/kube-petclinic-app:3.0.0is my DockerHub repository and image tag.
Now, push the image to DockerHub using the command. Before proceeding, ensure you havelogged in to docker hubfrom the CLI.
Check if your image is pushed into DockerHub as shown below
Clone the Git repository given below which contains all the YAML manifest we used in this guide under03-java-app-deploymentfolder.
In the03-java-app-deploymentfolder, you can see the YAML manifests in the below structure.
Given below are the steps to deploy Java and MySQL on Kubernetes
We are going to deploy the app and MySQL on two different namespaces so create two new namespacespet-clinic-appandpet-clinic-db.
Run the following commands to create both namespace
CD into the03-java-app-deploymentdirectory and run thesecret.ymlin bothpet-clinic-appandpet-clinic-dbnamespaces because the secret contains the MySQL login credentials which are needed in both MySQL and app deployment process.
Just change the namespace and run thesecret.ymlfile two times to create a secret in bothpet-clinic-appandpet-clinic-dbnamespaces.
You can see the data in the above block is given in base64-encoded values because the secret won‚Äôt be created unless you specify your username and password inbase64-encodedvalues.
You can use theechocommand withbase64to encode your data, the echo command will give the encoded values of your data. The command to encode your data is given below
For example, I set myusernameascrunchops, then the echo command will be
This command will give the encoded values of my data.
Now, create the secret in both namespaces using the following command.
Run the following command to verify the secret is created in both namespace
You will get the following output
CD into the03-java-app-deployment/mysqldirectory and run theconfigmap.yml.
This creates a configmapmysql-configmapon thepet-clinic-dbnamespace, that contains the SQL command to create a user, password, and tables on the database, and to insert data on the table.
It gets the username and password from env variables, which are retrieved from the secret.
Run the below command to create a configmap.
Now, run the following command to verify if the ConfigMap is created
You will get the following output
CD into the03-java-app-deployment/mysqldirectory and run themysql.yml.
This file deploys aMySQLstatefulset database on thepet-clinic-dbnamespace and also a nodeport servicemysql-serviceon thepet-clinic-dbnamespace so we can log in to MySQL from outside the cluster.
It gets the database username and password from the secret you created before.
Thedocker-entrypoint-initdb.ddirectory is part of the MySQL image. Any MySQL scripts placed in this folder will be executed during MySQL startup. It is primarily used for running database initialization scripts.
In our setup, we placed an init script (init.sql) in this folder through a ConfigMap (mysql-configmap).init.sqlcreates the username, password, and tables for our application. The script retrieves the username and password from environment variables set by the secret object usingsecretKeyRef
Run the below command to deploy the MySQL database.
Now, run the following command to check if the MySQL StatefulSet has been created.
You will get the following output
CD into the03-java-app-deployment/java-appfolder and run theconfigmap.yml.
Run the below command to create a configmap.
This creates a configmapjava-app-configon thepet-clinic-appnamespace, which contains content of the application.properties file which helps the application to connect with the MySQL database.
The username and password are given as a variable so that it can get the username and password from the env variables, which are retrieved from the secret.
Run the following command to check if the configmap is created
You will get the following output
This file deploys the Java applicationjava-appon thepet-clinic-appnamespace and also a nodeport servicejava-app-serviceon thepet-clinic-appnamespace so we can access the application on the web browser.
It gets the database username and password from the secret you created before and theapplication.propertiesfile gets the username and password from theenvduring startup.
The command is used to run the applicationJARfile along with theapplication.propertiesfile so that the application can access the MySQL database.
Also, I have added health checks for this application:
Run the below command to deploy the Java application.
After deploying the application, run the following command to check if the deployment pods are up and running. It takes minimum 2min for the pods to get ready.
You will get the following output.
For HPA to work, you need to have a metrics server running in the cluster.
If you don‚Äôt have a metrics server, you can install theMetrics serverusing the following command.
Now, run the top command to check if the metrics server is installed properly
You will get the following output.
Now, deploy theHorizontalPodAutoscalerin your cluster.
You can find the belowHPAfile inside the03-java-app-deployment/java-appdirectory.
This will deploy the HPA in the pet-clinic-app namespace.
It is configured to scale the target deploymentJava appif the pod‚Äôs CPU utilization is 50% and its maximum replica count is3.
Run the following command to deploy HPA
Now, run the following command to check if the HPA is deployed
You will get the following output
You can see the CPU usage of the target deployment and the number of pods available.
Once the pod is up and running, check if the application is deployed properly by trying to access it on the browser, search on the browser as{node-IP:nodeport}you will get the following
It‚Äôs important to clean up the setup if it‚Äôs no longer needed; run the following commands to clean up the setup.
Let‚Äôs start with deleting the Java application, CD into the03-java-app-deployment/java-appfolder and run the following command
Cette commande supprimera toutes les ressources cr√©√©es par les fichiers manifestes dans le r√©pertoire java-app, elle supprime le d√©ploiement de l'application Java, configmap et HPA.
L'√©tape suivante consiste √† supprimer MySQL, √† acc√©der au dossier03-java-app-deployment/mysqlet √† ex√©cuter la commande suivante
Cette commande supprimera toutes les ressources cr√©√©es par les fichiers manifestes dans le r√©pertoire mysql, elle supprime le statefulset et le configmap MySQL.
Pour supprimer le secret dans les deux espaces de noms, acc√©dez aud√©ploiement 03-java-appet ex√©cutez les commandes suivantes
Modifiez simplement l'espace de noms dans lefichiersecret.yml enpet-clinic-appetpet-clinic-db, puis ex√©cutez la commande suivante deux fois, une fois pour chaque espace de noms.
Enfin, supprimez les espaces de noms, ex√©cutez la commande suivante pour supprimer les deux espaces de noms
En r√©sum√©, nous avons cr√©√© l'application Java de la clinique pour animaux de compagnie √† l'aide de Maven, l'avons pouss√©e vers le hub Docker, avons utilis√© l'image pour d√©ployer l'application sur Kubernetes et avons configur√© une base de donn√©es MySQL.
Je pense que vous trouverez ce blog utile pour comprendre le d√©ploiement d‚Äôapplications et la configuration de la base de donn√©es sur l‚Äôapplication sur Kubernetes.
Dans ce didacticiel, nous aborderons les concepts essentiels desbiblioth√®ques partag√©es Jenkinset fournirons un guide pratique pour la cr√©ation de biblioth√®ques partag√©es pour les pipelines.
Nous vivons √† l'√®re des microservices, o√π les applications modernes sont divis√©es en composants d√©ployables individuellement. Contrairement √† une application monolithique, vous pouvez disposer de plusieurs pipelines pour d√©ployer chaque microservice.
De plus, Jenkins est utilis√© pour le d√©veloppement et le d√©ploiement d'infrastructures en tant que code.
Avecle pipeline Jenkins en tant que code, nous pouvons coder l'int√©gralit√© de notre processus CI/CD. Il est trait√© de la m√™me mani√®re que nous d√©veloppons le code d'application. Vous pouvez versionner votre code de pipeline et effectuer tous les niveaux de test avant de l'utiliser pour tout d√©ploiement d'application.
Cependant, nous pouvons avoir des pipelines r√©utilisables bien d√©finis en utilisant la biblioth√®que partag√©e Jenkins.
Lorsque nous parlons de CI/CD en tant que code, il doit √™tre modulaire et r√©utilisable. Et surtout, il doit suivre lesprincipes DRY(Don't Repeat Yourself). C'est l√† que la biblioth√®que partag√©e Jenkins entre en jeu.
Biblioth√®que partag√©e‚Äì Comme son nom l‚Äôindique, il s‚Äôagit d‚Äôune biblioth√®que qui peut √™tre partag√©e.
La biblioth√®que partag√©e Jenkinsest le concept d'avoir un code de pipeline commun dans le syst√®me de contr√¥le de version qui peut √™tre utilis√© par n'importe quel nombre de pipelines simplement en le r√©f√©ren√ßant. En fait,plusieurs √©quipespeuvent utiliser la m√™me biblioth√®que pour leurs pipelines.
Vous pouvez le comparer √† labiblioth√®que de programmation commune. En programmation, nous cr√©ons des biblioth√®ques individuelles qui peuvent √™tre utilis√©es par n'importe qui en les important simplement dans son code.
Supposons que vous ayez dix pipelines de microservices Java, l'√©tape de construction Mavenest dupliqu√©e sur les dix pipelines. Et chaque fois qu'un nouveau service est ajout√©, vous devrez copier et coller √† nouveau le code du pipeline. Maintenant, disons que vous souhaitez modifier certains param√®tres dans l'√©tape de construction Maven. Vous devrez le modifier manuellement dans tous les pipelines.
Pour√©viter la duplication du code du pipeline, nous pouvons √©crire une biblioth√®que partag√©e pour la construction Maven, et dans tous les pipelines, nous devons simplement faire r√©f√©rence au code de la biblioth√®que de construction Maven.
√Ä l'avenir, pour toute modification de build Maven, il vous suffira de mettre √† jour le code de la biblioth√®que partag√©e. Les modifications seront ensuite appliqu√©es √† tous les pipelines utilisant la biblioth√®que de build Maven.
Dans l‚Äôensemble, la biblioth√®que partag√©e Jenkins r√©pond aux probl√®mes suivants.
The Jenkins shared library examples used in this guide are hosted on aGitHub Repository.
Clone the repository to follow along with the guide.
A shared library is a collection ofGroovy files (DSLs + Groovy). All the Groovy filesshould be present in a git repo.
In this example, we will be using Github as our Git repo.
You can clone this repo to get the basic structure of the shared library.
The shared library repo has the following folder structure.
Let‚Äôs understand what each folder means.
This directory holds all theglobal shared library codethat can be called from a Jenkins pipeline. It holds all the library files with a .groovyextension.
Here is a simple library code for Git checkout.
Don‚Äôt worry about the syntax. We can generate it using the Jenkins pipeline generator. We will look at it practically in the following sections.
The vars directory also supports.txtfiles for the documentation of shared library code.
For example, if you have a file namedmaven-build.groovy, you can have a helper file namedmaven-groovy.txt. In this file, you can write the respective shared library function help documentation in markdown format.¬† The help file can be viewed from<your-jenkins-url>/pipeline-syntax/globalspage.
It is a¬†regular Java source directory. Here you can add mode complex and object-oriented code Groovy code to extend your shared library code. Also, you canimport core Jenkins and its plugin classesusing an import statement.
You might ask, when we have a vars directory, what is theneed for src?
There are scenarios where thegroovy DSLs will not be flexible enoughto achieve some complex functionalities. In this case, you can write custom Groovy functions in src and call them in your shared library code.
The src directory is added to the classpath during every script compilation. So we candirectly use the classesdefined in thesrcdirectory in Jenkinsfiles.
All thenon-groovy files(e.g., text files, templates) required for your pipelines can be managed in this folder. Typically files.
One such example is, you might¬†need a common JSON template to make an API call during the build. This JSON template can be stored in the resources folder and can be accessed in the shared library using thelibraryResourcefunction.
Or You can use aHTML file as a templatefor sending HTML-formatted email notifications from your Jenkins pipelines. In your pipeline script or shared library function, you can load this template and replace the placeholders with actual values.
We will look into the following four things to get your hands dirty with the shared library.
Let‚Äôs look at each one in detail.
Note:In this guide, we will concentrate only on the vars folder for creating your first shared library. The advanced shared library guide will cover src and resources.
Jenkins shared library has the following structure. You can get the basic structure and code used in this article from Github ->Jenkins Shared Library Structure
All the files under vars areglobal functions and variables. The file name is the function name. We will be using the filename in our declarative pipeline.
In this section, we will create the shared library code for Git Checkout functionality.
You can create the code snippets that can be used in share library function using the Pipeline Syntax Generator available in Jenkins. This will make our life easier for creating custom library DSL. All the supported pipeline functionality can be generated from the snippet generator.
You can access the syntax generator from your Jenkins on /pipeline-syntax/ path. For example,
Here is the screenshot, which shows creating a git checkout pipeline snippet using the pipeline syntax generator.
Here is the properly formatted checkout snippet.
Let‚Äôs convert the checkout snippet we generated in the above step to a shared library.
Create a file namedgitCheckout.groovyunder vars folder.
Here is our Git Checkout shared library code. We have removed all the empty checkout parameters that were generated by default.
Here is the code explanation,
Commit the changes and push it to your repository.
Now that we have a basic git checkout library ready, let‚Äôs add it to Jenkins configurations.
Step 1:Go toManage Jenkins ‚Äì> System
Step 2:Find theGlobal Trusted Pipeline Librariessection and add your repo details and configurations as shown below.
We always call the library using the filename undervars. In this case,gitCheckoutis the filename created under vars.
Here is how we call thegitCheckoutlibrary from the pipeline orJenkinsfile
As you can see, we are passingbranchandurlparameter to the Checkout function. Here is the full declarative pipeline code.
LikegitCheckout, you can create all your pipeline steps a shared library and you don‚Äôt have to repeat your common functionalities in all your pipelines.
@Library('jenkins-shared-library@master') _tells Jenkins to use the globally configured library namedjenkins-shared-library.
When you use this import statement, Jenkins will fetch the shared library code from the configured source (typically a Git repository) and make it available for use in your pipeline.
In larger enterprises, it is common to have central platform teams.
If Jenkins is used in such organizations, these platform teams usually create common Jenkins libraries for all application and infrastructure deployment tasks.
Application teams can reuse these pipelines to save time. Since these libraries are extensible, if the common libraries don‚Äôt meet the specific project needs, they can always be customized.
It is also common practice for teams to contribute to the central platform teams‚Äô shared libraries. This way, organizations can maintain efficient and streamlined pipeline libraries.
As I have explained in many other blogs, unit testing is important for Infrastructure as code.
Not every team writes tests, however, unit testing shared libraries isan important best practice in Jenkins pipeline development. It ensures code reliability, catches bugs early, and facilitates safe refactoring.
By thoroughly testing shared library functions, teams can prevent widespread issues across multiple pipelines, as these libraries often form the backbone of an organization‚Äôs CI/CD processes.
Writing unit test requiresfamiliarity with Java, Groovy and JUnit testing framework. Usually central platform team will have dedicated resources to write these tests for all the shared library functions.
In essence, although it takes time and effort, unit testing shared libraries is an investment in the stability, maintainability, and efficiency of your entire CI/CD ecosystem.
If you are using Jenkins for your CI/CD needs, implementing a shared library is a must.
Il simplifie votre flux de travail CI/CD avec Jenkins. Le meilleur, c'est que vous pouvez disposer d'un flux de travail de d√©veloppement bien d√©fini pour d√©velopper et tester le code du pipeline Jenkins.
Si vous avez des questions concernant les biblioth√®ques partag√©es, faites-le nous savoir dans la section commentaires.
Il est tr√®s important d'avoir une sauvegarde de Jenkins avec ses donn√©es et ses configurations. Cela comprend les configurations de t√¢ches, les journaux de builds, les plugins, la configuration des plugins, etc.
Jenkins n√©cessite des correctifs et des mises √† jour de plugins r√©guliers. Au cours de ces processus, il existe un risque de probl√®mes de configuration, qui peuvent potentiellement conduire √† un crash de Jenkins.
Cela peut entra√Æner une interruption du service Jenkins, il est donc tr√®s important de sauvegarder p√©riodiquement les donn√©es Jenkins.
Cet article couvrira les trois mani√®res suivantes de sauvegarderles donn√©es et les configurations Jenkins.
Jenkins Thin Backupest un plugin populaire pour la sauvegarde de Jenkins. Il sauvegarde toutes les donn√©es en fonction de votre planning et g√®re √©galement la conservation des sauvegardes.
Voici les principales fonctionnalit√©s de ce plugin.
Commen√ßons par la configuration.
1. Allez dans G√©rer Jenkins -> G√©rer les plugins
2. Cliquez sur l'onglet Disponible et recherchez ¬´ Sauvegarde l√©g√®re ¬ª
3. Installez le plugin et red√©marrez Jenkins.
Une fois le plugin install√©, suivez les √©tapes ci-dessous pour configurer les param√®tres de sauvegarde.
1. Acc√©dez √† G√©rer Jenkins ‚Äî > ThinBackup
2. Cliquez sur l'option Param√®tres.
3. Entrez les options de sauvegarde indiqu√©es ci-dessous et enregistrez-les. Toutes les options sont explicites. Le r√©pertoire de sauvegarde que vous sp√©cifiez doit √™tre accessible en √©criture par l'utilisateur ex√©cutant le service Jenkins. Le plugin enregistre la sauvegarde dans le r√©pertoire de sauvegarde que vous sp√©cifiez.
4. Vous pouvez maintenant tester si la sauvegarde fonctionne en cliquant sur l'Backup Nowoption. Cela cr√©era une sauvegarde des donn√©es Jenkins dans le r√©pertoire de sauvegarde que vous avez sp√©cifi√© dans les param√®tres.
5. Si vous v√©rifiez le r√©pertoire de sauvegarde sur le serveur, vous pouvez voir la sauvegarde cr√©√©e. Pour chaque nouvelle sauvegarde, l'horodatage est associ√© au nom du dossier et l'ancienne sauvegarde est conserv√©e en fonction de la politique de conservation que vous avez mentionn√©e dans les param√®tres.
Un exemple est pr√©sent√© ci-dessous.
Conserver la sauvegarde Jenkins dans Jenkins lui-m√™me n'est pas une bonne id√©e. Il s'agit d'un point de d√©faillance unique.
It is a must tomove thin backups to cloud storageor any other backup location so that even if the Jenkins server crashes, you will have all the data.
If you are on AWS, Azure, or Google Cloud, you can upload the backup‚Äôs respective storage solution using a Linux CronJob
As you know, Jenkins doesn‚Äôt¬†have a database. All the configurations are stored as¬†files in the/var/lib/jenkinsfolder.
All the modern private and public cloud platforms support the disk snapshot feature.
If your environment supports disk snapshots, here is what you can do during the initialJenkins installation.
For some reason, if your Jenkins server crashes or data gets corrupted, create a new disk from the existing snapshot backup and replace it in the Jenkins server. Jenkins will have all the data from the snapshot point in time backup.
If you are on the AWS cloud, use theEBS snapshot automationfeature to back up the Jenkins data disk.
Also, if you runJenkins on Kubernetes,you can back up the persistent volume.
Also, we suggest you use the Thin backup plugin in conjunction with disk snapshots.
If you don‚Äôt have any option using Thinback or disk snapshot, you can go for manual backups.
First, stop Jenkins to ensure the data is not being written or modified during backup. You can stop Jenkins with the following command:
Create a tar.gz archive of the Jenkins home directory to ensure all files are preserved
You can also copy the directory to a backup location:
You can also automate this process using Linux cron Job.

Dans ce tutoriel Jenkins, j'ai expliqu√© les √©tapes d√©taill√©es pour configurer le contr√¥leur Jenkins et mettre √† l'√©chelle les agents de build Jenkins sur les pods Kubernetes √† l'aide du plugin Jenkins Kubernetes
Dans un autre article, j'aiexpliqu√© comment configurerdes agents Jenkinsbas√©s sur Docker.
Si vous disposez d‚Äôuncluster Kubernetesdans votre environnement, l‚Äôex√©cution d‚Äôagents Jenkins sur les pods Kubernetes vous offrira une bonne isolation de build pour diff√©rentes versions d‚Äôapplication.
De plus, un agent Jenkins √©ph√©m√®re bas√© sur un pod Kubernetes est un excellent moyen de r√©duire le co√ªt de l'environnement CI, car les agents Jenkins ne sont lanc√©s qu'en cas de demande de build.
Avant d‚Äôentrer dans la mise en ≈ìuvre, comprenons comment fonctionne cette configuration.
L'image suivante montre le flux de travail de haut niveau.
Toutes les √©tapes de build du fichier Jenkins s'ex√©cutent sur ce pod. Une fois la build termin√©e, le pod sera automatiquement arr√™t√©. Cependant, il existe √©galement des options permettant de conserver le pod de build.
Le plugin Jenkins Kubernetes g√®re toutes les communications de Jenkins vers le cluster Kubernetes.
De plus, tant que votre cluster Kubernetes √©volue, vous pouvez faire √©voluer vos agents de build Jenkins sans probl√®me.
Pour travailler sur cette configuration, nous avons besoin des √©l√©ments suivants.
J‚Äôenvisage √©galement deux sc√©narios ici.
Nous examinerons les deux sc√©narios et leurs configurations.
D√©bordement, voil√† ce que nous allons faire.
Let‚Äôs get started with the setup.
Step 1:Create a namespace calleddevops-tools
Step 2:Save the following manifest asservice-account.yaml. It contains the role and role-binding for the service account with all the permission to manage pods in thedevops-toolsnamespace.
Create the service account.
The next step is to create a Secret, which creates a token for the service account.
Create a YAML filesecret.yamland copy the below contents into it
Create the secret
This creates a secret and links it with the service account using the annotation.
In this setup, we will have both the Jenkins controller and agents deploying in the same Kubernetes cluster.
We will set up the Jenkins controller server on the Kubernetes cluster.
Note:If you have an existing setup, you can use that as well. Ensure it has a service account with permissions to deploy pods in the namespace where Jenkins is deployed.
Save the following manifest asdeployment.yaml. This manifest contains persistent volume, deployment, and service definitions.
Note:Ensure that your Kubernetes cluster setup supports persistent volumes. If you deploy Jenkins without a persistent volume, you will lose the Jenkins data on every restart or pod deletion.
Create the deployment.
After a couple of minutes, the Jenkins deployment will be up, and you will be able to access any Kubernetes node on the port32000
Step 4:Access the Jenkins dashboard over the node port and unlock it using the password from the pod logs. Install the suggested plugins and create a Jenkins user.
Please follow theJenkins on Kubernetes blogif you have any doubts.
Jenkins Kubernetes pluginis required to set up Kubernetes-based build agents. Let‚Äôs configure the plugin.
Go toManage Jenkins‚Äì>Manage Plugins, search for¬†the Kubernetes Plugin¬†in the available tab, and install it. The following Gif video shows the plugin installation process.
Once installed, go toManage Jenkins‚Äì>Clouds
Click New Cloud
Give a name and select Kubernetes.
Click Create and move on to the next step
Here we have two scenarios.
Let‚Äôs look at configurations for both scenarios.
Since we have Jenkins inside the Kubernetes cluster with a service account to deploy the agent pods, we don‚Äôt have to mention the Kubernetes URL or certificate key.
However, to validate the connection using the service account, use the Test Connection button as shown below. It should show a connected message if the Jenkins pod can connect to the Kubernetes API Server.
If your Jenkins server is running outside the Kubernetes cluster, you need to specify the following.
Note:If you use managed services likeGKE cluster, you can get all the cluser details from the GKE dashboard.
We have created the service account and assigned a secret token to thedevops-toolsnamespace. We need to get the token from the secret.
Execute the following commands to retrieve the secret name from the service account.
Now click theAddbutton under credentials and create a credential type ‚ÄúSecret text‚Äú. Enter the service account token in the secret box and add other details as shown below. Finally, save the credential.
The Kubernetes cloud configuration would look like the following.
After filling in all the details, you can test the connection to validate the Kubernetes cluster connectivity.
For the Jenkins Controller running inside the cluster, you can use the Kubernetes cluster‚Äôs service endpoint as the Jenkins URL because agent pods can connect to the cluster via internal service DNS.
The URL is derived using the following syntax.
In our case, the service DNS will be,
Also, add the POD label, which can be used to group the containers that can be used for billing or custom build dashboards.
Note:If the Jenkins controller is outside the Kubernetes cluster, use theJenkins IP or DNSin the Jenkins URL configuration.
Next, you must add the POD template with the details, as shown in the image below. The label kubeagent will be used as an identifier to pick this pod as the build agent. Next, we must add a container template with the Docker image details.
The next configuration is the container template. If you don‚Äôt add a container template, the Jenkins Kubernetes plugin will use the default JNLP image from the Docker hub to spin up the agents. ie,jenkins/inbound-agent
If you are on the corporate network and don‚Äôt have access to the Docker hub, you will have to build your ownjnlpimage and override the default with the same name as shown below, assumingjenkins/inbound-agent:latestis the custom jnlp image.
Ensure that you remove thesleepand9999999default argument from the container template.
We can add multiple container templates to the POD template and use them in the pipeline. I have explained that in the next section withJenkinsfileexamples.
This is the base minimum configuration required for the agent to work. Later in the pipeline examples, I will explain a few use cases for volumes and other options.
Now save all the configurations, and let‚Äôs test if we can build a job with a pod agent.
Step 6:Go to Jenkins home ‚Äì> New Item and create a freestyle project.
In the job description, add the labelkubeagentas shown below. It is the label we assigned to the pod template. This way, Jenkins knows which pod template to use for the agent container.
Add a shell build step with an echo command to validate the job as shown below.
Now, save the job configuration and click ‚ÄúBuild Now‚Äù
You should see a pending agent in the job build history below.
You will see a successful build in a couple of minutes. If you check the logs, the executed shell will be shown.
Whatever we have seen till now is to understand and validate the Kubernetes Jenkins plugin setup.
When it comes to actual project pipelines, it is better to have the POD templates in theJenkinsfile
Here is what you should know about the POD template.
Here is an exampleJenkinsfilewith a POD template.
Building the above Jenkinsfile in a pipeline job will use the default JNLP image and execute the commands in the ‚ÄúRun Shell‚Äù stage. When I say default, the plugin will use the JNLP image from the docker hub if you don‚Äôt specify any.
Now, you can use your ownjnlpimage using acontainerTemplatewith all necessary build tools and use them in the pipeline as given below.
Here, instead ofjenkins/inbound-agent:latest, you will have your own image.
You can use multiple container templates in a single POD template.
Here is a use case of this setup.
Let‚Äôs say you want to set up a single build pipeline that builds both Java and Python projects. In this case, you can use two container templates in the build stages.
In the following example, in two separate stages, we are calling two different containers specified in the pod template.
One container contains all the maven dependencies for Java build, and another contains Python build dependencies.
You can try building the above Jenkinsfile using the pipeline job.
While building the above pipeline, if you check the Kubernetes pods, you will see three containers in the build agent pod, as shown below.
Note: You cannot use the Docker hub images directly due to security compliance issues in actual projects. Sou you have to build your own Docker images and host them in the organization-approved container registry.
It is better to attach a shared persistent volume to the build container to speed up the build process.
For example, if you take a Java application, it has many Maven package dependencies.
When you build the Java apps, it downloads dependencies added in the pom.xml from the remote maven repository the first time, and it creates a local .m2 cache directory where the dependent packages are cached.
The.m2cache is impossible in Docker agent-based builds as it gets destroyed after the build.
To solve this issue, we can create a persistent volume for the maven cache and attach it to the agent pod via the container template.
To demonstrate this, first, let‚Äôs create a PVC
Here is an exampleJenkinsfilewith a POD template that uses themaven-repo-storagepersistent volume.
If you are using Docker to deploy applications, you can integrate your CI Docker build pipeline with Kubernetes agents.
There are a few ways torunDocker on Dockerfor build use cases. However, since Kubernetes removed Dockerruntimes, it is better to use alternative solutions.
For now, the best way to build docker images on the Kubernetes cluster is usingKaniko
Referbuilding docker image using kanikoto learn more about kaniko build pipeline using Jenkins pipeline.
If you are using Jenkins & Kubernetes, you should definitely try out the container-based agents.
Scaling your Jenkins agents on Kubernetes helps you avoid the administrative overhead associated with static build VMs. Even though dynamic VM build options are available, each build could take a long time compared to dynamic container agents.
You don‚Äôt have to worry about running out of resources for Jenkins builds.
Do give it a try, and let me know if you face any issues.
Also, check out my comprehensive list ofJenkins tutorials for beginners
Ce blog traitera de la configuration d'unJenkins hautement disponible√† l'aide de la version open source.
Avant d‚Äôaborder la discussion sur la haute disponibilit√©, vous devez d‚Äôabord comprendre comment Jenkins g√®re ses donn√©es et l‚Äôarchitecture de haut niveau.
Si vous n'√™tes pas au courant de l'architecture, je vous sugg√®re fortement de lire l'articlesur l'architecture de Jenkins.
Il n‚Äôexiste aucun moyen direct de configurer Jenkins en mode haute disponibilit√© en raison de la fa√ßon dont Jenkins g√®re ses donn√©es.
Jenkins g√®re sesdonn√©es dans un fichier plat (xml)et vous ne pouvez avoir qu'une seule instance du n≈ìud ma√Ætre qui peut lire les donn√©es Jenkins.
Pour cette raison, l'ex√©cution de plusieurs r√©pliques duma√Ætre Jenkins dans une configuration active-active(o√π toutes les r√©pliques traitent activement des t√¢ches) n'est pas officiellement prise en charge.
Par exemple, si vous essayez de configurer plusieurs n≈ìuds ma√Ætres avec un volume partag√©, vous aurez des lectures et des √©critures incoh√©rentes qui conduiront √† un Jenkins instable.
Il existe deux fa√ßons d'avoir Jenkins en mode HA.
Vous pouvez appeler cette m√©thode unesolution de pauvre pour Jenkins HA.Car, lorsqu'une instance tombe en panne, il y a quelques minutes d'indisponibilit√© pour qu'une autre instance se r√©tablisse (temps de d√©marrage de la machine virtuelle + service Java). Mais √ßa marche üôÇ
Cette m√©thode fonctionnera sur n‚Äôimporte quelle plateforme cloud priv√©e/publique avec l‚Äôoption de mise √† l‚Äô√©chelle automatique.
Cette m√©thode est similaire aud√©ploiement de Jenkins sur Kubernetes, o√π si le pod Jenkins tombe en panne, un autre pod g√©n√©rera les m√™mes donn√©es.
Au lieu d'un pod, il s'agit d'une machine virtuelle, donc le temps de d√©marrage prend plus de temps que le lancement d'un nouveau pod.
Examinons l‚Äôarchitecture de haut niveau de la configuration Jenkins HA √† l‚Äôaide d‚Äôun groupe de mise √† l‚Äô√©chelle automatique.
Ici le concept est assez simple.
This setup also makes the upgrade and patching process so easy.
When deployed in Kubernetes, It should be deployed via StatefulSet. Also, wee need to keep the StatefulSet replica as one and the Jenkins data directory should be mounted to the a Persistent Volumeto store Jenkins data (e.g., job history, plugins, configurations).
This ensures data persists even if the Jenkins master pod is rescheduled or restarted.
A good news is, you can scale Jenkins agents horizontally.
There are several ways to scale Jenkins agents. In this method, the agents are dynamically provisioned and terminated once the build is completed.
For example,
If you want to try this setup on the AWS cloud, you can use my Documentation.
I have documented the whole setup for AWS here ->Jenkins HA Setup Using AWS Autoscaling Group
TheIaCcode for the setup is present in theDevOps ProjectsGithup Repo
Do try out this setup and see if it works for you.
Also, you shouldbackup jenkins dataperiodically using plugins and disk snapshots. You can easily restore a working version if you have all the data backup.
If you are new to Jenkins, check out ourJenkins tutorial for beginners.
Dans ce blog, vous apprendrez √† cr√©er AWS VPC √† l'aide de modules Terraform bien structur√©s. Il s'agit d'un guide √©tape par √©tape pour les d√©butants avec des informations d√©taill√©es.
Pour suivre ce guide, vous devez disposer des √©l√©ments suivants.
Le code AWS VPC Terraform fait partie du¬† r√©f√©rentielAWS Terraform. Clonez-le sur votre poste de travail pour suivre le guide.
Forkez et clonez le r√©f√©rentiel si vous avez l'intention de le r√©utiliser et d'apporter des modifications selon vos besoins.
Le code Terraform VPC est structur√© de la mani√®re suivante.
varsLe dossier contient le fichier de variables nomm√©vpc.tfvars. C'est le seul fichier qui n√©cessite une modification
Lemodules/vpcdossier contient les ressources VPC suivantes. Toute la logique de provisionnement des ressources fait partie de ces ressources.
Leinfra/vpc/main.tffichier appelle tous lesvpcmodules avec toutes les ressources VPC en utilisant les variables que nous transmettons √† l'aide duvpc.tfvarsfichier
Remarque¬†: le VPC et les sous-r√©seaux de cette d√©monstration sont cr√©√©s sur la base du document de conception VPC.
Nous allons cr√©er le VPC avec les √©l√©ments suivants
Suivez les √©tapes ci-dessous pour cr√©er un VPC √† l‚Äôaide du code Terraform.
Si vous n'avez pas encore clon√© le d√©p√¥t, clonez-le √† l'aide de la commande suivante.
Puis acc√©dez au dossier terraform-aws
Remarque: ouvrez le dossier du r√©f√©rentiel dans votre IDE pr√©f√©r√©, car cela facilite l‚Äô√©dition et la r√©vision du code.
Modifiez levars/dev/vpc.tfvarsfichier selon vos besoins. J'ai mis en √©vidence les param√®tres cl√©s en gras.
Si vous ne voulez pas de passerelle NAT, d√©finissezcreate_nat_gateway-la sur faux.
Acc√©dez maintenant au dossierinfra/vpcet ex√©cutez le plan Terraform pour valider les configurations.
Initialiser Terraform
Ex√©cuter le plan
Vous devriez voir une sortie avec toutes les ressources qui seront cr√©√©es par Terraform.
Cr√©ons le VPC et les ressources associ√©es √† l‚Äôaide de Terraform Apply.
Acc√©dez √† la console AWS et v√©rifiez la carte des ressources du VPC.
Cliquez sur le VPC cr√©√© et faites d√©filer vers le bas pour afficher la carte des ressources.
Vous devriez voir 15 sous-r√©seaux, 6 tables de routage, une passerelle Internet et une passerelle NAT comme indiqu√© ci-dessous.
Si vous avez cr√©√© le VPC √† des fins d'apprentissage et que vous souhaitez nettoyer les ressources cr√©√©es par Terraform, ex√©cutez la commande suivante
Dans ce guide, nous avons examin√© la cr√©ationd'Aws VPC√† l'aide de Terraform.
Lors de la mise en ≈ìuvre dans des projets r√©els, vous devrez peut-√™tre envisager davantage d'options VPC, telles que les journaux de flux, les connexions de peering, etc.
Pour la gestion de l'√©tat, vous devez utiliserun backend distant avec s3avec verrouillage dynamoDB.
Vous pouvez √©galement modifier le code Terraform en fonction de vos besoins. Si vous souhaitez acqu√©rir plus de connaissances, parcourez chaque ressource du module VPC
Si vous rencontrez des erreurs ou avez des questions ou des suggestions, laissez un commentaire ci-dessous.
Dans ce blog, nous examinerons les configurations Kubernetes importantes que chaqueing√©nieur DevOpsou administrateur Kubernetes doit conna√Ætre.
Vers la fin du guide, j‚Äôai ajout√© les configurations impliqu√©es dans une configuration de cluster Kubernetes r√©elle.
Remarque: tous les emplacements de configuration r√©f√©renc√©s dans ce guide sont bas√©s sur l‚Äôinstallation Kubernetes par d√©faut √† l‚Äôaidede kubeadm.
Que vous vous pr√©pariez auxcertifications Kubernetesou que vous envisagiez de travailler sur des projets Kubernetes, il est tr√®s important de conna√Ætre la configuration cl√© du cluster Kubernetes.
De plus, en ce qui concernela certification CKA, vous obtiendrez des sc√©narios pour corriger les probl√®mes dans le cluster. Ainsi, la compr√©hension des configurations du cluster vous permettra de r√©soudre plus facilement les probl√®mes et de trouver les probl√®mes dans le cluster de la bonne mani√®re.
Commen√ßons par les configurations li√©es aux composants du plan de contr√¥le.
Comme nous l'avons vu dans l'architecture Kubernetes, tous les composants du plan de contr√¥le sont d√©marr√©s par le kubelet √† partir des manifestes de pods statiques pr√©sents dans le/etc/kubernetes/manifestsr√©pertoire. Kubelet g√®re lecycle de vie de tous les podscr√©√©s √† partir des manifestes de pods statiques.
Les composants suivants sont d√©ploy√©s √† partir des manifestes de pod statiques.
Vous pouvez obtenir tous les emplacements de configuration de ces composants √† partir de ces manifestes de pod.
Si vous regardez lekube-apiserver.yaml, sous la sp√©cificationdu conteneur,vous pouvez voir tous les param√®tres qui pointent vers les certificats TLS et d‚Äôautres param√®tres requis pour que le serveur API fonctionne et communique avec d‚Äôautres composants du cluster.
Donc, si vous souhaitez d√©panner ou v√©rifier les configurations des composants du cluster, vous devez d‚Äôabord examiner les configurations du manifeste du pod statique.
Si vous souhaitez interagir avec le composant etcd, vous pouvez utiliser les d√©tails du pod statique YAML.
Par exemple, si vous souhaitezsauvegarder etcd,vous devez conna√Ætre le point de terminaison du service etcd et les certificats associ√©s pour vous authentifier aupr√®s d'etcd et cr√©er une sauvegarde.
Si vous ouvrez leetcd.yamlmanifeste, vous pouvez afficher toutes les configurations li√©es √† etcd comme indiqu√© ci-dessous.
In Kubernetes, all the components talk to each other over mTLS. Under the PKI folder, you will find all the TLS certificates and keys. Kubernetes control plane components use these certificates to authenticate and communicate with each other.
Also, there is an etcd subdirectory that contains the etcd-specific certificates and private keys. These are used to secure communication between etcd nodes and between the API server and etcd nodes.
The following image shows the file structure of the PKI folder.
The static pod manifests refer to the required TLS certificates and keys from this folder.
When you work on a self-hosted cluster using tools like kubeadm, these certificates are automatically generated by the tool. In managed kubernetes clusters, the cloud provider takes care of all the TLS requirements as it is their responsibility to manage control plane components.
However, if you are setting up a self-hosted cluster for production use, these certificates have to be requested from the organization‚Äôs network or security team. They will generate these certificates signed by the organization‚Äôs internal Certificate authority and provide them to you.
Any components that need to authenticate to the API server need thekubeconfig file.
All the cluster Kubeconfig files are present in the/etc/kubernetesfolder (.conf files). You will find the following files.
It contains the API server endpoint, cluster CA certificate, cluster client certificate, and other information.
Theadmin.conf,file, which is the admin kubeconfig file used by end users to access the API server to manage the clusters. You can use this file to connect the cluster from a remote workstation.
The Kubeconfig for the Controller manager, scheduler, and Kubelet is used for API server authentication and authorization.
For example, if you check the Controller Manager static pod manifest file, you can see thecontroller-manager.confadded as the authentication and authorization parameter.
Kubelet service runs as a systems service on all the cluster nodes.
You can view the kubelet systemd service under/etc/systemd/system/kubelet.service.d
Here are the system file contents.
I have highlighted two important kubelet configurations in bold.
The kubeconfig file will be used for API server authentication and authorization.
The/var/lib/kubelet/config.yamlcontains all the kubelet-related configurations. The static pod manifest location is added as part of thestaticPodPathparameter.
/var/lib/kubelet/kubeadm-flags.envfile contains the container runtime environment Linux socket and the infra container (pause container) image.
For example, here is the kubelet config that is using the CRI-O container runtime, as indicated by the Unix socket and the pause container image.
A pause container is a minimal container that is the first to be started within a Kubernetes Pod. Then the role of the pause container is to hold the networking namespace and other shared resources for all the other containers in the same Pod.
If you look at the kubelet configuration in the managed k8s cluster, it looks a little different than the kubeadm setup.
For example, here is a kubelet service file for anAWS EKS cluster.
Here you can see the container runtime is containerd and its Unix socket flag is directly added to the service file
The kubelet kubeconfig file is in a different directory as compared to kubeadm configurations.
CoreDNSaddon components deal with the cluster DNS configurations.
All the CoreDNS configurations are part of a configmap named CoreDNS in the kubesystem namespace.
If you list theConfigmapsin the kube-system namespace, you can see the CoreDNS configmap.
use the following command to view theCoreDNSconfigmap contents.
You will see the following contents.
When it comes to DNS connectivity, applications may need to connect to:
If you have a use case where you need to have custom DNS servers, for example, the applications in the cluster need to connect to private DNS endpoints in the on-premise data center, you can add the custom DNS server to the core DNS configmap configurations.
For example, let‚Äôs say the custom DNS server IP is10.45.45.34and your DNS suffix isdns-onprem.com, we have to add a block as shown below. So that all the DNS requests related to that domain endpoint will be forwarded to10.45.45.34DNS server.
Here is the full configmap configuration with the custom block highlighted in bold.
When it comes to production clusters, audit logging is a must-have feature.
Audit logging is enabled in thekube-api-server.yamlstatic pod manifest.
The command argument should have the following two parameters. The file path is arbitrary and it depends on the cluster administrator.
audit-policy.yamlcontains all the audit policies andaudit.logfile contains the audit logs generated by Kubernetes.
I have made a video explaining the Kubernetes configuration. You can watch the video on Youtube. Here is the embedded video.
It is very important to know about kubernetes cluster configuration when working on real-time projects.
When it comes to self-hosted Kubernetes clusters, which primarily happen in on-premise environments, you need to know each and every configuration of the cluster control plane and the worker nodes.
Although there are automation tools available to set up the whole cluster, you need to work on the following.
When it comes to managed kubernetes clusters, you will not have access to the control plane components.
However, having good knowledge of the cluster configuration would help during implementation and discussions with the cloud support teams to fix cluster-related issues.
In this guide, we have looked at the important Kubernetes cluster configurations that would help you in Kubernetes cluster administration activities.
Also, you can check out the detailed blog onProduction Kubernetes cluster activities.
If you want to level up your kubernetes skills, check out my 40+ comprehensivekubernetes tutorials.
Dans ce guide, nous explorerons ce que sont les pluginsChatGPTet je vous montrerai comment activer et utiliser les plugins dans ChatGPT.
Voici ce que dit le site officiel d'OpenAI √† propos des plugins ChatGPT.
Les plugins sont des outils con√ßus sp√©cifiquement pour les mod√®les de langage avec la s√©curit√© comme principe de base et aident ChatGPT √† acc√©der √† des informations √† jour, √† ex√©cuter des calculs ou √† utiliser des services tiers.
Pour faire simple :
Si vous avez un produit et que vous souhaitez que les gens l'utilisent via ChatGPT, vous pouvez cr√©er un plugin avec des sp√©cifications et des normes fournies par OpenAI. ChatGPT acceptera les invites des utilisateurs et utilisera le service h√©berg√© par le plugin correspondant pour fournir les informations ou le service demand√©s.
Par exemple, il existe un plugin ChatGPT appel√© ChatWithPDF. √Ä l'aide de ce plugin, vous pouvez fournir une URL PDF et ChatGPT peut comprendre ce qu'il contient. Supposons qu'il existe un PDF qui est un livreKubernetes. Vous pouvez fournir une invite indiquant¬†: ¬´¬†√ânum√©rez tous les concepts importants expliqu√©s dans statefulset¬†¬ª.
√Ä un niveau √©lev√©, voici quelques choses que vous pouvez r√©aliser avec les plugins ChatGPT. Veuillez noter que les fonctionnalit√©s ne se limitent pas √† celles-ci, mais ces exemples devraient vous donner une id√©e de ce qui peut √™tre fait avec les plugins¬†:
N'oubliez pas qu'il ne s'agit l√† que de quelques exemples. Les possibilit√©s offertes par les plugins ChatGPT sont vastes et peuvent √™tre adapt√©es √† vos besoins sp√©cifiques.
Remarque¬†: vous devez disposer d'un abonnement ChatGPT plus pour activer la fonctionnalit√© des plugins.
Vous pouvez activer les plugins ChatGPT en seulement deux √©tapes.
√âtape 1¬†:Cliquez sur les trois points dans l‚Äôoption de profil pr√©sente dans le coin inf√©rieur gauche et cliquez sur les options de configuration comme indiqu√© dans l‚Äôimage ci-dessous.
√âtape 2¬†:s√©lectionnez l‚Äôoption ¬´¬†Fonctionnalit√©s b√™ta¬†¬ª et activez le bouton bascule du plug-in comme indiqu√© ci-dessous.
Maintenant que nous avons activ√© les plugins, voyons comment nous pouvons installer un plugin.
L'installation du plugin est assez simple.
√âtape 1 : Cr√©ez une nouvelle discussion et s√©lectionnez l'option GPT-4. Vous verrez l'option des plugins comme indiqu√© ci-dessous.
√âtape 2 :Si vous cliquez sur l'option plugins, vous verrez l'option de magasin de plugins. Cliquez dessus pour acc√©der √† tous les plugins disponibles.
√âtape 3 :√Ä partir de la liste des plugins disponibles, vous pouvez installer les plugins requis. Il existe √©galement une barre de recherche dans laquelle vous pouvez rechercher des plugins.
Les plugins ne sont pris en charge qu'avec GPT-4. Dans la liste d√©roulante des plugins de l'onglet GPT-4, vous pouvez s√©lectionner les plugins requis comme indiqu√© ci-dessous
Lorsque vous fournissez une invite, ChatGPT utilise le plugin appropri√© pour vous fournir le r√©sultat.
Par exemple, si vous avez install√© le plugin AskYourPDF et si vous fournissez une invite avec un lien PDF pour r√©sumer le PDF, vous obtiendrez le r√©sum√© du PDF.
Le gif suivant montre la d√©monstration de l'utilisation d'un plugin avec ChatGPT.
Il existe √©galement des plugins qui permettent de r√©sumer automatiquement les vid√©os YouTube √† l'aide de leurs transcriptions. De cette fa√ßon, vous n'avez pas besoin d'√©couter toutes les vid√©os.
Tout le monde peut cr√©er un plugin ChatGPT. Vous devez suivre les sp√©cifications du plugin d'OpenAPI.
Voici un diagramme de haut niveau qui montre l'architecture du plugin ChatGPT.
Les plugins ChatGPT sont parfaits pour am√©liorer votre exp√©rience avec l'IA g√©n√©rative.
Il est toutefois essentiel de faire preuve de prudence lors de l‚Äôutilisation de ces outils, en particulier avec des donn√©es confidentielles ou organisationnelles.
En effet, les plugins sont des services tiers et ils auront acc√®s √† toutes les donn√©es que vous leur soumettez. Par cons√©quent, pour pr√©server la confidentialit√© et la s√©curit√© des donn√©es, √©vitez d'utiliser des informations sensibles avec ces applications.
Je partagerai des id√©es surl'apprentissage des outils CI/CDet la mise en ≈ìuvre des meilleures pratiques dans ce blog.
Pour les ing√©nieurs DevOps, apprendre un outil est devenu facile de nos jours avec une documentation pr√™te √† l'emploi,ChatGPT, des tutoriels YouTube gratuits et des blogs.
Cependant, vous pouvez am√©liorer votre apprentissage en mettant en ≈ìuvre les meilleures pratiques et les flux de travail standard du secteur pendant le processus d‚Äôapprentissage.
Il existe de nombreux outils pour le CI/CD. Si vous consultez ma listed'outils DevOps, vous trouverez plus de15 outils pour le CI/CD. Il y en a toujours plus.
Les principes et les workflows de base du CI/CD restent les m√™mes quel que soit votre outil. Chaque outil peut avoir sa propre syntaxe et ses propres configurations pour cr√©er un pipeline.
Alors, quel est le meilleur outil CI/CD ?
Vous pouvez d√©battre toute la journ√©e du meilleur outil. La plupart des outils suivent le m√™me mod√®le.
Vous d√©clarez votre workflow dans Git et l'outil l'ex√©cute. Que ce soit Jenkins, GitHub Actions, Gitlab CI, Circle CI, etc.
Si vous apprenez correctement un outil, vous pouvez apprendre d‚Äôautres outils rapidement.
Ce blog n'a pas pour vocation de vous proposer un tutoriel sur des outils sp√©cifiques, mais plut√¥t uneliste de bonnes pratiqueset de workflows. Ainsi, lors du choix des outils √† apprendre, vous pouvez suivre ces bonnes pratiques et d√©velopper les pipelines.
En ce qui concerne DevOps, CI/CD s‚Äôapplique √† la fois au code d‚Äôapplication etau code d‚Äôinfrastructure (IaC).
Nous devons passer par le processus de test et de r√©vision avant de d√©ployer le code d'application/les codes d'infrastructure dans un environnement.
Par exemple, le code d‚Äôapplication passe par des tests unitaires, une analyse de code statique, une analyse de vuln√©rabilit√©, etc. Nous devons √©galement suivre la m√™me proc√©dure pour le code d‚Äôinfrastructure.
J'ai class√© les meilleures pratiques sous diff√©rents titres. Entrons directement dans le vif du sujet.
La gestion de la configuration est un aspect essentiel d'un syst√®me CI/CD.
Par exemple, des points de terminaison tels que l'URLNexus, l'URLSonarqube, les points de terminaison du scanner de vuln√©rabilit√©, les points de terminaison d'API, etc.
Utilisez toujours des variables globales pour stocker les points de terminaison et les configurations communes. En cas de changement, il vous suffit de modifier la variable globale au lieu d'effectuer des modifications dans chaque pipeline.
Tous les outils CI/CD prennent en charge le stockage de variables globales et vous permettent d'acc√©der aux variables globales dans le pipeline.
Uber a pay√© des pirates informatiquespour cacher une violation de donn√©es impliquant 57 millions d'utilisateurs.
Savez-vous comment c'est arriv√© ?
Les pirates ont eu acc√®s auxinformations d'identification AWS enregistr√©es dans ler√©f√©rentiel GitHub.
Chaque syst√®me CI/CD doit g√©rer des secrets. Il peut s'agir de jetons d'API, d'identifiants de base de donn√©es, d'identifiants cloud, de jetons de compte de service, etc. Vous devez suivre les principes DevSecOps lorsque vous traitez des secrets pour CI/CD.
Aucun secret ne doit √™tre cod√© en dur ou stock√© dans le syst√®me CI ou Git sous forme de texte brut. Utilisez toujours unsyst√®me de gestion des secretsdans lequel l'outil CI/CD r√©cup√®re les secrets requis lors de l'ex√©cution.
Les outils de gestion des secrets offrent diff√©rents m√©canismes pour acc√©der aux secrets en cours d'ex√©cution en toute s√©curit√©
De plus, vous devez vous assurer que les secrets utilis√©s par les pipelines n'apparaissent pas dans les journaux.
Hashicorp Vault, AWS secrets manager et Google secret manager sont des exemples de solutions de gestion de secrets externes.
DRY ‚Äì ¬´ Ne vous r√©p√©tez pas ¬ª
D√®s le d√©but, vous devez travailler √†minimiser les doublons de code CI/CD. Un projet peut avoir de nombreux pipelines avec des √©tapes communes.
Un tel exemple est une construction Maven.
Supposons que vous ayez50 servicesqui n√©cessitent une build Maven et que vousdupliquiezle code pour50 pipelines. Ce n'est pas du tout une solution √©volutive.
Il est donc pr√©f√©rable de d√©velopper des biblioth√®ques ou des workflows communs et de r√©utiliser les √©tapes dans les pipelines au lieu de les r√©p√©ter pour chaque service.
Par exemple,la biblioth√®que partag√©e Jenkinset les workflows communs GitHub Actions vous permettent de r√©utiliser les workflows existants pour les pipelines.
Remarque: il est parfois difficile de d√©velopper des modules communs qui r√©pondent √† toutes les exigences. Dans ce cas, vous pouvez √©tendre les modules r√©utilisables pour r√©pondre aux exigences sp√©cifiques du projet.
Nous sommes dans l'√®re de GitOps.
Chaque pipeline doit faire partie de Git et √™tre test√© pour chaque PR.
Ne cr√©ez pas ou ne d√©clenchez pas manuellement de pipelines, du moins pendant le d√©veloppement. Cela entra√Æne des incoh√©rences et des erreurs humaines. Pour le code d'application et d'infrastructure, chaque PR doit √™tre automatiquement test√© avant d'√™tre valid√© dans les branches (enregistrement bloqu√©).
Le d√©ploiement dans des environnements sp√©cifiques tels que la pr√©paration ou la productionpeut n√©cessiter une intervention manuelle. Cela est principalement d√ª aux politiques organisationnelles, √† la conformit√© r√©glementaire ou √† la n√©cessit√© deprocessus d'approbation sp√©cifiques.
Par exemple, une modification de code peut n√©cessiter l‚Äôapprobation des √©quipes d‚Äôassurance qualit√©, des √©quipes de performance, des √©quipes de s√©curit√© et des parties prenantes de l‚Äôentreprise avant d‚Äô√™tre d√©ploy√©e dans un environnement de production.
Lorsque nous utilisons des outils CI/CD dans un r√©seau ouvert, nous pouvons acc√©der √† toutes les ressources disponibles en ligne, et vous pouvez les t√©l√©charger et les utiliser √† tout moment.
However, in real projects, CI/CD tools are set up in a private network behind forward proxies like Squid. You might need approval to download resources from the internet. This will be allowed only for official Linux repositories or dependency managers like Maven.
Most companies block public container registries like Docker Hub. So when you implement solutions, use private registries and official resources.
Create libraries and documents so anyone can onboard a new service without the knowledge of the tool.
Some companies have platform teams who offer these generic templates as part of theInnerSourceefforts.
And different teams in an organization contribute to the InnerSource to make it better.
Develop pipeline libraries that everyone in the team understands. Just because you can create a complex library doesn‚Äôt mean you have to. Always think from a team perspective.
For example, you can create a shared library usingJenkins pipelineDSL and pure Groovy code. If your DevOps team needs to gain a skillset to develop in Groovy, you should stick with DSL. Developing in pure Groovy would be an overhead for the team when a change is required.
Every CI/CD tool has the concept of build agents. To save cost and separation of concerns, it‚Äôs good to leverage ephemeral build agents. Meaning the agents get deployed only when needed.
You can call them dynamic agents or on-demand agents.
Every build would be running on an agent from a specific template, and it ensures consistency in the build environments.
The ephemeral agent could be a VM,Docker container, or evenKubernetes pod. Most CI/CD tools support ephemeral agents.
For example, you can integrate Jenkins with theKubernetes clusterand configure jobs to spin up kubernetes pods as build agents.
GitHub actions by default support container-based agents or runners.
En tant qu'ing√©nieurDevOps, il est essentiel d'apprendre les concepts de base de Git. Dans ce blog, je parlerai deGit pour DevOpset de la raison pour laquelle Git est une comp√©tence importante pour un ing√©nieur DevOps. J'ai √©galement r√©pertori√© les ressources pertinentes pour apprendre Git de la bonne mani√®re.
Git est un syst√®me de contr√¥le de version distribu√© open source. Il est tr√®s l√©ger et fonctionne sur presque tous les syst√®mes d'exploitation.
En 2005, Linus Torvalds a cr√©√© git comme syst√®me de contr√¥le de version distribu√© lorsque l'√©quipe de d√©veloppement du noyau Linux ne pouvait plus utiliser BitKeeper gratuitement.
Git est d√©sormais le syst√®me de contr√¥le de version de facto utilis√© par les d√©veloppeurs du monde entier. Sa nature distribu√©e facilite le d√©veloppement, le suivi et la collaboration avec les modifications de code.
Les r√©sultatsde l‚Äôenqu√™te aupr√®s des d√©veloppeurs StackOverflowpr√©sent√©s ci-dessous montrent que93 % des ing√©nieurs utilisent Gitet qu‚Äôil s‚Äôagit d‚Äôun outil fondamental pour eux.
Quand nous disons git, la plupart des nouveaux apprenants d‚Äôaujourd‚Äôhui font r√©f√©rence √† Github.
Des plateformes commeGitHub ou Bitbucketsont construites sur Git avec des fonctionnalit√©s suppl√©mentaires qui aident les ing√©nieurs et les organisations √† h√©berger et √† contr√¥ler les versions du code dans le r√©f√©rentiel Git distant. De plus, il est dot√© de bonnes int√©grations pour fonctionner avec d'autres outils CI/CD open source.
Avec GitHub Actions, vous pouvez configurer l'ensemble du pipeline CI/CD en utilisant les plateformes GitHub et Gitlab elles-m√™mes. Cela √©limine le besoin de g√©rer plusieurs outils pour CI/CD.
Examinons les facteurs cl√©s pour lesquels Git est n√©cessaire pour DevOps.
L'une des t√¢ches d'un ing√©nieur DevOps est deconcevoir et de d√©velopper des pipelines CI/CD. Git joue un r√¥le cl√© dans le CI/CD. D'apr√®s mon exp√©rience de travail dans diff√©rentes entreprises, je peux dire qu'il n'existe pas de norme unique pour la ramification et les flux de travail Git. Parfois, vous devez vous asseoir avec les d√©veloppeurs et discuter de la bonne approche pour la ramification Git dans le pipeline CI/CD. Cela inclut le balisage Git, la gestion des versions, etc.
En fait, dans la plupart des organisations, les ing√©nieurs DevOps poss√®dent et exploitent les r√©f√©rentiels Git.
Ainsi, pour avoir une discussion significative avec les √©quipes de d√©veloppement, vous devez avoir une bonne connaissance de Git.
De plus, lorsque nous parlons d'infrastructure en tant que code, nous d√©veloppons et maintenons tout le code d'infrastructure dans Git. Qu'il s'agisse d'unpipeline Jenkins, d'un playbook Ansible ou d'un module Terraform.
We treat infra code the same way application code is treated. Meaning, infra code goes through the same unit testing and integration tests before getting deployed to any environment.
It means, even the infrastructure code needs to have a CI/CD pipeline. That again translates to git-based workflows.
Most companies do not follow test-driven development for infra code, but it is the standard way of developing infrastructure code.
With technicalpractices like GitOps, git acts as a source of truth for all the infrastructure configurations.
With Gitops, any change in git repo configs gets deployed in the infrastructure.
So it is a must for DevOps engineers to know all about git.
Also, tools like ArgoCD have the whole workflows around gitOps practice.
Here is the roadmap on how you can learn git.
If you are looking for guided courses to learn git, I have picked the following best resources to learn git the right way.
When it comes to DevOps interview questions, it‚Äôs more about practical scenarios. So most of the Git devops interview questions will be based on real-time scenarios of the particular project you are getting interviewed for.
You can learn about the generic git functionalities using the resources I mentioned above. You should be able to answer all the generic git questions.
However, if you don‚Äôt have experience in working with git in real-time projects, I have a solution for you.
Go toStackoverflow git tag, and browse for specific git topics. For examplegit rebase. It should bring up many real-time scenarios and issues people are facing as shown in the image below.
You will get a lot of information that can help you in the interviews.
Another place you can look for is,Reddit Git. Here also you can find many conversations on git that will be helpful for learning and interviews.
Following are the important git concepts you shouldlearn for DevOps interviews
Git est un syst√®me de contr√¥le de version simple, mais il existe des outils puissants autour de Git pour l'automatisation DevOps.
Une fois que vous avez appris les bases, il est pr√©f√©rable de cr√©er vos propres d√©p√¥ts de code et d'essayer toutes les fonctionnalit√©s avanc√©es de Git. Pour conserver vos connaissances, vous pouvez documenter toutes les fonctionnalit√©s Git que vous avez apprises dans un d√©p√¥t Git.
De plus, si vous souhaitez apprendre Linux, consultez mon guide surla fa√ßon d‚Äôapprendre les scripts shell Linux.
Apprendre √† utiliser Kubernetespeut sembler compliqu√©. Il s'agit d'un syst√®me d'orchestration de conteneurs complexe dont la courbe d'apprentissage est abrupte. Mais avec la bonne feuille de route et la compr√©hension des concepts fondamentaux, c'est quelque chose que tout d√©veloppeur ou responsable des op√©rations peut apprendre.
Dans cette feuille de route d‚Äôapprentissage de Kubernetes, j‚Äôai ajout√© des pr√©requis et un parcours d‚Äôapprentissage complet qui couvre les concepts Kubernetes de base √† avanc√©s.
Avant de vous lancer dans l‚Äôapprentissage de Kubernetes, vous devez avoir une bonne connaissance de certaines des technologies et concepts sous-jacents.
Comprendre l'architecture de Kubernetes n'est pas une t√¢che facile. Le syst√®me comporte de nombreux √©l√©ments mobiles qui doivent √™tre compris pour que vous puissiez comprendre ce qui se passe sous la surface. En apprenant l'architecture, vous rencontrerez les concepts que nous abordons dans les pr√©requis.
Kubernetes √©tant un syst√®me complexe, il peut √™tre difficile pour les ing√©nieurs DevOps de comprendre l'architecture de base. √Ä mesure que vous acquerrez de l'exp√©rience pratique, vous serez en mesure de mieux comprendre l'architecture de base.
Voici ma suggestion.
Apprenez l'architecture de haut niveau et les composants cl√©simpliqu√©s dans Kubernetes. Si vous n'√™tes pas en mesure de saisir le concept, vous pouvez soit consacrer du temps √† faire des recherches suppl√©mentaires sur un sujet sp√©cifique, soit apprendre le concept en faisant des exercices pratiques. C'est votre choix.
Consultez leguide d'architecture Kubernetespour en savoir plus sur tous les composants Kubernetes en d√©tail.
Dans l‚Äôensemble, vous devez apprendre ce qui suit.
Note: For DevOps interviews, ensure you have a very good understanding of Kubernetes architecture and how all the components interact with each other.
Deploying big clusters on the cloud could be expensive. So make use of the following cloud credits and learn to launch clustersas if you would on a real-time project. This will give you a sense of confidence in the process.
All platforms offer managed k8s services.
Use one account at a time. Once the credits have expired. move to the next account. You need to keep a watch on your credits as well as expiry. Or else you could get charged. Also, check the terms and instance usage limits if any.
Also, setting up servers on this platform is very easy and every cloud provider has extensive documentation to get started.
ForDevOps engineers, it‚Äôs important to understand every component and cluster configuration. While there are many options to deploy a Kubernetes cluster, It is always better to learn to deploy multi-node clusters from scratch.
With multi-node clusters, you can learn about all the concepts like Cluster security,High Availability, Scaling, Networking, etc.
It gives you thefeeling of working on a real-world project. It will also help you in interviews and you can be confident about production-level cluster configurations.
Following are my cluster setup suggestions.
Once you have a working cluster, you should learn about thekey cluster configurations. This knowledge will be particularly helpful when working in a self-hosted Kubernetes setup.
Even if you use a managed Kubernetes cluster for your project, there may be certain cluster configurations that you need to modify.
For example, if you set up a cluster in a hybrid network, you may need to configure it with anon-premises private DNSserver for private DNS resolution. This can be done via CoreDNS configuration.
Refer to theKubernetes Cluster configurationsguide for more details.
Also, having a solid understanding of cluster configurations will help you with Kubernetes certifications (CKA & CKS) where you need to troubleshoot cluster misconfiguration and issues.
Kubeconfigfile is a YAML file that contains all the cluster information and credentials to connect to the cluster.
As a Devops Engineer, You should learn to connect to kubernetes clusters in different ways using the Kubeconfig file. Because you will be responsible for setting up clusterauthentication for CI/CD systems, providing cluster access to developers, etc.
So spend some time, understanding the Kubeconfig file structure and associated parameters.
Check out thecomplete Kubeconfig file guideto learn everything about the Kubeconfig file.
You will quite often come across the names ‚ÄúKubernetes Object‚Äù and ‚ÄúKubernetes Resource‚Äú
First, you need to Understand the difference between an object and a resource in kubernetes.
To put it simply, anything auser creates and persists in Kubernetes is an object. For example, a namespace, pod, Deployment configmap, Secret, etc.
Before creating an object, you represent it in a YAML or JSON format. It is called anObject Specification (Spec). You declare the desired state of the object on the Object Spec. Once the object is created, you can retrieve its details from the Kubernetes API using Kubectl or client libraries.
As we discussed earlier in the prerequisite section, everything in Kubernetes is an API. To create different object types, there areAPI endpoints provided by the Kubernetes API server. Thoseobject-specific api-endpoints are called resources. For example, an endpoint to create a pod is called apod resource.
So when you try to create a Kubernetes Object using Kubectl, it converts the YAML spec to JSON format and sends it to the Pod resource (Pod API endpoint).
You can refer to theKubernetes objects vs resourceguide for more details.
Once you have an understanding of Kubernetes Objects and resources, you can start with a native Kubernetes object called Pod. A pod is a basic building block of Kubernetes.
You should learn all thePod conceptsand their associated objects likeService, Ingress, Persistent Volume, Configmap, and Secret. Once you know everything about a pod, it is very easy to learn other pod-dependent objects like deployments, Daemonset, etc.
First, learn about the Pod Resource Definition (YAML). A typical Pod YAML contains the following high-level constructs.
Refer toKubernetes Pod Explainedblog to learn all the basics about Pod.
Once you have a basic understanding of the above, move on to hands-on learning. These concepts will make more sense when you do hands-on.
Following are thehands-on tasksto learn about Pod and its associated objects.
Few advanced pod scheduling concepts.
Now that you have a better understanding of Pod and independent kubernetes resources, you can start learning about objects that are dependent on the Pod object. While learning this, you will come across concepts like HPA (Horizontal Pod Autoscaling) and VPA (Verification Pod Autoscaling)
To expose applications to the outside world or end users, kubernetes has a native object called ingress.
Many engineers get confused with Ingress due to less knowledge of Ingress controllers. Ensure you go through the concept of Ingress and Ingress controllers and understand it correctly. Because it is the base of exposing applications to the outside world.
You can start with the following comprehensive guides.
Also, learn about theKubernetes Gateway API. It provides advanced features over Ingress.
Once you understand the basics of these objects, you can try deploying an end-to-end microservices application on Kubernetes. Start with simple use cases and gradually increase complexity.
I would suggest you get a domain name and try setting up a microservice application from scratch and host it on your domain.
You don‚Äôt need to develop an application for this. Choose any open-source microservice-based application and deploy it. My suggestion is to choose the open-sourcepet clinic microservice applicationbased on Spring Boot.
Following are the high-level tasks.
Security is a key aspect of Kubernetes. There are many ways to implement security best practices in Kubernetes starting from building a secure container image.
Following the native ways of implementing security in kubernetes.
The following are the open-source tools you need to look at.
Now that you have a good understanding of all Kubernetes objects and deploying applications on Kubernetes, you can start learning about Kubernetes configuration management tools.
When you start working on a real-time project in an organization, you will see the usage of configuration management tools to deploy applications on Kubernetes.
Because in organizations, there are different environments like dev, stage, pre-prod, and production. You cannot create individual YAML files for each environment and manage them manually. So you need a system to manage Kubernetes YAML configurations effectively.
Following are the popular and widely adopted Kubernetes tools to manage YAML.
Kubernetes Operators is an advanced concept.
To understand operators, first, you need to learn the following Kubernetes concepts.
To get started with operators, you can try setting the following operators on Kubernetes.
If you are a Go developer or you want to learn to extend/customize kubernetes, I would suggest youcreate your own operatorusing Golang.
While learning kubernetes, you might use a cluster in open network connectivity.
So most of the tasks get executed without any issues. However, this is not the case with clusters set up on corporate networks.
So, here are some custom cluster configurations you should be aware of
Following are the resources that might help and add value to the Kubernetes learning process in terms of best practices.
Following are the list of the best online resource to learn Kubernetes practically.
The official Kubernetes website has browser-based hands-onkubernetes basic tutorialspowered by Katacoda scenarios. It covers the following.
You can also look at officialKubernetes tasksto learn to implement Kubernetes concepts practically. It will also help you prepare for Kubernetes certifications.
DevOpsCube has 35+ comprehensiveKubernetes hands-on tutorialsfor beginners to advanced users. You will learn everything from Kubernetes architecture, Cluster setup, Deployments, best practices, package management, secret management, monitoring, logging, etc.
If you want to learn Kubernetes from the comfort of your browser,Killercodais a great option. It offers scenario-based learning playgrounds on the browser.
The full Kubernetes learning guide is added to theKubernetes learning path GitHub repowith links to all the free useful resources.
This repo is maintained and contributed by community members and it has the following.
Let‚Äôs have a look at some of the best ways to learn Kubernetes.
You could fall under any of the following categories.
When I spoke to the DevOps community, I found that a common issue was the lack of real-world experience with Kubernetes. If you don‚Äôt have an active Kubernetes project in your organization, you can refer to case studies and learning materials published by organizations that use Kubernetes. This will also help you in Kubernetes interviews.
Here are some good real-world Kubernetes case studies that can enhance your Kubernetes knowledge:
Lors de votre apprentissage de Kubernetes, il est pr√©f√©rable de suivre les derni√®res versions et les nouvelles fonctionnalit√©s de Kubernetes. Je continuerai √† mettre √† jour les derni√®res informations sur les versions et la liste des fonctionnalit√©s.
Dans ce parcours d'apprentissage, j'ai abord√© tous les concepts importants dont vous avez besoin pour ma√Ætriser Kubernetes. Je continuerai √† ajouter de nouvelles fonctionnalit√©s lorsque les nouvelles versions de Kubernetes seront publi√©es.
De plus, l'apprentissage d'une nouvelle comp√©tence technique n√©cessite des heures de pratique. Vous acquerrez certainement une bonne compr√©hension de Kubernetes au cours du processus d'apprentissage, mais la v√©rit√© est que vous n'arr√™tez jamais d'apprendre.
J'ai commenc√© mon parcours Kubernetes en 2014 et j'apprends constamment de nouveaux concepts et fonctionnalit√©s.
Bibin Wilson est un consultant cloud et DevOps avec plus de 10 ans d'exp√©rience en informatique. Il poss√®de une vaste exp√©rience pratique des plateformes de cloud public, de l'h√©bergement cloud, des d√©ploiements Kubernetes et OpenShift en production. Il est l'auteur de plus de 300 tutoriels techniques, fournissant des informations pr√©cieuses √† la communaut√© DevOps. Ses cours sur techiescamp.com offrent des conseils pratiques et des exemples concrets aux professionnels qui souhaitent exceller dans le cloud, DevOps et l'automatisation des infrastructures.
I would love to lean K8s from you guys do you have instructor led classes? One on one or learn with a group?
Hi Ozzy,
We have a CKA course in progress. You can join that to learn administrative aspects of Kubernetes. You can also be a part of a online cohort to preapre for CKA along with learning.
Beautiful. Thanks Bibin. Great job
Good Article dear friend !!!
Thank you for the details article. You have covered all the points.Can you help how to prepare a resume from Docker and K8s perspective?
Really nice blog. I have started learning DevOps journey and DevOpsCube is one of the best source for DevOps.
One thing, I‚Äôm also planning to start WordPress blog. May I know which plugin did you use for list or any CSS code?
Your email address will not be published.Required fields are marked*
Comment*
Name*
Email*


Œî
Dans ce didacticiel Kubernetes, vous apprendrez la sauvegarde et la restauration etcd sur un cluster Kubernetes avec un instantan√© etcd.
Dans l'architecture Kubernetes, etcd fait partie int√©grante du cluster. Tous les objets du cluster et leur √©tat sont stock√©s dans etcd. Quelques √©l√©ments √† conna√Ætre sur etcd du point de vue de Kubernetes.
Si vous souhaitez en savoir plus sur etcd et sur la mani√®re dont Kubernetes l'utilise, je vous recommande de lire l'article completsur l'architecture de Kubernetes.
De plus, si vous consid√©rezles meilleures pratiques de conception de Kubernetes, la sauvegarde et la restauration de Kubernetes etcd sont l‚Äôun des aspects importants de la strat√©gie de sauvegarde.
Voici ce que vous devez savoir sur la sauvegarde etcd.
Suivez les √©tapes ci-dessous pour prendre un instantan√© etcd.
√âtape 1¬†:connectez-vous au plan de contr√¥le.
√âtape 2¬†:si vous n‚Äôavez pas etcdctl dans votre plan de contr√¥le de cluster, installez-le √† l‚Äôaide de la commande suivante.
√âtape 3¬†:nous devons transmettre les trois informations suivantes pouretcdctlprendre un instantan√© etcd.
Vous pouvez obtenir les d√©tails ci-dessus de deux mani√®res.
√Ä partir du fichier manifeste du pod statique etcd situ√© √†/etc/kubernetes/manifests/etcd.yamll‚Äôemplacement.
Vous pouvez √©galement obtenir les d√©tails ci-dessus end√©crivant le pod etcd ex√©cut√©dans l'kube-systemespace de noms.
Lors de la description du pod, remplacez-leetcd-master-nodepar le nom de votre pod etcd.
Une autre fa√ßon d‚Äôafficher plus rapidement les param√®tres du serveur etcd consiste √† utiliser la commande suivante.
Choisissez une m√©thode avec laquelle vous √™tes √† l‚Äôaise pour obtenir les d√©tails du certificat.
√âtape 4¬†:effectuez une sauvegarde instantan√©e d‚Äôetcd √† l‚Äôaide de la commande suivante.
La commande ressemble √† ce qui suit lorsque vous ajoutez l'emplacement et les param√®tres r√©els. Ex√©cutez la commande pour effectuer une sauvegarde. Vous pouvez remplacer/opt/backup/etcd.dbpar l'emplacement et le nom de votre choix.
Lors d'une ex√©cution r√©ussie, vous obtiendrez un message ¬´ Snapshot enregistr√© dans /opt/backup/etcd.db ¬ª, comme indiqu√© ci-dessous.
Also, you can verify the snapshot using the following command.
Here is an example output.
Now we have the backup in the/opt/backup/etcd.dblocation. We will use the snapshot backup to restore etcd.
Here is thecommand to restore etcd.
Let‚Äôs execute the etcd restore command. In my case/opt/backup/etcd.dbis the backup file.
If you want to use a specific data directory for the restore, you can add the location using the--data-dirflag as shown below.
After restoring, we need to update the/etc/kubernetes/manifests/etcd.yamlas in the configuration it points to the older path.
We have now restored the etcd snapshot to a new path so the only change to be made in the YAML file, is to change thehostPathfor the volume calledetcd-datafrom the old directory (/var/lib/etcd) to the new directory (/opt/etcd).
Edit theetcd.yamland change the volume:
The etcd pod will be automatically created with new configuration and you would be able to see the previous data.
Also, if you want to change--data-dirto/opt/etcdin the etcd manifest, make sure that thevolumeMountsforetcd-datais updated as well, with themountPathpointing to/opt/etcd
To take the etcd backup, you need to the etcdctl command line utility. You need to use the etcdctl snapshot command with the etcd certificates to perform a backup operation.
In this blog, we learnedKubernetes etcd backup and restoreusingetcdctlcommand line utility.
etcd backup, and restoreare essential tasks in Kubernetes cluster administration. Also, it is an important topic in the CKA certification exam.
If you are preparing for the CKA exam, do check out theCKA exam study guideand for the exam discount voucher, check theKubernetes certification coupon.
Dans ce blog, vous d√©couvrirez ce qu'est EKS Anywhere et commentconfigurer un cluster de d√©veloppement EKS Anywhereet l'enregistrer sur la console AWS EKS √† l'aide du connecteur EKS.
EKS Anywhere est une fonctionnalit√© AWSpermettant d'ex√©cuter et de g√©rer des clusters EKS dans des environnements sur site. Elle simplifie la gestion de Kubernetes sur site et permet une exp√©rience Kubernetes coh√©rente dans un d√©ploiement Kubernetes multicloud. De plus, vous aurez un contr√¥le total sur le plan de contr√¥le et les n≈ìuds de travail.
EKS Anywhere utiliseAmazon EKS Distro (EKS-D), une distribution Kubernetes personnalis√©e et open source par AWS. Il s'agit de la m√™me distribution qui alimente EKS g√©r√© par AWS. Cela signifie que lorsque vous installez EKS Anywhere, il est fourni avec des param√®tres et des configurations optimis√©s pour AWS.
Vous pouvez √©galement enregistrer les clusters EKS Anywhere sur la console AWS EKS √† l'aide duconnecteur EKS.Une fois le cluster enregistr√©, vous pouvez visualiser tous les composants du cluster Anywhere dans la console AWS EKS.
Le connecteur EKSest un Statefulset qui ex√©cute l'agent AWS System Managerdans votre cluster. Il est responsable du maintien de la connexion entre le cluster EKS Anywhere et AWS.
Voici les principaux cas d‚Äôutilisation d‚ÄôEKS Anywhere¬†:
Vous pouvez configurer des clusters de d√©veloppement EKS n'importe o√π √† l'aide de Docker sur les syst√®mes MAC ou Ubuntu.
Suivez les √©tapes ci-dessous pour configurer le cluster de d√©veloppement EKS Anywhere.
Acc√©dez auxt√©l√©chargements Dockeret installez le bureau Docker sur MAC. Pour Ubuntu, utilisezce lien pour t√©l√©charger le package deb
Utilisateurs Mac, ouvrez le fichier suivant et remplacezdeprecatedCgroupv1-le par true. Red√©marrez ensuite le bureau Docker pour appliquer les modifications.
Sinon, vous obtiendrez l‚Äôerreur suivante.
G√©n√©rez la configuration du cluster EKS n'importe o√π √† l'aide de la commande suivante.
La configuration de votre cluster ressemblerait √† ce qui suit.
D√©ployez le cluster √† l'aide deeksctl. Le provisionnement du cluster prendra un certain temps.
Vous obtiendrez le r√©sultat suivant apr√®s un d√©ploiement de cluster r√©ussi.
Une fois le cluster cr√©√©, vous pouvez voir un dossier nomm√©dev-eks-clusteravec le fichier kubeconfig. Exportons le fichier kubeconfig.
Remplacez-le/path/topar le chemin absolu de l'emplacement du dossier dev-eks-cluster. Ou consultez leguide du fichier Kubeconfigpour en savoir plus sur l'utilisation pratique du fichier kubeconfig.
Maintenant, listons les pods dans l'kube-systemespace de noms pour valider le cluster. Vous devriez voir tous les pods en cours d'ex√©cution comme indiqu√© ci-dessous.
Maintenant que nous disposons d‚Äôun cluster de d√©veloppement EKS Anywhere en cours d‚Äôex√©cution, nous allons continuer et enregistrer le cluster √† l‚Äôaide du connecteur EKS.
Remarque: avant d'enregistrer le cluster, assurez-vous que vous disposez d'une configuration AWS CLI valide avec des privil√®ges d'administrateur sur votre syst√®me. Reportez-vous auguide de configuration AWS CLIpour plus de d√©tails.
Voici la commande permettant de g√©n√©rer les fichiers YAML de configuration du connecteur EKS. Remplacez la valeur de la r√©gion si vous utilisez une autre r√©gion.
La commande ci-dessus cr√©e les trois fichiers YAML suivants. O√πeks-connector.yamlse trouve l'agent de connecteur EKS Statefulset YAML
D√©ployons les trois YAML.
Si vous vous dirigez vers la console AWS EKS, vous devriez voir le cluster nouvellement enregistr√© comme indiqu√© ci-dessous.
Si vous cliquez sur le nom du cluster, vous pouvez afficher toutes les informations et tous les objets du cluster EKS Anywhere ex√©cut√© sur votre poste de travail local.
Voici la d√©mo du connecteur EKS que j'ai ajout√©e √†la cha√Æne YouTube DevOpsCube.
Dans ce guide, nous avons examin√© la configuration du cluster de d√©veloppement Kubernetes EKS Anywhere. Il est assez facile de commencer. Essayez-le.
De plus, si vous recherchez des clusters de d√©veloppement Kubernetes l√©gers, consultez montutoriel minikube.
Si vous apprenez Kubernetes, consultez plus de 30tutoriels pour d√©butants sur Kubernetes.
Bibin Wilson est un consultant cloud et DevOps avec plus de 10 ans d'exp√©rience en informatique. Il poss√®de une vaste exp√©rience pratique des plateformes de cloud public, de l'h√©bergement cloud, des d√©ploiements Kubernetes et OpenShift en production. Il est l'auteur de plus de 300 tutoriels techniques, fournissant des informations pr√©cieuses √† la communaut√© DevOps. Ses cours sur techiescamp.com offrent des conseils pratiques et des exemples concrets aux professionnels qui souhaitent exceller dans le cloud, DevOps et l'automatisation des infrastructures.
Votre adresse email ne sera pas publi√©e.Les champs obligatoires sont marqu√©s*
Commentaire*
Nom*
E-mail*


Œî
