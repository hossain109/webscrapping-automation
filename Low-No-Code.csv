Title,Content
Transformer l'expérience des développeurs mainframe grâce à l'IA générative : une journée dans la vie d'un développeur,"<p>Entrez dans le monde d'Alex, un développeur mainframe chevronné qui doit relever le formidable défi de naviguer dans le labyrinthe d'un code complexe à modules multiples. Chaque jour, Alex est chargé de déchiffrer la logique complexe intégrée aux systèmes existants, où des applications vieilles de plusieurs décennies cohabitent avec les exigences modernes d'agilité et d'innovation.</p><p>Alors qu’Alex s’installe à son poste de travail, elle découvre le spectacle familier des lignes de code qui s’étendent à l’infini sur l’écran. Chaque ligne représente un morceau de l’héritage de l’organisation, un témoignage d’années de développement et de perfectionnement. Mais sous la surface se cache un réseau enchevêtré de dépendances et un héritage alourdi par sa propre complexité.</p><p>Aujourd’hui, la mission d’Alex est claire : apporter des modifications à un module essentiel qui sous-tend un processus métier clé. Cependant, la tâche est loin d’être simple. La base de code, un mastodonte tentaculaire de logique entrelacée, manque de documentation et de commentaires, ce qui en fait un défi de taille, même pour les développeurs les plus expérimentés. Il pourrait falloir au moins une journée à Alex pour comprendre ce qu’elle regarde, avant de commencer un véritable travail.</p><p>De plus, la culture de « peur du changement » qui règne dans l’entreprise en ce qui concerne le code mainframe (la direction et les développeurs hésitent à apporter des modifications au code monolithique par crainte de casser quelque chose par inadvertance) pèse lourdement sur les efforts d’Alex. Elle freine également l’innovation et le progrès, laissant l’organisation dans la stagnation.</p><h3>IA générative : transformer l'écosystème DevOps du mainframe</h3><p>Mais Alex ne recule pas devant un défi. Armée de sa détermination et des outils les plus récents, elle se lance à l’assaut d’une tâche apparemment insurmontable. C’est là qu’intervient l’intelligence artificielle générative (GenAI), une technologie révolutionnaire qui promet de transformer la façon dont les développeurs comme Alex interagissent avec les applications mainframe et d’améliorer l’expérience des développeurs.</p><p>GenAI est en passe de devenir la solution incontournable pour améliorer le parcours du développeur d'applications dans le DevOps mainframe en raison de sa capacité innée à comprendre, guider et améliorer les tâches liées au code. Contrairement aux méthodologies d'IA traditionnelles, qui se concentrent principalement sur l'optimisation du système et la détection des anomalies, GenAI transcende ces limites en participant activement au cycle de vie du développement logiciel.</p><p>GenAI est le guide d'Alex dans le labyrinthe de la complexité. Grâce à ses capacités avancées de traitement du langage naturel (NLP), il offre des informations inégalées sur le fonctionnement interne de la base de code, démêlant ses mystères avec facilité. L'époque où il fallait déchiffrer minutieusement une logique non documentée est révolue ; avec GenAI, Alex peut désormais naviguer dans la base de code avec confiance et clarté.</p><p>L’une des fonctionnalités les plus puissantes de GenAI est sa fonctionnalité d’explication du code. Un simple clic droit permet à Alex d’accéder à des explications détaillées de n’importe quelle ligne de code, révélant son objectif et ses fonctionnalités. Cela change la donne pour Alex, dissipant ses craintes de modifier une base de code monolithique et lui permettant de se mettre au travail immédiatement au lieu de perdre une journée à analyser le code.</p><p>L’impact de GenAI va au-delà de la compréhension, de la révision et des tests du code. Il joue également un rôle crucial dans le respect des normes de codage et des meilleures pratiques. Grâce à des commentaires et des suggestions en temps réel, GenAI aide Alex à maintenir la cohérence et la conformité dans l’ensemble de la base de code, réduisant ainsi le risque d’introduction d’erreurs ou de vulnérabilités.</p><h3>GenAI — Insuffler la confiance aux développeurs et à la direction du mainframe</h3><p>À mesure qu'Alex approfondit la base de code, elle découvre des opportunités d'optimisation et d'amélioration, avec GenAI, un allié précieux, fournissant des informations et des recommandations qui aident à rationaliser le processus de développement et à améliorer les performances des applications commerciales critiques.</p><p>Mais le plus important est peut-être que GenAI permet à Alex de remettre en question la « peur du changement » qui règne au sein de l’organisation. Grâce à sa capacité à fournir des explications claires et concises sur les changements de code, GenAI donne à Alex la confiance dont elle a besoin pour aider l’organisation à évoluer vers une culture d’innovation et de progrès.</p><p>Alors que la journée touche à sa fin, Alex réfléchit à l’impact transformateur de GenAI sur son travail. Ce qui était autrefois une tâche ardue et intimidante est devenu un voyage de découverte et d’autonomisation. Avec GenAI à ses côtés, Alex se sent encouragée à relever même les défis les plus redoutables, sachant qu’elle dispose des outils et du soutien dont elle a besoin pour réussir.</p><h3>Principaux cas d'utilisation de GenAI pour améliorer l'expérience des développeurs mainframe</h3><p>1. Expliquez ce que fait le code : GenAI propose des explications détaillées sur les extraits de code et les programmes. En s'appuyant sur des méthodes NLP sophistiquées, il intègre de manière transparente les commentaires dans le code, améliorant ainsi la lisibilité et favorisant la collaboration entre les développeurs. Ce processus automatisé améliore la compréhension et rationalise le flux de travail de développement, garantissant que les développeurs peuvent saisir les subtilités de la base de code plus rapidement et plus efficacement, ce qui contribue à accélérer le cycle de développement. 2. Recevez des commentaires immédiats sur les normes de code : GenAI joue un rôle essentiel dans les révisions de code, en aidant les développeurs avec des commentaires en temps réel, des conseils et des suggestions de correction qui favorisent la cohérence et la conformité entre les applications. 3. Améliorez la livraison de vos modifications : GenAI peut considérablement rationaliser le processus de livraison du code. En facilitant une isolation plus rapide des causes profondes et en améliorant la résilience et les performances des chaînes d'outils d'intégration continue et de livraison continue (CI/CD), il accélère le temps moyen de résolution (MTTR). 4. Offrez à chaque développeur un assistant personnel : GenAI fonctionne comme un assistant de codage virtuel indispensable, doté d'une connaissance approfondie des meilleures pratiques, des modèles de conception et de la syntaxe. En s'intégrant de manière transparente dans les flux de travail des développeurs, il fournit des recommandations contextuelles et favorise le respect des normes industrielles et organisationnelles, améliorant ainsi la productivité des développeurs et la qualité du code. 5. Tests efficaces avec un minimum de données viables : GenAI révolutionne le paradigme des tests en analysant intelligemment le code source et en concevant des pratiques optimales de test et de données de test.</p><h3>Ouvrir la voie à un avenir d'innovation mainframe</h3><p>En conclusion, l’intégration de GenAI représente un changement de paradigme dans l’amélioration de l’expérience des développeurs mainframe. En fournissant des informations inégalées sur des bases de code monolithiques complexes, GenAI permet aux développeurs de naviguer dans les complexités des systèmes existants avec confiance et clarté. De plus, en remettant en question la culture dominante de la « peur du changement », GenAI ouvre la voie à un avenir d’innovation et de progrès au sein de l’organisation. Alors qu’Alex se tourne vers l’avenir, elle le fait avec optimisme et enthousiasme, sachant que GenAI continuera de révolutionner sa façon de travailler dans les années à venir.</p>"
ContextQA se tourne vers IBM pour l'IA afin d'automatiser les tests,"<p>ContextQA intègre la plateforme IBM watsonx.ai pour la création, l'accès et le déploiement de modèles d'intelligence artificielle (IA) dans sa plateforme d'automatisation low-code/no-code pour tester le front-end des applications.</p><p>Auparavant, ContextQA s'appuyait initialement sur Amazon Web Services (AWS) mais a décidé de passer à IBM pour réduire les coûts.</p><p>Deep Barot, PDG de ContextQA, a déclaré qu'en plus de fournir un meilleur support, IBM travaille plus étroitement avec ContextQA pour élargir le nombre de cas d'utilisation où l'IA peut être appliquée.</p><p>En fin de compte, l’objectif n’est pas tant d’augmenter le nombre de tests exécutés que de permettre aux équipes DevOps d’exécuter plus facilement le bon test au bon moment, a-t-il ajouté. À terme, les modèles d’IA devraient être capables d’exécuter 80 % des tests les plus courants, ce qui laisserait aux équipes DevOps plus de temps pour exécuter des tests de cas d’utilisation supplémentaires qui n’auraient peut-être jamais été exécutés auparavant, a noté Barot.</p><p>En théorie, les modèles d’IA devraient améliorer la qualité globale des applications déployées. Cependant, l’enjeu n’est pas seulement de s’assurer que davantage d’applications sont testées de manière approfondie, mais également de s’assurer que les tests sont effectués dans le bon ordre. En effet, les équipes DevOps doivent être capables d’exploiter différentes classes de modèles d’IA pour orchestrer des processus de test plus intelligents dans le contexte d’un flux de travail DevOps plus large.</p><p>Selon Barot, plus l’application en cours de création et de déploiement est complexe, plus la capacité d’orchestration devient essentielle. Cela est d’autant plus important qu’à mesure que de plus en plus de tests sont effectués à l’aide de modèles d’IA, le coût global des tests aura tendance à augmenter. En outre, les progrès de l’IA devraient simplifier la création et le déploiement d’un nombre d’applications plus important que jamais, qui doivent toutes être minutieusement testées avant d’être déployées dans un environnement de production.</p><p>On ne sait pas exactement pendant combien de temps les équipes DevOps vont s’intéresser aux modèles d’IA spécifiques utilisés pour effectuer une tâche spécifique, mais pour l’instant, la plupart des équipes informatiques sont très intéressées de savoir à quels LLM elles pourraient exposer des données sensibles lorsque des problèmes de sécurité et de conformité surviennent, a noté Barot.</p><h3>Identifier les opportunités d'automatisation rendues possibles par l'IA dès maintenant</h3><p>Il faudra peut-être un certain temps avant que l’IA ne soit appliquée de manière généralisée aux tests d’applications, mais la question est désormais de savoir quand plutôt si. Historiquement, chaque fois qu’une équipe DevOps prenait du retard, elle avait naturellement tendance à réduire le temps alloué aux tests. Le problème est qu’au fil du temps, la réduction des tests finit par entraîner une baisse globale de la qualité des logiciels, à une époque où les utilisateurs finaux sont moins tolérants aux bugs et aux défauts.</p><p>Espérons qu’un jour prochain, le nombre de problèmes que les équipes DevOps doivent résoudre régulièrement diminuera à mesure que la qualité des logiciels déployés s’améliorera. En attendant, les équipes DevOps doivent évaluer les flux de travail DevOps existants pour identifier les opportunités d’automatisation rendues possibles par l’IA. Le problème n’est pas tant que l’IA va remplacer le besoin de professionnels DevOps dans un avenir proche, mais plutôt qu’elle détermine les tâches à déléguer aux machines d’une manière qui permet aux équipes DevOps de créer et de déployer des applications à une échelle sans précédent.</p>"
Pas de pays pour le no-code : allons-nous vers un Far West de la sécurité logicielle ?,"<p>Quasiment tout ce que nous utilisons est basé sur du code, des voitures aux réfrigérateurs intelligents en passant par les sonnettes. Dans les entreprises, d’innombrables applications assurent le fonctionnement des appareils, des flux de travail et des opérations. Ainsi, lorsque les premières plateformes de développement sans code ont été lancées en 2010, promettant un développement d’applications plus accessible aux développeurs citoyens, son succès semblait inévitable.</p><p>Il est difficile de nier le succès du no-code. Ces plateformes aplanissent la courbe d’apprentissage des développeurs en herbe, permettant aux entreprises d’innover et d’automatiser avec des applications utiles malgré une pénurie de compétences en matière de développement. De plus, les applications prêtes à l’emploi proposées par les plateformes no-code accélèrent le processus de développement d’applications dans un monde où la rapidité de mise sur le marché est primordiale. L’année dernière, Forrester a constaté que 87 % des développeurs d’entreprise utilisent des outils ou des plateformes low-code et no-code pour au moins une partie de leur charge de travail.</p><p>Mais la fonctionnalité n’est pas le seul signe de réussite. Sans le vouloir, les mêmes tendances qui ont poussé à la démocratisation du développement d’applications ont conduit à un Far West d’applications non sécurisées et de mauvaises configurations qui exposent toute une série d’organisations aux cybermenaces.</p><h3>L'importance de la sécurité</h3><p>Bien que ces plateformes démocratisent le développement, elles doivent être utilisées avec prudence. Le Top 10 de l'OWASP met en évidence des facteurs tels que la mauvaise configuration et l'utilisation de composants vulnérables comme menaces de sécurité courantes. Pourtant, le recours au développement sans code pourrait introduire des vulnérabilités non détectées directement dans une organisation.</p><p>Forrester met en garde depuis longtemps contre les risques du no-code et du low-code, et met en avant cette vulnérabilité dans ses prévisions pour les années à venir. Le spectre d’un employé non formé créant des applications est particulièrement alarmant : ces plateformes permettent aux employés sans aucune connaissance en matière de sécurité des applications de développer des programmes dont les équipes de sécurité n’ont souvent pas connaissance.</p><p>Les entreprises doivent avoir une réelle idée de qui est responsable du développement des logiciels, qu’il s’agisse de développeurs professionnels utilisant des plateformes no-code comme outils ou de développeurs citoyens créant des applications pour des équipes et des projets plus petits. Ce n’est un secret pour personne que les CVE sont en forte augmentation. Ils ont atteint un record de 28 092 l’année dernière et devraient augmenter de 25 % en 2024. En décembre dernier, Microsoft a révélé un CVE de haute gravité qui touchait les utilisateurs low-code et no-code.</p><p>Lorsque les entreprises sont confrontées chaque jour à une vague de nouveaux exploits, des compétences telles que la détection et la correction des vulnérabilités sont essentielles à tout nouveau projet de développement logiciel.</p><p>Le développement de logiciels doit devenir plus flexible dans ses rôles, mais jamais au détriment de la sécurité. En favorisant une culture de « sécurité dès la conception » dans toute l’organisation, les responsables de la sécurité peuvent s’assurer que tous les rôles du cycle de vie du développement logiciel (SDLC) comprennent leurs responsabilités dans leur posture de sécurité, y compris les développeurs citoyens.</p><h3>Renforcer l'intervention humaine</h3><p>Selon l’étude Security Journey, seule une entreprise sur cinq est sûre de sa capacité à détecter une vulnérabilité avant la publication d’une application. Cela signifie que les connaissances en matière de sécurité dans la plupart des SLDC sont insuffisantes. Les développeurs doivent être formés pour créer des logiciels sécurisés et détecter le code non sécurisé dans le reste de la base de code, en y répondant et en le corrigeant rapidement, avant qu’il ne soit mis en production. Sans cela, les équipes de sécurité et de sécurité des applications se retrouvent avec une charge inutile, qui nécessite en fin de compte plus de temps, de dépenses et un risque commercial potentiel plus élevé. La sécurisation des vulnérabilités après coup, par le biais d’analyses de sécurité et de correctifs réguliers, ne devrait pas être la norme.</p><p>Les entreprises ont plutôt la possibilité de doter leurs développeurs de compétences et de connaissances en matière de sécurité tout au long de leur carrière. Ces compétences leur permettent de fournir des résultats de meilleure qualité et jouent un rôle essentiel dans la sécurisation de l’entreprise elle-même. Et pourtant, seule une entreprise sur trois (36 %) forme les développeurs à l’écriture de code sécurisé, ce qui garantit que la sécurité logicielle commence à la fin du processus de développement dans 64 % des cas. Il en va de même pour les développeurs citoyens, dont le travail témoigne souvent d’une passion pour la résolution de problèmes et l’innovation qui doit être exploitée et soutenue par une formation adaptée.</p><h3>Un problème pour l’avenir</h3><p>Il serait réducteur de prétendre que le risque de sécurité des logiciels augmente uniquement à cause des plateformes no-code et low-code, ou même que les développeurs citoyens sont la majorité des contributeurs aux CVE. La culture même du développement logiciel a poussé l’industrie à emprunter la voie de la rapidité et de la facilité au détriment de la sécurité depuis près de deux décennies. L’essor du codage généré par l’IA le prouve plus que tout.</p><p>Tant que les développeurs et les chefs de projet qui les dirigent seront incités à agir vite, chaque nouvelle solution sera valorisée en fonction de sa capacité à créer rapidement du code fonctionnel. Ce sera le cas jusqu'à ce que la sécurité soit considérée comme une priorité par les régulateurs et, surtout, par les dirigeants et le conseil d'administration.</p><p>La déconnexion culturelle au cœur de la crise de sécurité logicielle est d’origine humaine. Quel que soit l’outil mis en avant, la création de logiciels sécurisés nécessitera des solutions humaines. Si les grands modèles de langage (LLM) ne sont pas encore équipés pour faire face aux considérations complexes auxquelles les développeurs sont confrontés au quotidien, le plus grand risque viendra de la complaisance, de la dépendance excessive et de la confiance aveugle de leurs utilisateurs. Les développeurs humains, équipés pour effectuer des examens de code rigoureux et corriger les vulnérabilités qu’ils trouvent, sont essentiels à la mise en œuvre sûre de toutes ces technologies, qu’elles soient sans code, à faible code ou générées par l’IA. Sans cela, les outils courent le risque d’introduire davantage de vulnérabilités avec une supervision moins critique.</p><p>Quels que soient les outils proposés, les utilisateurs humains avertis devront toujours comprendre ce que l’outil fournit et pourront agir comme une solution provisoire en matière de qualité et de sécurité.</p>"
Spotify va fournir une instance d'opinion de Backstage IDP,"<p>Spotify a annoncé aujourd'hui qu'il mettait à disposition du marché une instance de son portail de développement interne (IDP) basé sur la plateforme open source Backstage que la société avait précédemment contribué à la Cloud Native Computing Foundation (CNCF).</p><p>Pia Nilsson, directrice principale de l'ingénierie chez Spotify, a déclaré que Spotify Portal for Backstage, disponible en version bêta privée aujourd'hui, fournit aux équipes d'ingénierie de la plateforme un cadre low-code/no-code pour la mise en place d'un IDP.</p><p>De plus, Spotify met désormais à disposition des organisations ayant adopté Backstage un support d'entreprise, ainsi que des plug-ins supplémentaires qui simplifient les intégrations avec des outils et des plateformes de fournisseurs tiers tels que New Relic, Atlassian, Snyk et Datadog.</p><p>Enfin, Spotify ajoute des fonctionnalités pour gérer les hackathons et faire remonter les informations sur l'utilisation. Un prochain plug-in promet également de permettre d'ajouter des entités de données à un catalogue de logiciels résidant dans Backstage.</p><p>Backstage a gagné en popularité en tant qu'IDP principalement parce qu'il fournit un cadre extensible pour centraliser la gestion des environnements de développement.</p><h3>Mise en œuvre du portail Spotify</h3><p>Certaines entreprises ont trouvé difficile de créer et de déployer Backstage. Spotify propose donc désormais une implémentation plus réfléchie du portail Spotify, plus simple à déployer, à configurer et à gérer à l'aide de modèles, a noté Nilsson.</p><p>Les applications étant devenues plus difficiles à créer, l'accent est mis sur l'amélioration de la productivité des développeurs. Dans le même temps, les IDP permettent aux équipes d'ingénierie de plateforme de rationaliser le nombre d'outils utilisés de manière à réduire le coût total du développement logiciel.</p><p>De nombreux développeurs souhaitent ajouter des outils selon leurs besoins. Les équipes DevOps doivent donc trouver un moyen de trouver un équilibre entre la réduction de la charge cognitive à laquelle les développeurs sont confrontés et ce qui pourrait devenir une approche trop lourde de la centralisation des flux de travail DevOps. Si les développeurs talentueux commencent à se diriger vers la sortie parce qu’ils n’aiment pas l’expérience proposée, les responsables informatiques auront du mal à les remplacer.</p><h3>Donner plus de temps aux équipes DevOps</h3><p>L’idée est que les IDP, utilisés dans le contexte de l’ingénierie de plateforme, donneront aux développeurs plus de temps pour se concentrer sur l’écriture de la logique métier. Cependant, le développement d’applications est autant un art qu’une science. Ce n’est pas parce que les développeurs ont plus de temps que les idées et l’inspiration nécessaires pour écrire du code s’ensuivent automatiquement. Les IDP et l’ingénierie de plateforme, à tout le moins, créent cependant la possibilité pour les développeurs d’écrire plus de logique métier plus rapidement. Le degré auquel cela se produit varie naturellement d’une organisation à l’autre.</p><p>Chaque organisation devra décider dans quelle mesure elle souhaite adopter l'ingénierie de plateforme, mais quel que soit son niveau d'engagement, les IDP peuvent jouer un rôle essentiel en simplifiant l'intégration des développeurs dans de nouveaux projets, a noté Nillson. En outre, un IDP permet aux équipes DevOps de suivre plus facilement des indicateurs tels que la vitesse à laquelle le code est mis à jour, a-t-elle déclaré.</p><p>Les IDP ne sont bien sûr pas nécessairement idéaux, mais avec l’essor de Backstage, il y a clairement désormais plus de standardisation, car les équipes DevOps continuent de chercher à éliminer autant de frictions que possible.</p>"
"Exploration des plateformes Low/No-Code, GenAI, Copilots et Générateurs de code","<p>L’émergence des plateformes low/no-code remet en question les notions traditionnelles d’expertise en codage. L’époque où le codage était un ensemble de compétences exclusives réservées à quelques personnes averties est révolue. Les plateformes low/no-code ont démocratisé le développement de logiciels. Elles permettent aux personnes issues de milieux non informatiques ou techniques de traduire leurs idées commerciales en applications sans avoir besoin de maîtriser des langages de programmation complexes.</p><p>Ces plateformes low/no-code, avec leurs interfaces glisser-déposer conviviales et leurs composants pré-intégrés, ont simplifié le développement d'applications. Imaginez créer une application pour maison intelligente en quelques clics et glisser-déposer : les plateformes low/no-code rendent cela possible.</p><p>Ajoutez à cela l’intelligence artificielle générative (Gen AI) et les nouvelles pratiques de développement changent considérablement le domaine.</p><h3>L'impact de la génération d'IA sur les plateformes Low-Code</h3><p>Les plateformes low-code devraient continuer à évoluer, devenant plus intelligentes, plus adaptables et plus intégrées au cycle de vie du développement logiciel. On assistera à une évolution vers des plateformes qui utilisent l'IA de génération pour comprendre l'intention des utilisateurs, automatiser les tâches de routine et générer des extraits de code complexes.</p><p>Gartner prédit que, d'ici 2026, plus de 80 % des entreprises utiliseront les API et modèles GenAI ou déploieront des applications compatibles GenAI dans des environnements de production, contre moins de 5 % début 2023.</p><p>La combinaison du low-code et de l’IA générative permettra aux développeurs d’automatiser les tâches de routine et de se concentrer sur la logique et la créativité de haut niveau. L’IA générative agit comme un multiplicateur qui peut accélérer et optimiser les opérations de développement. McKinsey estime que l’IA générative pourrait ajouter entre 2,6 et 4,4 billions de dollars par an à l’économie mondiale d’ici 2040.</p><h3>Un autre outil : les copilotes IA et les générateurs de code</h3><p>Une autre application prometteuse des grands modèles de langage (LLM) de l'IA est celle des assistants basés sur l'IA. C'est là qu'interviennent les copilotes et les générateurs de code, des assistants IA qui simplifient le codage.</p><p>Alors que les plateformes low/no-code ont transformé le développement d’applications, les copilotes et les générateurs de code ajoutent une couche supplémentaire d’efficacité.</p><p>Les copilotes IA utilisent une interface de chat pour simplifier le codage via une interface de chat, où les développeurs articulent leurs exigences de code dans des invites en langage naturel, et le copilote génère le code en conséquence. Ces assistants fournissent une assistance en temps réel, en proposant des suggestions contextuelles et des extraits de code, et ils peuvent anticiper les bugs potentiels. De plus, ils peuvent expliquer les blocs de code, générer des tests unitaires et proposer des correctifs de bugs, ce qui améliore le processus de codage. Les copilotes IA sont comme des assistants de confiance, prêts à vous aider dans des tâches de codage spécifiques ou à générer du code complexe - et ils le font rapidement.</p><h3>La grande question</h3><p>Avec l’essor des plateformes low/no-code, les compétences requises dans le secteur technologique vont évoluer. L’époque où la maîtrise de plusieurs langages de programmation était indispensable est révolue.</p><p>Les outils low/no-code occupant une place centrale, cela signifie-t-il que le codage devient obsolète ?</p><p>Un grand non.</p><p>Si les connaissances de base en programmation restent précieuses, elles ne constituent plus la seule exigence pour créer des applications innovantes. Grâce aux plateformes low/no-code qui démocratisent le développement d’applications, des personnes d’horizons divers peuvent exploiter la technologie pour créer des solutions efficaces.</p><p>GenAI, les copilotes et les générateurs de code rendent-ils les plateformes low/no-code obsolètes ?</p><p>Encore une fois, non.</p><p>Si GenAI, copilots et générateurs de code excellent dans certaines tâches spécifiques, les plateformes low/no code offrent une solution holistique, combinant conception d’interface visuelle, intégration de bases de données et bien plus encore. Ce sont les couteaux suisses du développement, répondant à un large éventail de besoins au-delà de la simple génération de code.</p><p>L’IA de génération, les copilotes et les générateurs de code ne sont pas là pour remplacer les plateformes low/no-code ou les pratiques de codage traditionnelles. Au contraire, ils sont positionnés pour les compléter et les améliorer. La fusion de ces technologies est très prometteuse pour simplifier le développement de logiciels, accroître l’efficacité et ouvrir de nouvelles voies d’innovation.</p><h3>Le dernier mot</h3><p>Grâce à de meilleures suggestions de code et à des capacités de test automatisées, les plateformes low/no-code offrent des solutions de haute qualité qui répondent aux exigences des utilisateurs férus de technologie d’aujourd’hui.</p><p>Grâce à la combinaison passionnante des plateformes low/no-code et de GenAI, l’avenir du développement logiciel est prometteur. Si ces avancées peuvent bouleverser le codage traditionnel, elles offrent également des opportunités d’innovation et de créativité.</p><p>Il est temps pour nous d’accepter ce changement et de construire un avenir meilleur, une ligne de code (ou son absence) à la fois.</p>"
L'essor du low-code/no-code dans DevOps,"<p>L’évolution constante du paysage technologique a entraîné un changement de paradigme dans le développement et le déploiement de logiciels. L’une des principales tendances qui gagne du terrain est l’intégration de plateformes low-code/no-code au sein de l’écosystème DevOps. Cet article explore la manière dont ces plateformes révolutionnent la manière dont les applications sont développées, déployées et gérées, favorisant la collaboration entre les développeurs et les équipes opérationnelles.</p><p>1. Démocratiser le développement :</p><p>Les plateformes low-code/no-code permettent aux personnes ayant une expérience limitée en codage de participer activement au processus de développement d'applications. Cette démocratisation du développement accélère la livraison de logiciels en permettant aux analystes commerciaux, aux concepteurs et à d'autres non-développeurs, parfois appelés développeurs citoyens, de contribuer directement à la création d'applications.</p><p>2. Accélération du délai de mise sur le marché :</p><p>Le cycle de vie traditionnel du développement logiciel implique souvent de longs processus de codage, ce qui entraîne des retards dans la publication des versions. Les plateformes low-code/no-code permettent un prototypage et un développement rapides grâce à des interfaces visuelles, réduisant ainsi considérablement le temps nécessaire pour faire passer les applications du concept à la production. Cette accélération s'aligne sur les principes de DevOps, favorisant une livraison continue et une mise sur le marché plus rapide.</p><p>3. Améliorer la collaboration :</p><p>DevOps vise à éliminer les silos et à favoriser la collaboration entre les équipes de développement et d'exploitation. Les plateformes low-code/no-code comblent le fossé entre ces rôles traditionnellement distincts en fournissant un terrain d'entente où les parties prenantes techniques et non techniques peuvent collaborer de manière transparente. Cet environnement collaboratif favorise une meilleure communication, une meilleure compréhension et un meilleur alignement des objectifs.</p><p>4. Flexibilité dans le déploiement :</p><p>Les solutions low-code/no-code sont conçues pour être indépendantes de la plateforme, ce qui permet le déploiement d'applications dans différents environnements, y compris sur site et dans le cloud. Cette flexibilité s'aligne sur le principe DevOps de l'infrastructure en tant que code (IaC), permettant aux équipes de déployer et de gérer des applications de manière cohérente sur diverses infrastructures.</p><p>5. Réduire la dépendance aux compétences spécialisées :</p><p>Dans un environnement DevOps, il est essentiel de réduire les goulots d'étranglement et les dépendances vis-à-vis d'individus ou de rôles spécifiques. Les plateformes low-code/no-code permettent aux équipes d'être plus autonomes, réduisant ainsi la dépendance à l'égard de compétences de codage spécialisées ou de formations DevOps. Cela contribue à son tour à une culture DevOps plus résiliente et adaptable.</p><p>6. Défis et considérations :</p><p>L’adoption du low-code/no-code dans DevOps apporte de nombreux avantages, mais elle présente également des défis. Cette section aborde des considérations telles que la sécurité, l’évolutivité et le besoin potentiel de personnalisation au-delà des capacités de la plateforme.</p><p>7. Cas d'utilisation réels :</p><p>Découvrez des exemples concrets d'organisations qui ont intégré avec succès le low-code/no-code dans leurs workflows DevOps. Mettez en évidence les résultats positifs, les leçons apprises et l'impact sur leur cycle de vie global de développement logiciel.</p><p>Conclusion:</p><p>L’essor des plateformes low-code/no-code dans DevOps remodèle la manière dont les logiciels sont développés et déployés. En favorisant la collaboration, en accélérant les cycles de développement et en réduisant les dépendances vis-à-vis des compétences spécialisées, ces plateformes s’alignent parfaitement sur les principes de DevOps. Alors que les entreprises continuent d’adopter cette tendance, la synergie entre low-code/no-code et DevOps est sur le point de redéfinir l’avenir de la distribution d’applications.</p>"
Low Code : la clé pour accélérer le développement d'applications personnalisées pour les développeurs modérés,"<p>Le développement d'applications personnalisées est devenu une compétence cruciale dans un monde de plus en plus numérisé. De nombreux développeurs modérés sont confrontés à des défis lors de la création d'applications uniques et fonctionnelles. C'est là qu'entrent en jeu les plateformes low-code, offrant une solution pour accélérer le développement d'applications et compenser ces lacunes.</p><h3>Qui sont les développeurs modérés ?</h3><p>Bien que chaque développeur évolue constamment et acquière de l'expérience, comme tout professionnel, on peut les classer en trois catégories. La première est celle des développeurs débutants qui apprennent sur le tas et qui peuvent aider au débogage, à la documentation essentielle, à la maintenance du référentiel de code et à certaines demandes de fonctionnalités simples. À l'autre extrémité se trouvent les développeurs très expérimentés qui dirigent des projets, conçoivent des solutions, supervisent le développement d'applications et assument l'entière responsabilité de la fourniture de fonctionnalités exceptionnelles dans une nouvelle application.</p><p>Les développeurs modérés sont ceux qui se situent entre les deux, représentant un large éventail de professionnels possédant l'expertise de base pour mettre en œuvre la plupart des conceptions d'applications et des demandes de fonctionnalités. Avec plus d'expérience que les débutants, mais pas encore qualifiés pour servir en tant que seniors dans une équipe, ils ont un ensemble commun de défis à relever.</p><h3>Comprendre les défis des développeurs modérés</h3><p>Les développeurs de niveau intermédiaire ont souvent besoin d'aide pour répondre aux exigences complexes du développement d'applications et aux limites de leurs compétences. Ils doivent créer des applications de haute qualité, fonctionnelles et uniques, ce qui peut être intimidant compte tenu du rythme rapide des changements technologiques et des attentes des utilisateurs.</p><p>Ces développeurs moyennement qualifiés sont souvent confrontés à des défis communs tels que :● Expertise limitée : cultiver une connaissance approfondie des langages de programmation et des environnements de développement est un processus continu.● Contraintes de temps : développer une application à partir de zéro nécessite beaucoup de temps. Consacrer des efforts à un seul projet peut limiter les développeurs et leurs organisations.● Problèmes d'évolutivité : la croissance et l'extension des applications augmentent le besoin d'évolutivité et peuvent créer de la complexité. Apporter des modifications et ajouter de nouvelles fonctionnalités peut réduire la capacité d'une organisation à se concentrer sur de nouveaux projets.● Problèmes de sécurité : les développeurs modérés peuvent ne pas être conscients des risques de sécurité d'une application, ce qui met en péril la protection d'une entreprise.</p><h3>Les plateformes low-code offrent de l'espoir</h3><p>Les plateformes low-code ont été créées pour répondre aux besoins des développeurs moyennement qualifiés et des organisations axées sur la compétitivité. L'utilisation d'éléments glisser-déposer testés offre un moyen sûr et puissant de surmonter ces défis.</p><p>La création d'applications pratiques et puissantes est possible via des plateformes low-code en connectant des modèles prêts à l'emploi. Ce processus crée rapidement des applications pouvant être utilisées comme applications mobiles et Web.</p><p>Les non-professionnels de l'informatique peuvent surmonter leur manque de temps et de connaissances grâce à des plateformes low-code. Les organisations qui manquent de personnel dans leur service informatique peuvent néanmoins fournir une connexion puissante pour leurs services. L'équipe peut rapidement se mettre au travail pour remplir sa mission principale.</p><h3>La modélisation visuelle est le pouvoir secret des plateformes low-code</h3><p>Le développement d'applications traditionnelles implique l'écriture de lignes de code, les tests et la gestion par une équipe informatique expérimentée. Les plateformes low-code utilisent des composants visuels pré-testés et connectés pour créer et mettre en œuvre rapidement des applications performantes et sécurisées.</p><p>Les développeurs low-code peuvent visualiser l’application qu’ils construisent depuis le début du processus jusqu’à son lancement. L’aspect glisser-déposer de ces plateformes est plus intuitif et convivial. L’utilisation de modèles éprouvés proposés par ces plateformes peut également contribuer à réduire les erreurs.</p><h3>Dupliquer le succès</h3><p>L’assemblage de composants testés et prêts à l’emploi augmente les chances de réussite d’une application. Les applications préconfigurées sont un moyen de lancer rapidement des applications avec la confiance d’un historique éprouvé.</p><p>Les plateformes low-code offrent aux utilisateurs la confiance nécessaire pour faire confiance aux composants tout en observant directement leurs résultats en cours depuis une perspective visuelle claire. Il est ainsi possible d'accorder plus de temps et d'attention aux fonctionnalités uniques d'une application plutôt qu'à la complexité et à la pénibilité du codage.</p><h3>Opportunités de team building et de collaboration</h3><p>La nature visuelle des plateformes low-code permet à toute l’équipe de jouer un rôle actif dans le développement d’une application et permet à chacun de parler le même langage de développement.</p><p>Les outils de collaboration intégrés facilitent les boucles de rétroaction, le suivi des révisions, les récits d'utilisateurs et la messagerie, ce qui permet aux équipes de travailler plus facilement ensemble dans le même bureau ou dans le monde entier. Chacun peut s'approprier la solution tout en ayant un impact positif sur sa sortie.</p><h3>Assurer l'évolutivité</h3><p>Les plateformes low-code offrent bien plus qu’une opportunité unique de croissance et de réussite. Les utilisateurs de plateformes low-code qui exploitent leur puissance peuvent bénéficier de connexions client robustes et conviviales. Ils peuvent continuer à générer de nouvelles opportunités de services et de ventes après le lancement initial.</p><p>Les réseaux de traitement internes éprouvés peuvent être étendus avec les mêmes plateformes low-code qui ont permis ce développement robuste. Les connexions low-code peuvent être efficacement étendues à l'aide de travaux low-code antérieurs.</p><p>Les plateformes low-code existantes permettent de répondre facilement aux besoins en constante évolution des entreprises. Elles peuvent continuer à proposer des modèles prêts à l’emploi pour des réussites internes et externes adaptées aux besoins d’une entreprise.</p><p>La nature basée sur le cloud des plateformes low-code garantit un service flexible et continu des applications. Cela permet de garantir la fiabilité et la réactivité aux besoins continus du client.</p><h3>Choisir la bonne plateforme Low-Code</h3><p>L'identification de la meilleure plateforme de développement de logiciels low-code repose sur plusieurs facteurs clés que les développeurs doivent prendre en compte :● Facilité d'utilisation● Évolutivité● Capacités d'intégration● Possibilité de personnaliser les applications</p><p>Les décideurs doivent également tenir compte de l’expertise de leur équipe lors du choix d’une plateforme low-code. Les versions d’essai ou les niveaux gratuits peuvent être utiles pour comprendre l’expertise de l’équipe et les capacités d’une plateforme à répondre aux besoins d’une organisation.</p><h3>L'avenir des plateformes low-code</h3><p>Alors que les entreprises continuent de s’adapter aux complexités de la transformation numérique, les analystes prédisent un avenir prometteur pour les plateformes low-code. La tendance sera à une adoption continue par les entreprises pour garantir un développement plus rapide et répondre aux besoins spécifiques des entreprises. Il est également clair que les plateformes low-code ne remplaceront que partiellement le développement logiciel traditionnel. Mais en démocratisant le développement d’applications et en favorisant une culture d’innovation plus solide, les plateformes low-code sont bien placées pour façonner de manière significative l’avenir des entreprises à l’ère numérique.</p>"
Pourquoi les startups misent gros sur le low-code/no-code,"<p>Il est exhaustif — de l’infrastructure à la livraison des applications, des données aux applications — de moderniser vos pratiques, vos processus et vos fournisseurs pour vous assurer de disposer des bases sous-jacentes pour tirer parti de ce qui vient ensuite.</p><p>Il y a deux ou trois ans, les applications créées via des plateformes low-code/no-code n'étaient généralement pas aussi détaillées que les logiciels développés à partir de zéro, mais elles suffisaient à certaines fins. Il existait même une distinction claire entre les développeurs de logiciels et tous les autres, par nécessité, car le développement de logiciels était incroyablement difficile à maîtriser.</p><p>Mais maintenant, alors que nous nous dirigeons vers une IA plus avancée, les plateformes low-code/no-code (LCNC) basées sur SaaS permettent aux entreprises de créer des logiciels de manière exponentiellement plus rapide et moins chère qu'une approche basée sur le code.</p><p>L’avenir des startups dans ce paysage commercial en pleine mutation devient donc encore plus compétitif, compte tenu de l’importance croissante de la modélisation de l’interface utilisateur centrée sur le client, du développement de produits de données et des technologies de pointe comme l’apprentissage automatique et l’apprentissage profond.</p><h3>Accélération à forte valeur ajoutée</h3><p>Les applications créées via le développement logiciel traditionnel peuvent prendre des mois, voire des années, à être lancées. Si vous créez une solution basée sur du code, il est également facile de rejeter la faute sur les autres et il y a un manque de compréhension si la solution n’est pas bien documentée. « Les fonctionnalités low-code no-code peuvent changer cette dynamique », explique le Dr Ingo Mierswa, informaticien chevronné du secteur et fondateur d’Altair RapidMiner. « Le flux de travail visuel décrit ce qu’il fait, afin que les gens puissent le comprendre, l’adopter et s’approprier les résultats. »</p><p>Les workflows visuels peuvent être compris et créés par davantage de personnes. « Ils facilitent la maintenance et l’explication des causes d’un événement, comme une décision d’un modèle ou un bug, car les workflows se documentent eux-mêmes », explique Mierswa. « Il serait difficile de créer une telle explication si vous deviez parcourir 100 000 lignes de code, surtout si le code avait été modifié 17 fois au cours des deux dernières semaines. »</p><p>Vous devez itérer, vous ferez des erreurs et vous ne voulez pas perdre de temps à coder des choses non critiques. « Mon principal conseil pour tous les débutants est de toujours penser à ce qui est essentiel pour votre produit. Quelle est votre propriété intellectuelle ? Que devez-vous posséder et personnaliser ? Et si le codage n’est pas si important pour votre produit, je pense que le low-code ou le no-code est toujours la meilleure solution », explique Mierswa. « C’est plus important pour les startups car vous avez moins de ressources, moins de temps, une plus grande pression concurrentielle et les marchés évoluent très rapidement. »</p><h3>Tout le monde est un développeur citoyen</h3><p>Au début des années 1960 et 1970, il existait une distinction claire entre les développeurs de logiciels et le reste de la population, par nécessité. Le développement de logiciels était incroyablement difficile et prenait beaucoup de temps à apprendre et à maîtriser. Mais aujourd'hui, avec l'avènement des solutions low-code/no-code, tout le monde, des équipes de gardiennage aux cadres dirigeants, peut créer et personnaliser des applications qui rendent leur travail plus efficace.</p><p>Parce que les plateformes no-code/low-code sont construites sur le principe fondamental. « Les personnes les plus proches du problème sont mieux équipées pour trouver des solutions plus simples et plus efficaces », explique Suresh Sambandam, PDG de Kissflow. « C’est un sport d’équipe, et la responsabilisation, l’avantage le plus important des solutions LCNC, accélère le développement et permet à encore plus de personnes de collaborer de la bonne manière. » Un grand avantage », déclare Sambandam, « est que les DSI des grandes entreprises peuvent résoudre la pénurie de talents informatiques qui sévit aujourd’hui dans le secteur en s’appuyant sur des utilisateurs professionnels experts qui sont des « développeurs citoyens ». De nombreuses entreprises ne peuvent éviter de lutter pour recruter et retenir des talents technologiques sur un marché hautement concurrentiel, mais les solutions low-code/no-code aident énormément à combler ce manque de talents en libérant la bande passante des ressources existantes. »</p><p>Au plus haut niveau, vous avez toujours besoin de personnes qui comprennent les problèmes commerciaux à résoudre. Les fonctionnalités LCNC permettent également aux membres de l'équipe adjacente (concepteurs, chefs de produit, data scientists et autres) de participer aux différentes étapes de développement à mesure que le produit prend forme.</p><h3>Réduire la dette technique pour surmonter les frictions</h3><p>Dans un scénario d’entreprise, la plupart des systèmes de base comme l’ERP, le CRM, le SCM en amont et en aval sont achetés auprès de fournisseurs standard. Il n’y a AUCUNE différenciation, car toutes les grandes entreprises achètent auprès du même fournisseur. En revanche, l’essentiel de la différenciation provient des processus de middle-office qui sont propres à une entreprise. Sambandam souligne : « Il s’agit souvent de processus métier qui nécessitent de solides connaissances du domaine, qui changent fréquemment pour s’adapter à l’évolution des conditions commerciales. Les utilisateurs professionnels sont donc mieux équipés pour créer ces automatisations de flux de travail. » Il souligne que les modèles de développement de logiciels conventionnels ne rendent pas justice à l’agilité requise par les utilisateurs professionnels et sont trop complexes à utiliser. Bien que les utilisateurs professionnels disposent des connaissances du domaine, le système nécessiterait également des points de contact d’intégration avec d’autres systèmes d’entreprise. Ces intégrations nécessitent souvent une expertise technique plus approfondie.</p><p>Il est essentiel de créer un changement culturel au sein de votre organisation, où il ne s’agit pas seulement de disposer des bons outils, mais aussi d’investir dans vos employés et de les former, a commenté Ahmed Bashir, responsable de l’ingénierie chez DevRev. Cela reste un travail difficile et il y aura des frictions. « Pour surmonter les frictions, il faut créer une boucle plus étroite entre les services et les responsables, en comblant l’écart entre les développeurs et les clients », souligne-t-il. « Et les plateformes LCNC sont conçues pour agir comme un système d’action, en faisant apparaître des informations en temps réel qui relient le travail aux développeurs, aux clients et au produit. »</p><p>C’est précisément là qu’interviennent des plateformes comme Kissflow, Blaze et Bubble, qui prennent en charge à la fois les cas d’utilisation sans code et à faible code, et permettent aux utilisateurs professionnels de gérer la partie domaine de l’application (90 %) et aux équipes informatiques de configurer les points d’intégration (10 %). Cela réduit considérablement les frictions entre les équipes informatiques et les utilisateurs professionnels, en particulier lorsqu’il s’agit de solutions pour les flux de travail internes à longue traîne.</p><p>Les applications à longue traîne incluent des éléments tels que la gestion des approbations, les demandes créatives, la gestion des incidents, l'intégration des clients et le service d'assistance informatique. « Nous avons étudié l'espace et avons décidé de nous attaquer à ce problème », explique Sambandam.</p><p>Les applications et processus de longue traîne sont souvent perçus par le service informatique comme une perte de temps et de ressources dont il ne dispose pas. Pourtant, c’est le manque d’automatisation des processus de workflow internes qui freine la transformation numérique. « Au fur et à mesure de l’évolution de l’entreprise, nous avons constaté que lorsque vous permettez aux utilisateurs professionnels de créer et d’améliorer rapidement des workflows qui ont un impact direct sur leur quotidien en leur fournissant les outils pour le faire sans connaissances techniques avancées, ils sont motivés à le faire », a-t-il affirmé.</p><h3>La sécurité est un facteur clé pour les entreprises</h3><p>L'objectif principal de la sécurité est de protéger les organisations et les personnes. Les organisations se préparent aux menaces potentielles en matière de sécurité en mettant en œuvre des politiques et en s'assurant qu'elles disposent des outils nécessaires pour atténuer et réagir rapidement aux menaces extérieures.</p><p>Cependant, de nombreux adoptants du low-code/no-code ne disposent pas d’expertise en sécurité au sein de leur équipe et s’appuient donc sur la plateforme LCNC pour proposer des fonctionnalités de sécurité facilement disponibles pour les applications qu’ils créent. En effet, la création d’applications avec du code personnalisé peut entraîner divers problèmes de sécurité. De plus, ces applications sont difficiles à sécuriser, la majorité des applications testées contenant une ou plusieurs vulnérabilités de gestion de session, et d’autres avec des erreurs de validation des entrées.</p><p>Pour maîtriser parfaitement la sécurité, il faut réfléchir à ce qu’il faut faire. Cela semble simple, mais il est surprenant de constater combien de startups commettent des erreurs en raison d’une mauvaise planification et de stratégies bâclées. « Nous avons observé une tendance. Les entreprises veulent une sécurité de niveau entreprise comme les journaux d’audit, l’authentification unique et d’autres exigences de sécurité des données pour leurs applications », a commenté Nanxi Liu, co-PDG de Blaze. « Constatant cette forte tendance, nous avons travaillé à la conception de notre plateforme en gardant à l’esprit la sécurité et l’évolutivité de l’entreprise, car la plupart des entreprises en phase de démarrage n’ont pas d’expertise en sécurité dans leur équipe et comptent sur des plateformes pour offrir des fonctionnalités de sécurité avancées pour les applications qu’elles créent. »</p><p>Mais ne vous y trompez pas : il n’existe pas de meilleure sécurité que celle qui repose sur les meilleures pratiques. « C’est en partie pour cette raison que les entreprises soucieuses de la conformité, comme les sociétés de services financiers et de santé, qui ont besoin du plus haut niveau de sécurité pour créer leurs portails clients, envisagent des plateformes low-code et no-code de qualité professionnelle qui offrent le niveau de sécurité requis », explique Liu.</p><p>Avec des plateformes low-code/no-code, vos applications sont sécurisées grâce à des protocoles standard du secteur, des pratiques de protection des données et des fonctionnalités permettant de bloquer les accès non autorisés.</p><p>Pour souligner cela : LCNC permet aux personnes non techniques de créer des applications complexes sans avoir besoin de se familiariser avec la logique logicielle traditionnelle. Vous n’avez pas besoin de réflexion informatique, car les composants visuels des plateformes low-code/no-code intègrent automatiquement la logique. « Et maintenant, grâce aux avancées révolutionnaires de l’IA », remarque Liu, « les utilisateurs peuvent indiquer à l’IA en langage naturel le flux de travail ou la fonctionnalité dont ils ont besoin et le voir créé instantanément. »</p>"
Utilisation des LLM pour automatiser les conversions de pipelines de Legacy à Tekton,"<p>Le marché a connu de nombreuses avancées technologiques, mais le principal obstacle est le processus fastidieux de transition entre la technologie/le cadre existant et le nouveau. C'est là que les équipes et les organisations sont laissées pour compte dans la courbe technologique. Dans le paysage DevOps, les pipelines CI/CD sont l'épine dorsale de DevOps, et la façon dont vous travaillez avec eux dicte en grande partie votre efficacité DevOps.</p><p>Les pipelines CI/CD, comme d'autres technologies et frameworks majeurs dans le passé, ont également connu diverses évolutions ; la dernière en date est de devenir réutilisables dans le but de standardiser le CI/CD. Cependant, ici aussi, il existe plusieurs inconvénients :</p><p>1. Les pipelines ne sont pas la propriété des entreprises utilisatrices finales et appartiennent aux plateformes DevOps qui ne sont pas open source2. La migration vers ces plateformes et pipelines est une tâche énorme3. Ils peuvent ne pas être aussi efficaces que décrit</p><p>En parlant de nouvelles avancées technologiques, la plupart des gens connaissent probablement Tekton pour les pipelines CI/CD : il s’agit du framework open source de Google qui est désormais un projet CDF gradué. Il redéfinit la manière dont les pipelines sont construits (par le biais de tâches réutilisables) et ces tâches sont open source et approuvées par la communauté. Elles permettent la création de pipelines et les entreprises peuvent les réutiliser sur des plateformes compatibles avec Tekton, évitant ainsi la dépendance vis-à-vis d’un fournisseur.</p><p>Bien que cela atténue le premier défi lié à la propriété du pipeline et aux migrations, le même problème afflige les équipes DevOps : la transition des technologies/frameworks existants vers des frameworks plus récents et beaucoup plus performants comme Tekton.</p><p>Mais que se passerait-il s’il existait un moyen d’automatiser de manière transparente votre transition des pipelines existants vers des pipelines Tekton réutilisables de pointe, sans effort ? C’est précisément ce que l’article vise à explorer : automatiser la conversion des scripts Yaml des pipelines existants en scripts Tekton Yaml.</p><p>Considérons les trois plateformes CI/CD les plus populaires pour ce cas d’utilisation : Jenkins, GitLab et Azure DevOps. Avant de passer à l’approche proposée pour y parvenir (qui est détaillée dans la deuxième moitié de cet article), examinons d’abord les limites de Jenkins, GitLab et Azure Pipelines et pourquoi il faut procéder à une conversion.</p><h3>Limitations courantes des pipelines Jenkins, Azure et GitLab</h3><p>Besoin intensif en ressources : les pipelines hérités peuvent être gourmands en ressources, en particulier pour les organisations ou les projets de plus grande taille. La gestion des ressources du serveur, l'optimisation des configurations et la garantie d'un matériel suffisant peuvent constituer un défi. Configuration complexe : l'installation et la configuration de Jenkins, GitLab et Azure DevOps peuvent être complexes, en particulier pour les instances auto-hébergées. Cette complexité peut nécessiter des administrateurs expérimentés et un investissement en temps considérable. Compatibilité des plug-ins et des intégrations : les trois plates-formes peuvent être confrontées à des problèmes de compatibilité avec certains plug-ins ou intégrations. Défis de mise à l'échelle : la mise à l'échelle dans les organisations, en particulier lorsqu'il s'agit de plusieurs microservices, nécessite de passer d'une mise à l'échelle individualisée à une approche basée sur des modèles. Le non-respect de cette obligation entraîne une augmentation chaotique des pipelines, ce qui compromet les normes et les processus organisationnels. Coûts : bien que Jenkins et GitLab proposent des versions gratuites et open source, certaines fonctionnalités ou capacités avancées peuvent n'être disponibles que dans les plans payants de niveau supérieur. Cela peut conduire à des considérations de coût à grande échelle. Complexité de la personnalisation : ces plateformes peuvent être complexes pour personnaliser les flux de travail et intégrer des scripts personnalisés car elles nécessitent des connaissances avancées en matière de scripts. Complexité de l'interface utilisateur : bien qu'elles disposent d'interfaces riches en fonctionnalités, il peut parfois être difficile pour les nouveaux utilisateurs de naviguer sur les plateformes et de trouver des paramètres ou des options spécifiques. Intégration native et plugins limités : les intégrations natives de Jenkins, GitLab et Azure peuvent ne pas couvrir l'ensemble des outils et services dont une équipe peut avoir besoin. Des efforts d'intégration supplémentaires ou des outils tiers peuvent être nécessaires pour combler les lacunes du flux de travail de développement.</p><p>Comme le montrent les limitations ci-dessus, bon nombre d’entre elles sont communes, notamment les problèmes d’évolutivité, l’utilisation intensive de ressources, les intégrations limitées, etc. Tous les défis se résument à un dénominateur commun : la gestion complexe des pipelines à grande échelle.</p><p>C'est là qu'un framework comme Tekton peut aider à relever tous les défis à la fois, simplement en simplifiant la gestion des pipelines : avec ses pipelines natifs K8s qui sont réutilisables, open source et des tâches approuvées par la communauté.</p><h3>Tekton Pipelines : faire progresser le CI/CD avec l'automatisation native de Kubernetes</h3><p>Tekton, un projet open source, gagne rapidement du terrain en tant que pionnier dans le monde des pipelines CI/CD. Sa conception native Kubernetes est une fonctionnalité remarquable, s'intégrant parfaitement aux clusters Kubernetes pour exploiter son évolutivité et son efficacité en termes de ressources.</p><p>De plus, les racines cloud natives de Tekton garantissent la possibilité d’exécuter des tâches dans des conteneurs légers et éphémères, optimisant ainsi l’utilisation des ressources. La possibilité de déclarer des pipelines CI/CD sous forme de code, associée aux pratiques GitOps, améliore l’automatisation et la reproductibilité.</p><h3>En quoi les pipelines Tekton sont-ils différents ?</h3><p>Automatisation native de Kubernetes : les pipelines Tekton sont profondément intégrés à Kubernetes, utilisant des ressources et des opérateurs personnalisés pour définir et exécuter des flux de travail CI/CD.</p><p>Déclaratif et modulaire : ces pipelines sont définis de manière déclarative à l'aide de manifestes YAML, favorisant le contrôle des versions, la collaboration et les révisions de code. La conception modulaire des tâches et des pipelines permet aux équipes de créer des composants réutilisables pour la création, le test et le déploiement d'applications.</p><p>Conteneurisation et isolement : chaque tâche d'un pipeline Tekton s'exécute dans un conteneur dédié, garantissant l'isolement et la reproductibilité de l'environnement de création et de déploiement.</p><p>Architecture pilotée par événements : les pipelines Tekton peuvent être déclenchés par divers événements, tels que des validations de code, des demandes d'extraction ou des événements externes, offrant un processus CI/CD réactif et piloté par événements.</p><p>Évolutivité et efficacité : les pipelines Tekton exploitent l’évolutivité inhérente à Kubernetes, permettant une exécution efficace des tâches sur un pool dynamique de nœuds de travail.</p><p>Visibilité et observabilité : ils offrent une surveillance et une journalisation intégrées, permettant aux équipes d'obtenir des informations sur l'exécution du pipeline, de suivre les progrès et de diagnostiquer les problèmes.</p><p>Intégration et extensibilité : les pipelines Tekton peuvent être facilement étendus avec des tâches et des intégrations personnalisées, permettant aux équipes de se connecter à divers outils, services et plateformes cloud.</p><p>Bonnes pratiques cloud natives : en adoptant les pipelines Tekton, les organisations s'alignent sur les bonnes pratiques cloud natives, en promouvant l'utilisation de Kubernetes et de la conteneurisation pour une distribution d'applications rationalisée.</p><h3>Pourquoi passer de Jenkins, GitLab et Azure Pipelines à Tekton Pipelines ?</h3><p>La migration des pipelines Jenkins, GitLab ou Azure vers les pipelines Tekton peut être un choix stratégique, en particulier pour les organisations profondément ancrées dans Kubernetes et les méthodologies cloud natives.</p><p>Optimisez les flux de travail centrés sur Kubernetes : les projets étroitement intégrés à Kubernetes peuvent trouver les pipelines Tekton plus alignés avec leur écosystème.</p><p>Accélérez le DevOps cloud natif : les organisations souhaitant adopter une approche cloud native et exploiter l'infrastructure Kubernetes.</p><p>Performances et évolutivité : les pipelines Tekton fonctionnent sur des clusters qui peuvent être créés et détruits de manière dynamique en fonction de la demande, portant ainsi les optimisations des ressources à un niveau supérieur.</p><p>Bonnes pratiques cloud natives : les bonnes pratiques, telles que la conteneurisation, la configuration déclarative et l'infrastructure en tant que code, s'adaptent naturellement en raison de leur conception native Kubernetes.</p><h3>Flux de travail proposé pour automatiser les conversions de pipelines à grande échelle</h3><p>L'objectif principal de ce flux de travail est de faciliter un processus de conversion transparent à l'aide de grands modèles de langage (LLM) sans se plonger dans les subtilités du réglage fin, mais plutôt en utilisant les avantages de l'ingénierie rapide. Au cœur de cette approche se trouve l'utilisation du contexte de chat et l'application stratégique des rôles pour les modèles LLM afin d'établir le contexte. Parallèlement à cela, des exemples de pipelines sont exploités pour former et affiner le modèle afin de définir à quoi ressemblent les YAML correspondants de toutes ces plateformes pour un pipeline donné.</p><p>L'utilisation d'invites et d'instructions adaptées au cas d'utilisation de la génération de pipelines contextuels YAML et de la conversion de pipelines Jenkins/Gitlab en pipelines Tekton rend ce flux de travail possible. Nous maintenons un contexte et une cartographie contextuelle d'exemples réels et des conceptions d'invites les plus appropriées pour produire les réponses les plus précises. Le rôle des utilisateurs dans ce contexte ajoute du poids et affine davantage la réponse reçue.</p><p>Cependant, avant d’entrer dans les détails et les exemples, posons les bases de ce que signifie exactement l’IA générative et son contexte dans notre cas d’utilisation :</p><h3>IA générative et LLM pour automatiser les conversions de scripts YAML</h3><p>L'IA générative, comme les LLM, crée du contenu semblable à du texte, en tirant parti des modèles présents dans de grands ensembles de données. Les grands modèles linguistiques (LLM), dotés de milliards de paramètres, excellent dans la génération de textes de type humain en comprenant les structures linguistiques. Ils ont de nombreuses applications, notamment la compréhension du langage naturel, la synthèse, la traduction et la génération de contenu, promettant une automatisation et des interactions de type humain avec l'IA.</p><h3>Adaptation du modèle pour résoudre des cas d'utilisation réels</h3><p>Le réglage fin et l'ingénierie rapide sont deux méthodes courantes utilisées pour former des modèles de langage volumineux (LLM) tels que GPT-3, BERT et autres. Ces méthodes permettent d'adapter des modèles pré-entraînés à des tâches spécifiques ou de générer des réponses contextuellement pertinentes. Le réglage fin et l'ingénierie rapide jouent tous deux un rôle crucial. Le réglage fin aide le modèle à comprendre des cas d'utilisation complexes, tandis que l'ingénierie rapide fournit des exigences détaillées, extrayant les meilleurs résultats du modèle.</p><h3>Pourquoi Prompt Engineering?</h3><p>L'ingénierie des invites se distingue comme une approche très avantageuse dans des cas d'utilisation spécifiques où la précision, le contrôle et la personnalisation du comportement du modèle d'IA sont primordiaux. Cette méthode permet aux développeurs et aux utilisateurs de concevoir méticuleusement des invites de saisie, guidant efficacement les modèles d'IA pour produire des réponses contextuellement pertinentes et souhaitées.</p><p>L'ingénierie rapide est à la fois une technique d'ingénierie de l'IA permettant d'affiner de grands modèles linguistiques (LLM) avec des invites spécifiques et des résultats recommandés et le terme désignant le processus d'affinage des entrées dans divers services d'IA génératifs pour générer du texte ou des images.</p><p>Le processus d’ingénierie rapide adapté à notre cas d’utilisation comprend :</p><p>Définition de l’objectif : La première étape du processus d’ingénierie des invites d’IA consiste à définir un objectif clair.</p><p>Élaboration de l’invite initiale : avec l’objectif en tête, il est temps de rédiger une invite initiale. Cela peut prendre la forme d’une question, d’une commande ou même d’un scénario, selon l’objectif.</p><p>Test de l'invite : l'invite initiale est ensuite entrée dans le modèle de langage et la réponse est analysée.</p><p>Analyse de la réponse.</p><p>Affiner l’invite : avec les informations recueillies lors des tests et des analyses, il est temps de réviser l’invite. Cela peut impliquer de la rendre plus spécifique, d’ajouter plus de contexte ou de modifier la formulation.</p><p>Itération du processus : les étapes de test, d'analyse et d'affinage sont répétées jusqu'à ce que nous soyons convaincus que l'invite guide systématiquement le modèle vers la génération de la réponse souhaitée</p><p>Pour conclure, voici un exemple de YAML typique de Jenkins, GitLab et Azure DevOps, et à quoi ressemble le même YAML une fois converti en YAML Tekton. Cela permet aux équipes de passer enfin de leurs pipelines existants à des frameworks de pipeline réutilisables de pointe :</p><p>Jenkins YAML</p><p>GitLab YAML</p><p>Azure YAML</p><p>Tekton YAML converti</p>"
De la réaction aux robots : surfer sur la vague de l'IA en 2024,"<p>Alors que nous traversons une nouvelle année de violations zero-day constantes, de pivots législatifs, d’explosion des outils d’IA et d’acteurs malveillants de plus en plus audacieux et désespérés, on peut dire sans se tromper que se sentir à l’aise avec le changement est une condition nécessaire pour prospérer dans le secteur technologique.</p><p>Nous occupons un espace notoirement imprévisible, mais c’est là que réside toute l’importance du secteur. Comparée à de nombreux autres secteurs, la technologie, et notamment la cybersécurité, est relativement jeune, et l’avenir devrait nous permettre de nous réjouir de voir s’épanouir la sophistication de la technologie que nous nous engageons à protéger.</p><p>Alors, à quoi pouvons-nous nous attendre dans le secteur en 2024 ? Nous avons réfléchi ensemble, regardé dans notre boule de cristal, et voici les résultats :</p><h3>Les réglementations gouvernementales autour de l’IA vont bouleverser le secteur</h3><p>L’IA a été au cœur des discussions lors des conférences de 2023, avec plusieurs présentations de haut niveau à Black Hat, DEF CON, Infosecurity Europe et bien d’autres, annonçant les changements explosifs que nous pouvons attendre de la mise en œuvre de l’IA dans tous les secteurs, en particulier la cybersécurité. Comme cela a tendance à se produire lorsque les barrières à l’entrée pour une technologie aussi transformatrice sont faibles, l’adoption a dépassé toute réglementation officielle ou mandat au niveau gouvernemental.</p><p>Avec des changements importants dans les directives et les critères généraux de cybersécurité à travers le monde, y compris les principes Secure-by-Design et Secure-Default de la CISA aux États-Unis et des initiatives similaires des gouvernements britannique et australien, il est essentiellement acquis que les réglementations autour de l'utilisation de l'IA seront annoncées tôt ou tard.</p><p>Si une grande partie du débat autour de l’utilisation généralisée des outils d’IA et des LLM s’est concentrée sur les questions de droits d’auteur concernant les données de formation, une autre perspective s’intéresse à la meilleure façon d’utiliser l’IA dans les pratiques de cybersécurité. En matière de codage, sa qualité la plus humaine est peut-être la difficulté similaire à afficher une conscience contextuelle de la sécurité, et ce facteur est profondément préoccupant à l’heure où de plus en plus de développeurs adoptent des assistants de codage IA dans la construction de logiciels. Cela n’est pas passé inaperçu, et à une époque où les éditeurs de logiciels sont de plus en plus surveillés pour adopter les meilleures pratiques en matière de sécurité, une intervention au niveau gouvernemental ne surprendrait certainement pas.</p><h3>… Et la demande d’outils de codage IA/ML créera un besoin de plus de développeurs, et non moins !</h3><p>On a beaucoup écrit sur la prise de contrôle de l’IA, et pendant la majeure partie de l’année, nous avons été soumis à une pléthore de gros titres à appâts à clics qui annoncent la fin et la destruction de presque toutes les professions de cols blancs, et les développeurs n’ont pas été épargnés.</p><p>Après des mois de spéculation et d’expérimentation avec des LLM dans un contexte de codage, nous ne sommes toujours pas convaincus que les emplois de développement soient collectivement menacés. Il ne fait aucun doute que les outils de codage IA/ML représentent une nouvelle ère de technologies d’assistance puissantes pour les développeurs, mais ils sont formés à partir d’entrées et de données créées par des humains, ce qui rend les résultats loin d’être parfaits. Peut-être que si chaque développeur de la planète était un ingénieur de haut niveau, soucieux de la sécurité, nous aurions de réelles raisons de nous inquiéter.</p><p>Cependant, tout comme le conducteur adulte moyen dépasse largement ses capacités (remarquez que tout le monde dit qu’il est un excellent conducteur, alors que ce sont toujours les autres qui manquent de compétences ? C’est un exemple classique de l’effet Dunning-Kruger !), il en va de même pour la communauté des développeurs, en particulier en ce qui concerne les meilleures pratiques de sécurité. Selon une étude de Stanford sur l’utilisation des outils d’IA par les développeurs, il est probable que les développeurs non qualifiés utilisant cette technologie deviendront dangereux. L’étude affirme que les participants qui ont accès à des assistants d’IA sont plus susceptibles d’introduire des vulnérabilités de sécurité pour la majorité des tâches de programmation, mais également plus susceptibles de considérer leurs réponses non sécurisées comme sécurisées. Cela pose un problème important : les développeurs peu qualifiés seront en mesure d’introduire des problèmes de sécurité plus rapidement, et au contraire, cela ne fera qu’accroître le besoin de développeurs qualifiés en sécurité, dotés des connaissances et de l’expertise nécessaires pour coder en toute sécurité et utiliser la technologie de l’IA en toute sécurité.</p><h3>Nous verrons les conséquences pour les éditeurs de logiciels qui ne livrent pas de code sécurisé</h3><p>La directrice de la CISA, Jen Easterly, a clairement indiqué que les fournisseurs de logiciels ne devraient pas être autorisés à « rejeter la responsabilité » sur les autres en matière de sécurité de leurs produits, soulignant que la responsabilité actuelle de la sécurité des logiciels incombe en grande partie au consommateur.</p><p>Nous sommes d’accord avec ce point de vue et nous pensons qu’il faudra un bouleversement de cette ampleur pour que la sécurité au niveau du code – sans parler de la formation appropriée des développeurs – soit prise au sérieux.</p><p>Même si les pouvoirs de la CISA sont limités (elle ne peut en principe imposer des pratiques de sécurité dès la conception qu’aux fournisseurs qui vendent leurs produits aux agences fédérales), cela représente néanmoins une nouvelle référence en matière de sécurité à atteindre pour de nombreux grands fournisseurs de logiciels. Colonial Pipeline, SUNBURST et, plus récemment, la violation de données MOVEit sont toutes des cyberattaques de grande envergure qui ont affecté des systèmes gouvernementaux à un moment donné, et avec ces nouvelles directives en vigueur, il est fort possible que de futures violations très visibles fassent l’objet d’un examen plus approfondi et d’une réprimande plus sévère.</p><h3>La sécurité réactive va commencer à être considérée comme obsolète</h3><p>Alors que l’objectif d’une cyber-résilience accrue continue de dominer les stratégies cybernétiques dans de nombreux secteurs verticaux, ceux qui comptent sur la réaction et la réponse aux incidents comme seuls principes fondamentaux de leur plan se retrouveront dans une situation d’exposition et de risque inacceptables.</p><p>Les professionnels de la sécurité doivent agir rapidement face à l’adversité et aux attaques directes, mais les temps modernes exigent des solutions modernes et nous ne pouvons tout simplement pas nous permettre d’adopter une approche moins globale. Le « shift left » doit être plus qu’un mot à la mode qui vieillit rapidement ; la sécurité au niveau du code doit être prioritaire, parallèlement à la mise à niveau et à la vérification des compétences des développeurs qui travaillent sur les logiciels et les infrastructures numériques critiques que nous tenons pour acquis. Après tout, qui veut l’équivalent d’un programme de sécurité d’Etch-a-Sketch alors qu’il pourrait avoir un iPad Pro ?</p><p>Aujourd’hui plus que jamais, les gouvernements et les entreprises doivent s’engager dans un programme de sécurité préventif et de sensibilisation, dans lequel chaque membre du personnel est habilité à partager la responsabilité. Il ne suffit pas de citer le manque de compétences en cybersécurité comme raison du retard pris ; l’investissement dans des développeurs sensibilisés à la sécurité et la promotion de la collaboration entre eux et leurs homologues AppSec devraient être une force motrice pour rester aussi sûr que possible, à la fois en tant qu’organisation et dans le cadre de la production de logiciels.</p><p>Matias Madou, co-fondateur et CTO de Secure Code Warrior, a contribué à cet article.</p>"
SASE est-il le DevSecOps de la gestion des infrastructures ?,"<p>Le DevOps a gagné en popularité lorsque les équipes informatiques et opérationnelles ont reconnu que les silos et les transferts traditionnels entraînaient des inefficacités et des retards dans la livraison des logiciels. Alors que le DevOps permettait une collaboration transparente et tenait ses promesses de rapidité et d'efficacité, la sécurité restait une préoccupation secondaire. Pour combler cette lacune en matière de sécurité, le DevSecOps a émergé, proposant une approche de la sécurité vers la gauche. Il met l'accent sur la réalisation de tâches telles que l'analyse de sécurité, l'évaluation des vulnérabilités et les contrôles de conformité tout au long du pipeline CI/CD.</p><p>Avec DevSecOps, la vitesse ne se fait plus au détriment de la sécurité.</p><p>L’approche DevSecOps a aidé les entreprises à trouver le juste équilibre entre sécurité et agilité dans le développement de logiciels. Alors que le paysage des infrastructures continue d’évoluer avec l’essor du cloud computing et de l’edge computing, les initiatives d’IA et de ML gourmandes en ressources et la main-d’œuvre distribuée, les entreprises doivent établir un équilibre similaire entre sécurité et connectivité omniprésente. C’est là qu’intervient le service d’accès sécurisé Edge (SASE).</p><h3>La philosophie de SASE est similaire à celle de DevSecOps</h3><p>Alors que les réseaux traditionnels, caractérisés par une infrastructure matérielle rigide, peinaient à suivre le rythme des exigences des entreprises modernes, le SD-WAN est apparu comme une solution offrant flexibilité, gestion centralisée et routage dynamique du trafic. Cependant, lorsque l'informatique distribuée et le travail à distance ont pratiquement dissous le périmètre de l'entreprise, les outils de sécurité axés sur le périmètre n'étaient plus suffisants. Aujourd'hui, les entreprises doivent étendre leurs capacités de sécurité à un nombre quasi illimité de points d'accès au réseau.</p><p>SASE relève ce défi en fusionnant la mise en réseau et la sécurité dans un seul cadre cloud natif. Il intègre l'ensemble de la pile de sécurité sur tous les sites périphériques, garantissant une connectivité sécurisée entre les utilisateurs, les applications et les ressources, où qu'ils se trouvent. Tout comme DevSecOps déplace la sécurité vers la gauche, en la faisant partie intégrante de l'ensemble du cycle de vie du développement logiciel (SDLC), SASE déplace la sécurité vers la périphérie du réseau, en la faisant partie intégrante de la connectivité réseau.</p><p>La ressemblance stratégique entre la philosophie derrière SASE et DevSecOps est troublante.</p><p>1. Briser les cloisonnements</p><p>DevSecOps élimine les cloisonnements entre les équipes DevOps et de sécurité, favorisant la collaboration et le partage des responsabilités. Dans la même optique, SASE unifie toutes les fonctions réseau et sécurité en une seule architecture, supprimant ainsi efficacement les frontières conventionnelles entre les équipes réseau et sécurité. Il permet aux deux équipes de gérer, surveiller et sécuriser conjointement l'infrastructure et le trafic réseau via un tableau de bord de gestion unifié. SASE élimine également efficacement les cloisonnements de données qui laissent les équipes de sécurité sans visibilité sur les conditions du réseau. La visibilité unique de SASE permet la corrélation des données réseau et de sécurité, élargissant la perspective de chaque équipe et éliminant la vision tunnel pour une détection précise et robuste des menaces et une posture de sécurité améliorée.</p><p>2. Adopter le Cloud</p><p>DevSecOps s'aligne parfaitement sur les technologies cloud natives telles que l'infrastructure en tant que code (IaC) et les technologies de conteneurisation telles que Docker, ce qui le rend impératif pour les organisations cloud-first et cloud-ready. D'autre part, SASE est intrinsèquement cloud-native. Il fournit des services réseau et de sécurité à partir du cloud, offrant aux organisations l'agilité et l'évolutivité nécessaires pour répondre aux exigences dynamiques d'un environnement distribué.</p><p>Les solutions traditionnelles de connectivité backhaul et de sécurité périmétrique introduisent des lacunes en termes de latence et de couverture. SASE exécute les fonctions réseau et de sécurité en périphérie, au plus près des ressources et des utilisateurs. Cela élimine le besoin de solutions ponctuelles sur site disparates et étend le périmètre de sécurité de l'entreprise pour correspondre à la portée mondiale du cloud.</p><p>3. Agilité grâce à l'automatisation</p><p>DevSecOps met l'accent sur l'automatisation des tâches de sécurité, telles que les contrôles de sécurité, les analyses et les évaluations de conformité, dans ses pipelines d'intégration continue et de livraison continue (CI/CD). SASE exploite également l'automatisation des tâches de mise en réseau et de sécurité, telles que l'application dynamique des politiques, la détection et la réponse aux menaces pilotées par l'IA et l'optimisation du réseau via le routage dynamique et les propriétés d'auto-réparation. L'automatisation réduit le besoin d'intervention manuelle, renforce la sécurité, simplifie les tâches opérationnelles et permet aux organisations de répondre plus rapidement aux demandes et aux circonstances en constante évolution, ce qui est essentiel pour les environnements agiles.</p><h3>SASE comme catalyseur pour DevSecOps</h3><p>Tout comme DevSecOps améliore la sécurité dans le contexte du développement d'applications, SASE améliore la sécurité et l'efficacité dans le domaine de la gestion des réseaux et des infrastructures. Les deux approches partagent les objectifs communs d'intégration de la sécurité, de promotion de l'automatisation et de garantie de l'évolutivité. Elles peuvent appliquer ces principes à différents aspects de l'informatique et de la cybersécurité, mais DevSecOps et SASE peuvent fonctionner ensemble de manière transparente pour prendre en charge les environnements informatiques modernes.</p><p>De nombreuses organisations adoptant DevSecOps se rendent compte qu’elles ne disposent pas de l’infrastructure nécessaire pour prendre en charge efficacement cette approche. DevSecOps exige une collaboration mondiale transparente et l’intégration de contrôles de sécurité dans l’ensemble de l’environnement informatique. C’est un aspect que SASE peut aider à atteindre. Il peut simplifier la gestion de l’infrastructure et améliorer la sécurité pour DevSecOps de plusieurs manières. Il offre une connectivité omniprésente pour une collaboration transparente, fournit des mesures de sécurité intégrées pour une réponse plus rapide aux incidents et garantit une infrastructure fiable. En tant que tels, tous ces aspects sont essentiels pour atteindre l’objectif ultime de DevSecOps, à savoir fournir des applications sécurisées et performantes à grande vitesse. Avec SASE, les organisations peuvent mettre leurs DevSecOps sur la voie du succès.</p>"
Utiliser le Low-Code/No-Code pour accélérer les solutions d'entreprise,"<p>Il n’y a pas si longtemps, il n’était pas rare que le déploiement d’une nouvelle application prenne un an ou plus. Aujourd’hui, ce délai se mesure en semaines. Qu’est-ce qui a changé ?</p><p>Pour de nombreuses entreprises, le développement d'applications traditionnel en cascade, avec son approche séquentielle de définition-développement-test-déploiement-maintenance, a cédé la place au développement low-code/no-code, une méthode plus rapide et plus accessible pour développer et modifier des applications à l'aide d'outils intuitifs sans codage approfondi. Les systèmes de développement low-code et no-code répondent aux demandes toujours croissantes de livraison rapide d'applications et de flux de travail d'automatisation hautement personnalisés.</p><p>En plus de redonner le contrôle aux utilisateurs qui connaissent le mieux leurs besoins, les systèmes low-code et no-code sont également reconnus pour améliorer la productivité des développeurs en permettant aux développeurs professionnels de rationaliser certains aspects du processus de développement.</p><p>Selon Gartner, le marché des plateformes no-code/low-code devrait croître de près de 20 % en 2023 pour atteindre 10 milliards de dollars et 12,3 milliards de dollars en 2024.</p><p>Cette croissance n’est pas surprenante si l’on considère les éléments suivants :</p><p>• Pénurie de talents technologiques. Le marché des plateformes low-code/no-code est en grande partie motivé par une pénurie mondiale de développeurs de logiciels qualifiés, une situation qui devrait perdurer tout au long de cette décennie. Les plateformes low-code/no-code permettent aux entreprises de lancer rapidement des projets de développement sans avoir besoin de développeurs professionnels.• Focus sur les coûts. Alors que les entreprises deviennent de plus en plus attentives à leurs dépenses technologiques, les solutions low-code/no-code peuvent offrir une alternative accélérée et moins coûteuse au développement de logiciels personnalisés, qui implique des développeurs professionnels, des cycles de développement plus longs et des programmes de support plus complets.• Nécessité de réduire les arriérés informatiques. Le low-code/no-code a également un impact significatif en réduisant les arriérés d'amélioration des applications dans les services informatiques et les demandes d'application des utilisateurs finaux qui n'ont pas encore été traitées. Dans de nombreuses entreprises, cet arriéré dure des années. Avec le no-code/low-code, les utilisateurs peuvent réellement créer et/ou modifier des applications eux-mêmes plutôt que d'attendre dans une file d'attente que leurs besoins soient satisfaits.• Développement agile. De nombreuses entreprises suivent aujourd'hui la méthodologie Agile de développement de logiciels, où les équipes travaillent ensemble dans des cycles incrémentiels pour s'améliorer en permanence. Les principaux moteurs du développement Agile sont la flexibilité et la rapidité. Le développement d'applications low-code/no-code peut permettre à ces équipes d'adopter une approche plus rapide du développement logiciel continu basé sur des éléments et des modèles prédéfinis et des interfaces glisser-déposer.• Croissance des applications cloud-native. La croissance des applications low-code/no-code est en partie due à l'adoption croissante des technologies cloud-native, les organisations adoptant rapidement les avantages et la disponibilité du cloud. Les avantages du développement de logiciels cloud-native comprennent une agilité accrue, des coûts d'hébergement réduits, une mise sur le marché plus rapide et des améliorations de l'expérience utilisateur.</p><h3>Varian Medical Systems utilise le Low-Code/No-Code pour garantir la conformité</h3><p>Les fournisseurs de logiciels d’entreprise d’aujourd’hui ouvrent de plus en plus leur code pour permettre une plus grande personnalisation et innovation des systèmes critiques. Prenons par exemple Varian Medical Systems, un fabricant leader de dispositifs médicaux et de logiciels pour le traitement du cancer et d’autres pathologies. En tant qu’entreprise mondiale du secteur des sciences de la vie, elle doit se conformer aux réglementations de la FDA et à celles d’autres organismes de réglementation du monde entier. Alors que son système de gestion de la qualité était en mesure de fournir un bon niveau de visibilité et de surveillance pour répondre aux exigences spécifiques de son marché, Varian souhaitait personnaliser le système pour ajouter une nouvelle couche de gestion de la conformité et rationaliser les principaux processus d’action sur le terrain. Elle a utilisé des modules low-code/no-code dans son système de gestion de la qualité (QMS) pour permettre la conformité et la standardisation des processus clés et s’intégrer à d’autres dossiers de qualité, tels que les dossiers de réunion ou les évaluations des réclamations et des risques, afin de recueillir plus facilement des informations à l’appui de l’action sur le terrain.</p><h3>Comprendre le paysage et les limites</h3><p>Alors que le développement low-code/no-code est en plein essor, aidant les entreprises à déployer des solutions presque prêtes à l'emploi rapidement, de manière rentable et avec moins de risques, il est essentiel de comprendre qu'il peut s'accompagner de sacrifices en termes d'évolutivité, de flexibilité et d'intégration avec les outils existants.</p><p>Les solutions ne disposent pas toujours d’une interface utilisateur personnalisée, elles ne disposent pas forcément de fonctionnalités inédites dans le secteur et sont souvent considérées comme des produits logiciels. Pourtant, ce n’est peut-être pas toujours la technologie qui détermine le résultat, mais l’expérience utilisateur qu’elle offre.</p><p>L’une des caractéristiques d’une organisation prospère est de parvenir à un bon équilibre entre coûts et bénéfices. Pour les organisations d’aujourd’hui, confrontées à des pénuries de main-d’œuvre, à des marges bénéficiaires serrées et à un besoin de rapidité, savoir quand un développement logiciel personnalisé de grande envergure est nécessaire et quand le low-code/no-code offre une approche meilleure et plus rentable peut faire la différence entre le succès et l’échec.</p>"
L'impact croissant de l'IA générative sur le développement Low-Code/No-Code,"<p>Les plateformes sans code/à faible code, autrefois révolutionnaires dans le domaine du développement logiciel, adoptent désormais les capacités de l’IA générative pour créer des expériences encore plus dynamiques. Cette alliance de commodité et d’innovation redéfinit la manière dont les utilisateurs interagissent avec leurs logiciels. Imaginez un scénario dans lequel l’élaboration d’instructions complexes telles que « Déployer la protection des terminaux sur des appareils non conformes » devient aussi simple que de converser avec votre application.</p><p>La fusion de l’IA générative et des plateformes sans code/à faible code permet aux utilisateurs de façonner le comportement de leur logiciel sans se plonger dans des détails techniques complexes. Les utilisateurs peuvent saisir des invites telles que « Générer un extrait de code pour convertir les formats de date » ou « Créer un flux de travail qui automatise les mises à jour d’inventaire ». En traduisant le langage naturel en action, cette approche rationalise le développement et favorise la créativité.</p><h3>Une fusion de l'IA générative et du No-Code/Low-Code</h3><p>Au-delà des mots à la mode, l’association de l’IA générative avec les plateformes no-code/low-code offre des avantages tangibles. Les gains d’efficacité qui se produisent lorsque les utilisateurs peuvent éviter la nécessité de configurations manuelles et communiquer directement leurs intentions sont à la fois remarquables et sans précédent. L’accessibilité est améliorée, ce qui permet aux personnes non techniques de participer activement au développement des applications. De plus, des cas d’utilisation innovants émergent, permettant aux organisations de rationaliser facilement des flux de travail complexes.</p><p>Comme pour toute technologie transformatrice, des défis apparaissent parallèlement aux avantages. Les préoccupations en matière de confidentialité sont importantes lorsqu’il s’agit de saisir des données dans des modèles d’IA générative. Il devient primordial de trouver un équilibre entre la fourniture d’informations précieuses et la protection des informations sensibles. En outre, la nature intrinsèquement non déterministe de l’IA générative peut conduire à des résultats variables, ce qui nécessite une réflexion approfondie sur les cas d’utilisation pour garantir des résultats fiables.</p><p>À mesure que cette collaboration gagne en maturité, le paysage du développement logiciel est sur le point de connaître des changements importants. Les interfaces conversationnelles qui permettent aux utilisateurs de dicter les comportements des logiciels continueront d’évoluer, réduisant ainsi les frais d’implémentation et de configuration. Imaginez un avenir où des flux de travail complexes sont déclenchés par une simple requête ou où les applications sont conçues sur mesure à partir de schémas en langage naturel. Ce changement permettra non seulement de rationaliser le développement, mais aussi de démocratiser la technologie, la rendant accessible à un public plus large.</p><p>L’intégration de l’IA générative avec des plateformes sans code ou à faible code permet aux utilisateurs d’exprimer leur créativité plus librement. En activant des invites en langage naturel telles que « Concevoir une application pour gérer les stocks avec réapprovisionnement automatique » ou « Créer un flux de travail qui envoie un utilisateur sur Google, Slack et Salesforce », les utilisateurs peuvent piloter les comportements logiciels sans être limités par le jargon technique.</p><p>Cette fusion redéfinit l'efficacité de l'interaction logicielle. Les tâches qui nécessitaient auparavant une configuration ou un codage minutieux peuvent désormais être exécutées via de simples invites. Qu'il s'agisse de générer des modèles d'e-mails, de créer des scripts de transformation de données ou d'orchestrer des flux de travail en plusieurs étapes, la commodité de la saisie en langage naturel élimine les obstacles et accélère les résultats.</p><h3>Une approche démocratique</h3><p>À l’avenir, l’intégration de l’IA générative dans les plateformes no-code/low-code laisse entrevoir une approche plus démocratique du développement logiciel. Cette convergence permettra à un plus large éventail d’individus de participer activement, quelle que soit leur expertise en codage. En simplifiant le processus et en le rendant plus inclusif, nous façonnons un avenir où les logiciels s’adaptent véritablement à l’intention humaine.</p><p>Alors que les entreprises continuent d’exploiter le potentiel de l’IA générative et des plateformes sans code/à faible code, l’adaptation et l’apprentissage seront essentiels. Adopter cette transformation nécessite un changement de mentalité et la compréhension que les logiciels peuvent être façonnés par des conversations et des suggestions. À mesure que la technologie mûrit, les barrières entre l’intention de l’utilisateur et le comportement du logiciel s’estomperont, inaugurant une ère où la maîtrise technologique sera définie par notre capacité à communiquer plutôt qu’à coder. Les spéculations sur l’impact de ce changement sur la réalité quotidienne des opérations informatiques repoussent les limites de la compréhension, mais elles seront certainement profondes.</p><p>L’intégration de l’IA générative aux plateformes no-code/low-code marque une avancée passionnante dans le développement logiciel. En permettant aux utilisateurs de communiquer naturellement leurs idées, leurs préférences et leurs besoins, les experts techniques et les utilisateurs non techniques peuvent, pour la première fois, contribuer de manière égale au processus de développement. L’IA générative étant de plus en plus utilisée pour le développement no-code/low-code, le processus de développement logiciel lui-même se transforme en conversation, plutôt qu’une base de code complexe en une conversation, rendant l’innovation plus accessible que jamais.</p>"
Développement d'applications Low-Code/No-Code : donner le contrôle aux utilisateurs,"<p>Il n’y a pas si longtemps, il n’était pas rare que le déploiement d’une nouvelle application prenne un an ou plus. Aujourd’hui, ce délai se mesure en semaines. Qu’est-ce qui a changé ?</p><p>Pour de nombreuses entreprises, le développement d'applications traditionnel en cascade, avec son approche séquentielle de définition-développement-test-déploiement-maintenance, a cédé la place au développement low-code/no-code, une méthode plus rapide et plus accessible pour développer et modifier des applications à l'aide d'outils intuitifs sans codage approfondi. Les systèmes de développement low-code et no-code répondent aux demandes toujours croissantes de livraison rapide d'applications et de flux de travail d'automatisation hautement personnalisés.</p><p>En plus de redonner le contrôle aux utilisateurs qui connaissent le mieux leurs besoins, les systèmes low-code et no-code sont également reconnus pour améliorer la productivité des développeurs en permettant aux développeurs professionnels de rationaliser certains aspects du processus de développement.</p><p>Selon Gartner, le marché des plateformes no-code/low-code devrait croître de près de 20 % en 2023 pour atteindre 10 milliards de dollars et 12,3 milliards de dollars en 2024. Cette croissance n'est pas surprenante si l'on considère les éléments suivants :</p><p>• Pénurie de talents technologiques. Le marché des plateformes low-code/no-code est en grande partie motivé par une pénurie mondiale de développeurs de logiciels qualifiés, une situation qui devrait perdurer tout au long de cette décennie. Les plateformes low-code/no-code permettent aux entreprises de lancer rapidement des projets de développement sans avoir besoin de développeurs professionnels.• Focus sur les coûts. Les entreprises étant de plus en plus attentives à leurs dépenses technologiques, les solutions low-code/no-code peuvent offrir une alternative accélérée et moins coûteuse au développement de logiciels personnalisés, qui implique des développeurs professionnels, des cycles de développement plus longs et des programmes de support plus complets.• Nécessité de réduire les arriérés informatiques. Le low-code/no-code a également un impact significatif en réduisant les arriérés d'amélioration des applications dans les services informatiques et les demandes d'application des utilisateurs finaux qui n'ont pas encore été traitées. Dans de nombreuses entreprises, cet arriéré dure des années. Avec le no-code/low-code, les utilisateurs peuvent réellement créer et/ou modifier des applications eux-mêmes plutôt que d'attendre dans une file d'attente que leurs besoins soient satisfaits.• Développement agile. De nombreuses entreprises suivent aujourd'hui la méthodologie Agile de développement de logiciels, où les équipes travaillent ensemble dans des cycles incrémentiels pour s'améliorer en permanence. Les principaux moteurs du développement Agile sont la flexibilité et la rapidité. Le développement d'applications low-code/no-code peut permettre à ces équipes d'adopter une approche plus rapide du développement logiciel continu basé sur des éléments et des modèles prédéfinis et des interfaces glisser-déposer.• Croissance des applications cloud-native. La croissance des applications low-code/no-code est en partie due à l'adoption croissante des technologies cloud-native, les organisations adoptant rapidement les avantages et la disponibilité du cloud. Les avantages du développement de logiciels cloud-native comprennent une agilité accrue, des coûts d'hébergement réduits, une mise sur le marché plus rapide et des améliorations de l'expérience utilisateur.</p><h3>Comprendre le paysage et les limites</h3><p>Alors que le développement low-code/no-code est en plein essor, aidant les entreprises à déployer des solutions presque prêtes à l'emploi rapidement, de manière rentable et avec moins de risques, il est essentiel de comprendre qu'il peut s'accompagner de sacrifices en termes d'évolutivité, de flexibilité et d'intégration avec les outils existants.</p><p>Les solutions ne disposent pas toujours d’une interface utilisateur personnalisée, elles ne disposent pas forcément de fonctionnalités inédites dans le secteur et sont souvent considérées comme des produits logiciels. Pourtant, ce n’est peut-être pas toujours la technologie qui détermine le résultat, mais l’expérience utilisateur qu’elle offre.</p><p>L’une des caractéristiques d’une organisation prospère est de parvenir à un bon équilibre entre coûts et bénéfices. Pour les organisations d’aujourd’hui, confrontées à des pénuries de main-d’œuvre, à des marges bénéficiaires serrées et à un besoin de rapidité, savoir quand un développement logiciel personnalisé de grande envergure est nécessaire et quand le low-code/no-code offre une approche meilleure et plus rentable peut faire la différence entre le succès et l’échec.</p>"
Microsoft tue Python 3.7 ¦ … et VBScript ¦ Exascale ARM sur Jupiter,"<p>Bienvenue dans The Long View, où nous passons en revue l'actualité de la semaine et en tirons l'essentiel. Déterminons ce qui compte vraiment.</p><p>Cette semaine : VS Code abandonne le support de Python 3.7, Windows abandonne VBScript et l'Europe prévoit le supercalculateur ARM le plus rapide.</p><p>Tout d’abord cette semaine : Microsoft abandonne la prise en charge de Python 3.7 dans l’extension Python de Visual Studio Code. Cela continuera probablement à fonctionner pendant un certain temps, cependant (l’accent est mis sur le « probablement »).</p><h3>Analyse : Le langage de script obsolète est obsolète</h3><p>Si vous utilisez toujours la version 3.7, pourquoi ? Il est temps de passer à autre chose : la version 3.12 est la nouvelle tendance. Même la version 3.8 est en sursis.</p><p>Priya Walia : Microsoft fait ses adieux à Python 3.7</p><p>« L’influence croissante du langage Python »Python 3.7, bien qu’ayant atteint sa fin de vie en juin, reste une version très populaire parmi les développeurs. … Microsoft s’attend à ce que l’extension continue de fonctionner de manière non officielle avec Python 3.7 dans un avenir prévisible, mais rien ne garantit que tout fonctionnera correctement sans le soutien d’un support officiel. … Le récent lancement par Microsoft de scripts Python dans Excel souligne l’influence croissante du langage Python dans divers domaines. Cette initiative ouvre de nouvelles perspectives aux développeurs Python pour travailler avec des données dans le célèbre logiciel de tableur. Cependant, tout ne se passe pas sans heurts, car de récentes failles de sécurité dans certains packages Python ont posé des problèmes.</p><p>Python ? N’est-ce pas un langage de jeu ? Ce lâche anonyme dit le contraire :</p><p>Ha, dites ça à Instagram, Spotify, Nextdoor, Disqus, BitBucket, DropBox, Pinterest ou YouTube. Ou au domaine de la science des données, aux mathématiciens ou à la communauté de l'intelligence artificielle.... Notre production actuelle exécute la version 3.10, mais nous avons hâte de la déplacer vers Python 3.11 (la version 3.12 étant un peu trop récente) en raison des augmentations de vitesse allant jusqu'à 60 %. ... Si vous êtes encore quelque part avant la version 3.11, essayez de passer directement à la version 3.11.6.... Les principales améliorations... sont des améliorations de l'interpréteur et du compilateur pour créer un bytecode plus rapide pour l'exécution, parfois de nouvelles fonctionnalités pour écrire du code plus efficacement et des correctifs occasionnels pour supprimer l'ambiguïté. J'exécute Python en production depuis quatre ans maintenant, en migrant de la version 3.8 -> 3.9 -> 3.10 et bientôt vers la version 3.11 et jusqu'à présent, nous n'avons jamais eu à apporter de modifications à notre base de code pour fonctionner avec une nouvelle mise à jour du langage.</p><p>Et Sodul dit que la réputation de Python de ne pas être compatible avec les versions antérieures n'est pas nouvelle :</p><p>La plupart des codes écrits pour Python 3.7 fonctionneront parfaitement dans la version 3.12. … Nous effectuons des mises à jour une fois par an et la plupart des problèmes que nous rencontrons sont liés à des SDK tiers qui ont trop d’opinions sur leurs propres dépendances. Nous effectuons des changements radicaux, mais nous trouvons surtout des bugs préexistants qui sont découverts grâce à une meilleure annotation de type, ce qui est essentiel dans les projets Python de plus grande envergure.</p><p>Microsoft abandonne également VBScript dans le client Windows. Il continuera probablement à fonctionner pendant un certain temps en tant que fonctionnalité à la demande (je souligne le « probablement »).</p><h3>Analyse : Le langage de script obsolète est obsolète</h3><p>Si vous utilisez toujours VBScript, pourquoi ? Il est temps de passer à autre chose : PowerShell est la nouvelle tendance, et il est même multiplateforme.</p><p>Sergiu Gatlan : Microsoft va supprimer VBScript dans Windows</p><p>« Campagnes de malware » VBScript (également connu sous le nom de Visual Basic Script ou Microsoft Visual Basic Scripting Edition) est un langage de programmation similaire à Visual Basic ou Visual Basic for Applications (VBA) et a été introduit il y a près de 30 ans, en août 1996. Il… intègre des scripts actifs dans les environnements Windows et communique avec les applications hôtes via Windows Script.… Bien que cela ne soit pas officiellement expliqué, la décision de Microsoft de déprécier VBScript fait probablement… partie d’une stratégie plus large visant à atténuer la prévalence croissante des campagnes de malware exploitant diverses fonctionnalités de Windows et Office pour les infections. Des acteurs malveillants ont utilisé VBScript pour distribuer des malwares, notamment des souches notoires comme Lokibot, Emotet, Qbot et, plus récemment, le malware DarkGate, entre autres.</p><p>La nostalgie n’est plus ce qu’elle était. Avec les larmes aux yeux, voici un whoopdedo :</p><p>Je suis un peu nostalgique à ce sujet. Pas à cause de VBScript… mais à cause d’ActiveState qui fournissait des interpréteurs Perl, TCP et Python fonctionnant avec Windows Script Host. Je pouvais créer et appeler des interfaces COM ainsi que la bibliothèque CPAN parmi lesquelles choisir… Cela faisait partie du rêve d’OLE que les utilisateurs disposent de nombreux petits scripts automatisant leurs flux de travail orientés composants. Au lieu de cela, nous avons eu un codage culte du cargo et d’innombrables vulnérabilités car, pour emprunter une expression aux gens de l’IoT, le « S » de COM/OLE signifie sécurité.</p><p>La seule constante est le changement. xzelldx prédit beaucoup de plaisir pour DevOps et l'informatique :</p><p>Cela va casser des choses bizarrement. … J’imagine que cela va se transformer en une sorte de mini problème de l’an 2000, où la plupart des gens ne sauront pas que cela touche quelque chose jusqu’à ce que cela se produise. … Maintenant, je peux exécuter une recherche .vbs et déterminer ce qui utilise quoi et si je peux amener la personne qui le possède à comprendre le problème.</p><p>Ces Européens sournois prévoient de construire un supercalculateur incroyablement rapide, qui fonctionnerait avec des puces ARM.</p><h3>Analyse : ExaFLOPS en vue</h3><p>Les conceptions Neoverse d’Arm semblent vraiment attrayantes pour les constructeurs HPC. C’est également la base de l’AWS Graviton3. Comme toujours, tout est une question de performances par watt.</p><p>Ryan Whitwam : Le supercalculateur exascale fonctionnera sur ARM</p><p>« Début 2024 » L’un des supercalculateurs les plus puissants du monde sera bientôt en ligne en Europe, mais ce n’est pas seulement la vitesse brute qui rendra le supercalculateur Jupiter spécial. Contrairement à la plupart des supercalculateurs du Top 500, le système exascale Jupiter s’appuiera sur des cœurs ARM au lieu de pièces x86. … Une fois terminé, Jupiter sera tout en haut de la liste des supercalculateurs. … Jupiter est un projet de l’entreprise commune européenne pour le calcul haute performance (EuroHPC JU), qui … a choisi d’utiliser le processeur Rhea de SiPearl … basé sur l’architecture ARM. … Rhea est basé sur la conception du processeur Neoverse V1 d’ARM, qui a été développé spécifiquement pour les applications de calcul haute performance (HPC) avec 72 cœurs. Il prend en charge la mémoire à large bande passante HBM2e, ainsi que la DDR5, et le cache plafonne à un impressionnant 160 Mo.… Le système sera doté du module Booster de Nvidia, qui comprend des GPU et des interconnexions à bande passante ultra-élevée Mellanox. Le groupe n'a pas annoncé quelles puces Nvidia… mais la génération actuelle de H100 semble être une valeur sûre. … L'assemblage pourrait commencer dès le début de l'année 2024.</p><p>La seule constante est le changement (je l'ai peut-être mentionné plus tôt). Darinbob explique l'abandon du x86 :</p><p>Français À l’époque du calcul parallèle ou des supercalculateurs, les familles x86 étaient correctes, mais pas géniales. … Les temps ont évolué, mais il semble que la raison pour laquelle les gens utilisent des puces compatibles Intel x86/64 pour les supercalculateurs est que c’est tout ce que les gens connaissent désormais. … Les puces modernes ont des problèmes dans les supercalculateurs : le processeur de votre PC est en fait une grosse pile de puces avec plusieurs couches, il y a beaucoup de choses qui gênent les performances et c’est là pour la compatibilité, etc. … Les processeurs x86-64 modernes sont des machines RISC, ils sont juste cachés derrière une dominatrice CISC. … L’une des raisons pour lesquelles les GPU sont beaucoup utilisés dans ce domaine est que la conception (et la programmation !) des GPU est fortement orientée vers les calculs optimisés, pas vers des applications Web à usage général, etc. Le pipeline massif, la superscaling et le traitement vectoriel sont intégrés, exactement les composants que vous voulez avec les supercalculateurs.</p><p>Mais ARM est-il prêt pour le DevOps classique ? Voici l'expérience personnelle de customizable :</p><p>Nous avons déplacé plusieurs serveurs PostgreSQL, dont un grand utilisant 32 vCPU, vers des instances équivalentes basées sur ARM, et les performances étaient à peu près les mêmes, mais bien sûr, les instances ARM sont moins chères.</p><p>[Vous êtes viré – NDLR] Vous lisez The Long View de Richi Jennings. Vous pouvez le contacter à @RiCHi, @richij ou à [email protected].</p><p>Image : @flaviewxvx (via Unsplash ; nivelée et recadrée)</p>"
"Raspberry Pi 5 : plus rapide, plus performant, plus puissant — plus cher","<p>Bienvenue dans The Long View, où nous passons en revue l'actualité de la semaine et en tirons l'essentiel. Déterminons ce qui compte vraiment.</p><p>Dans un article supplémentaire insolent cette semaine : l’ordinateur monocarte ARM préféré de tous, le Raspberry Pi, va bientôt sortir une nouvelle génération. Par rapport au ’4, le RPi5 a deux fois plus de performances, quatre fois plus de RAM de base et des E/S bien plus performantes.</p><h3>Analyse : Et vous pourrez même en acheter un</h3><p>La pandémie a complètement bouleversé les chaînes d’approvisionnement de la Fondation Raspberry Pi, qui a dû se concentrer sur l’approvisionnement des entreprises qui avaient acheté les appareils en avance. Cette fois, l’équipe d’Eben Upton tente de revenir à ses racines, en promettant, pendant les deux premiers mois, de vendre des RPi5 uniquement aux particuliers.</p><p>Quelle est l’histoire ? Alaina Yee rapporte : « Le Raspberry Pi 5 vient d’être annoncé » :</p><p>« J’ai hâte » Oubliez la tarte des fêtes, c’est ce que je veux sur ma table pour Thanksgiving. … Il a l’air totalement génial. … Non seulement le Raspberry Pi 5 semble prêt à offrir une amélioration considérable des performances par rapport à son prédécesseur de 2019, mais son nouveau silicium a été conçu en interne. … Le Raspberry Pi 5 se penche fortement sur le mini-calcul à indice d’octane élevé. … Vous pouvez vous attendre à ce que le Raspberry Pi 5 soit environ deux à trois fois plus rapide. La bande passante mémoire double également. … Et… un nouveau système d’exploitation officiel de première partie sera lancé… à la mi-octobre. Appelé Raspberry Pi OS, il est basé sur la distribution Linux Debian, ainsi que sur le dérivé Raspbian qui existe depuis des années. … J’ai hâte.</p><p>Vitesse et alimentation ? Brad Linder les a : « Le Raspberry Pi 5 offre deux fois plus de performances » :</p><p>« 4x ARM Cortex-A76 » Le nouveau Raspberry Pi 5 est un ordinateur monocarte qui constitue une mise à niveau majeure par rapport au Raspberry Pi 4… à presque tous les égards. … Au lancement, deux configurations seront disponibles : un modèle avec 4 Go de RAM vendu 60 $ et une version 8 Go au prix de 80 $. Cela signifie que le modèle de départ dispose de deux fois plus de RAM qu'un Raspberry Pi 4 à 35 $. … Au cœur du nouvel ordinateur se trouve une nouvelle… puce 16 nm dotée de 4 cœurs de processeur ARM Cortex-A76 à 2,4 GHz, d'un cache L2 de 512 Ko par cœur, d'un cache L3 de 2 Mo, d'une carte graphique VideoCore VII avec prise en charge de deux écrans HDMI 4k/60 Hz. [Il] dispose également d'une mémoire LPDDR4X 32 bits 4267MT/s… 2x micro HDMI (4K/60Hz), 2x USB 3.0 Type-A, 2x USB 2.0 Type-A, 1x Gigabit Ethernet avec prise en charge PoE, 1x entrée d'alimentation USB-C, 1x lecteur de carte microSD. … Il existe également deux interfaces MIPI à 4 voies.</p><p>La bouche d’un cheval ? Eben Upton — « Présentation : Raspberry Pi 5 ! » :</p><p>« Nous sommes incroyablement reconnaissants » Pratiquement tous les aspects de la plateforme ont été mis à niveau, offrant une expérience utilisateur sans compromis. … Et c’est le premier ordinateur Raspberry Pi à intégrer du silicium conçu en interne ici à Cambridge, au Royaume-Uni. … Le VideoCore VII de Broadcom [est également] développé ici. … Comme tous les produits phares Raspberry Pi [il est] construit au Sony UK Technology Centre à Pencoed, au sud du Pays de Galles. Nous travaillons avec Sony depuis le lancement du premier Raspberry Pi… en 2012, et nous sommes convaincus des avantages de la fabrication de nos produits à quelques heures de route de notre centre de conception technique de Cambridge. … Nous prévoyons que les premières unités seront expédiées d’ici la fin octobre. … Nous sommes incroyablement reconnaissants envers la communauté de créateurs et de hackers qui font de Raspberry Pi ce qu’il est. [Ainsi,] nous allons réserver tous les Raspberry Pi 5 que nous vendons au moins jusqu’à la fin de l’année pour les ventes à l’unité aux particuliers.</p><p>Êtes-vous déjà excité ? Dioptase est excité par les petites choses :</p><p>Une fonctionnalité importante qui n'a pas encore été mentionnée est le bouton d'alimentation souple. Il démarre le RPI 5 ainsi que l'éteint. Je crois que le mode par défaut est de passer en mode veille, mais il existe apparemment une option pour exécuter un script d'arrêt. Pour les configurations sans tête, c'est une excellente nouvelle. J'ai appris à mes dépens que le système de fichiers peut être corrompu si vous le débranchez simplement.</p><p>À quoi ça ressemble ? Chewitt l'a déjà goûté :</p><p>Il y a des changements significatifs dans les performances d'E/S :… SD prend en charge SRD104, USB3 fonctionne à 5 Gbit/s sur les deux sockets, RAM LPDDR4, tous les périphériques GPIO sont maintenant gérés par une puce RP1 dédiée (Cortex M3) pour ajouter de la bande passante.… J'ai eu une image fonctionnellement complète construite et fonctionnant 58 minutes après que DHL a livré l'échantillon de carte ; c'est la mise en place de carte la moins difficile que j'ai jamais faite avec la distribution. Je suis sûr que les développeurs de Pi (et les nombreux entrepreneurs et ateliers de développement bien connus qu'ils ont embauchés pour faire des choses spécifiques) s'accorderont une petite pause et une bière aujourd'hui, mais ensuite, le développement du code en amont commencera.</p><p>OK, c'est plus rapide, mais est-ce assez rapide ? Johannesburgel12 se demande :</p><p>Le Cortex-A76 est une conception vieille de cinq ans qui a été dépassée par cinq (!) générations de cœurs ARM (A77, A78, A710, A715, A720). … Les conceptions plus modernes sur un processus de fabrication plus moderne produiraient en fait des puces plus petites avec une consommation d’énergie plus faible. Mais je n’ai jamais vraiment compris pourquoi ils devaient créer leurs propres conceptions de puces pour commencer.</p><p>Mais TheJish pense que cela passe à côté de l’essentiel :</p><p>Je suis d’accord qu’il existe de bien meilleures options SBC. … Cependant, là où le RPi brille, c’est dans la maturité de la pile logicielle qui lui est associée. La prise en charge de la vidéo, de l’audio et des E/S est vraiment excellente sur le RPi par rapport aux autres fournisseurs. … La pile d’E/S fonctionne tout simplement, et elle fonctionne de manière fiable (sans parler de la disponibilité de la documentation). Nous avons porté notre plateforme sur les NanoPi M4 et M4B et n’avons eu que des problèmes. … En fin de compte, si vous voulez faire de vraies choses sur les systèmes embarqués avec votre SBC, vous aurez beaucoup plus de facilité avec le RPi qu’avec n’importe quel autre produit de sa catégorie.</p><p>Les excuses d’Upton mises à part, n’oublions pas le pachyderme dans le salon. baylf2000 n’oublie ni ne pardonne :</p><p>Après la façon dont Raspberry a traité sa base de fans fidèles pendant la pandémie, les mettant de côté pour gagner beaucoup d'argent avec ses gros clients corporatifs, je vais désormais laisser tomber tous leurs produits. … Après la façon dont ils ont traité leur communauté, ils peuvent aller se faire foutre.</p><p>En attendant, il semble qu'il puisse exécuter les versions ARM de Windows. Boris le cafard nous montre la scène :</p><p>Ahhh, c'est un très bon processeur que tu as là. Ce serait dommage qu'il arrive quelque chose à tous ces cycles d'horloge en trop.</p><p>—Joel OsteenVous lisez The Long View de Richi Jennings. Vous pouvez le contacter à @RiCHi, @richij ou [email protected].</p><p>Image : Paul Shore (via Unsplash ; nivelée et recadrée)</p>"
Low-Code et IA : amis ou ennemis ?,"<p>Les frontières entre le low-code et la nouvelle intelligence artificielle (IA) sont de plus en plus floues. Historiquement, les plateformes low-code/no-code ont introduit l’automatisation du développement logiciel via des interfaces utilisateur graphiques, permettant aux développeurs professionnels et citoyens de créer rapidement des flux de travail et de générer des applications. Mais l’essor des grands modèles de langage (LLM) représente une menace existentielle pour le statu quo du développement low-code.</p><p>Alors, l’IA générative et le low-code sont-ils amis ou ennemis ? Étant donné que la nouvelle IA générative peut produire du code complexe en quelques millisecondes à partir d’invites en langage naturel, la barrière au développement de logiciels n’a jamais été aussi basse. D’un autre côté, les entreprises ont déjà des pratiques et des opérations low-code bien ancrées, qui pourraient perdurer pendant un certain temps. Dans cette optique, il existe de nombreuses façons pour l’IA et le low-code de coexister.</p><p>Ci-dessous, nous verrons si l’IA et le low-code sont des outils diamétralement opposés ou des forces complémentaires. Nous verrons comment l’IA et le low-code fusionnent et examinerons les avantages de leur utilisation en tandem.</p><p>Les LLM, comme GPT-3.5 et GPT-4 d’OpenAI, peuvent offrir des capacités impressionnantes de génération de logiciels, comme la création d’extraits de code et même de programmes complets à partir d’invites en langage naturel. En raison de ces capacités remarquables, il est logique que les plateformes low-code se méfient un peu de l’IA.</p><p>L’intelligence artificielle peut effectivement tenir certaines des promesses initiales du low-code, comme la démocratisation des logiciels, une agilité accrue et la réduction du déficit de compétences grandissant. « ChatGPT pourrait permettre aux utilisateurs d’apporter des modifications plus importantes aux applications, ce qui permettrait potentiellement aux entreprises d’accomplir bien plus qu’avec le low-code et en deux fois moins de temps », a écrit Romy Hughes sur DevOps.com.</p><p>Les LLM peuvent également accélérer le côté DevOps de l’équation cloud native de nombreuses manières. En plus de la génération de code, l’IA pourrait aider à générer des manifestes de configuration, exécuter des tests de code et effectuer des analyses de cybersécurité. Si l’IA ne peut pas remplacer complètement la subtilité de la supervision humaine, elle peut en effet automatiser de plus en plus d’éléments du cycle de vie du développement logiciel.</p><p>Même s’il semble probable que l’IA remplace le low-code, il existe en réalité de nombreuses possibilités de symbiose entre les deux concepts. Plutôt que d’éradiquer complètement les plateformes low-code, les LLM vont probablement y être davantage intégrés. Nous avons déjà vu cela se produire lorsque des fournisseurs low-code comme Mendix et OutSystems ont intégré des connecteurs ChatGPT. Microsoft a également intégré ChatGPT dans sa Power Platform ainsi que des copilotes pilotés par GPT dans divers environnements de développement.</p><p>« Le low-code et l’IA sont des outils puissants pour accroître l’efficacité et la productivité des entreprises », a déclaré Dinesh Varadharajan, directeur des produits chez Kissflow. « Mais la combinaison des deux pourrait permettre de mettre en place une automatisation révolutionnaire pour presque tous les secteurs. La puissance de ces deux outils vient de la congruence entre le low-code/no-code et l’IA. »</p><p>Il est également possible de former des LLM sur mesure sur le fonctionnement interne de plateformes de développement logiciel spécifiques, qui pourraient générer des modèles entièrement construits à partir d'invites en langage naturel. Cela rendrait le LLM plus personnalisé et plus pertinent pour la plateforme en question et faciliterait la fluidité du développement. En plus de l'intégration des LLM existants, une autre synergie potentielle est que les solutions low-code pourraient aider à automatiser la formation de nouveaux modèles d'IA personnalisés.</p><p>Comme pour toute solution technologique, les choix doivent être guidés par des résultats commerciaux concrets. Commencez par définir les objectifs commerciaux et laissez-les déterminer les solutions technologiques qui vous permettront d'obtenir les résultats souhaités. Dans le contexte du low-code et de l'IA, cela peut équivaloir à décider quels modèles prendre en charge.</p><p>Ensuite, les entreprises doivent éviter les risques liés à l’utilisation de plateformes low-code. Et du côté de l’IA, les plateformes devront gérer la confidentialité des données et les complications juridiques liées à l’utilisation de LLM publics. Comme toute nouvelle technologie, l’IA et le low-code nécessiteront une gouvernance, a déclaré Varadharajan. « Les organisations doivent intervenir pour normaliser les outils, les processus et les cycles DevOps. Seuls certains outils basés sur l’IA devraient être approuvés pour le développement lorsque des accords de sécurité, de confidentialité et de protection de la propriété intellectuelle sont en place. »</p><p>Il a également expliqué que pour tirer parti des avantages des deux stratégies, il serait primordial de se concentrer sur la gestion du changement. « Je pense que le plus grand obstacle à l’adoption et à la mise en œuvre sera la gestion du changement », a-t-il déclaré. « Les utilisateurs en entreprise sont habitués à certaines méthodes de travail et peuvent être réticents au changement, ce qui les rend peu susceptibles d’adopter le low-code basé sur l’IA. Les dirigeants doivent anticiper cela et intégrer la gestion du changement dans leur stratégie d’adoption de l’IA/du low-code. »</p><p>Le low-code est apparu pour aider les développeurs citoyens à créer des applications sans nécessiter d’expérience technique avancée. Cependant, le low-code nécessite toujours une connaissance de la plateforme de développement ainsi que des terminologies et formules de programmation spécifiques. Mais maintenant, comme l’IA générative se comporte en réponse au langage naturel, elle a le potentiel de contourner instantanément cette barrière.</p><p>« L’IA générative comble ce fossé sémantique », a déclaré Varadharajan. « L’IA générative sert de traducteur et les utilisateurs n’ont plus besoin de comprendre exactement comment fonctionne le système. »</p><p>À mesure que de plus en plus de programmeurs en binôme IA arrivent sur le marché, les attentes augmentent dans tous les domaines du développement logiciel, y compris les plateformes low-code, pour intégrer ces modèles avancés. Si les dirigeants parviennent à gérer efficacement le changement technique, les résultats augmenteront probablement considérablement l'agilité et la productivité.</p><p>« En fin de compte, tous les développeurs finiront par gagner du temps en déléguant des tâches répétitives à ces programmeurs en binôme alimentés par l’IA », a déclaré Varadharajan.</p>"
Le nouvel environnement de développement d’IA de Google : le projet « expérimental » IDX,"<p>Bienvenue dans The Long View, où nous passons en revue l'actualité de la semaine et en tirons l'essentiel. Déterminons ce qui compte vraiment.</p><p>Cette semaine : l'environnement de développement cloud de Google, basé sur un navigateur et entièrement en pile. Il ne s'agit pas d'un simple clone de Copilot, mais il vise à vous aider à « faire passer une application de zéro à la production ».</p><h3>Analyse : louable mais risquée</h3><p>Cela semble être un objectif formidable, surtout lorsque les émulateurs Android et iOS seront intégrés. Mais devriez-vous vous lancer à fond dans un projet « expérimental » d’une entreprise connue pour son support médiocre et pour ses projets abandonnés ?</p><p>Quelle est l’histoire ? Frédéric Lardinois rapporte : « Google lance le projet IDX » :</p><p>« Focus sur le développement full-stack » Le projet IDX [propose] un environnement de développement basé sur un navigateur et activé par l’IA pour créer des applications Web et multiplateformes full-stack. Il prend actuellement en charge des frameworks comme Angular, Flutter, Next.js, React, Svelte et Vue, ainsi que des langages comme JavaScript et Dart, avec la prise en charge de Python, Go et d’autres en cours de développement. … Il utilise Visual Studio Code [permettant] à l’équipe de se concentrer sur l’intégration avec Codey, le modèle de base basé sur PaLM 2 de Google pour les tâches de programmation. … IDX prend en charge la saisie semi-automatique intelligente du code, un chatbot de type ChatGPT/Bard qui peut aider les développeurs à répondre à des questions générales sur le codage ainsi qu’à celles liées spécifiquement au code sur lequel vous travaillez [et] à des actions de code contextuelles telles que « ajouter des commentaires ». … En tant qu’IDE basé sur le cloud, il n’est pas surprenant que le projet IDX s’intègre à Firebase Hosting de Google (et à Google Cloud Functions). … Chaque espace de travail a accès à une machine virtuelle (VM) basée sur Linux et, bientôt, à des simulateurs Android et iOS intégrés directement dans le navigateur. … Alors que Copilot de GitHub, CodeWhisperer d’Amazon et d’autres offrent des fonctionnalités de codage IA similaires, l’accent mis par Google sur le développement full-stack apporte une tournure légèrement différente à ce thème.</p><p>Faites-moi un portrait. Maria Diaz espère que cela « rendra le développement de logiciels multiplateformes aussi accessible que l’utilisation de Google Docs » :</p><p>« Programme d’aperçu » Imaginez un outil tout-en-un pour le développement de logiciels auquel vous pouvez accéder depuis votre navigateur Web, où que vous soyez, même sur votre tablette. … Vous n’avez pas besoin d’attendre bien longtemps : Google vient de dévoiler Project IDX, une plateforme qui centralise les configurations dans un environnement basé sur un navigateur pour simplifier le processus de programmation. … Google n’a pas communiqué d’informations sur les prix de sa nouvelle plateforme ni sur la date à laquelle elle sera largement disponible. … L’accès à Project IDX est limité à un programme d’aperçu gratuit.</p><p>Une bouche à cheval ? Bre Arder, Kirupa Chinnathambi, Ashwin Raghav Mohan Ganesh, Erin Kidwell et Roman Nurik — « Une expérience pour améliorer le développement d’applications multiplateformes et full-stack » :</p><p>« En quelques clics seulement » Faire passer une application de zéro à la production… peut donner l’impression de construire une machine Rube Goldberg. Vous devez naviguer dans une mer infinie de complexité, en assemblant avec du ruban adhésif une pile technologique qui vous aidera à démarrer, compiler, tester, déployer et surveiller vos applications. … Il y a donc plusieurs mois, quelques-uns d’entre nous se sont réunis et ont commencé à expérimenter. … Avec le projet IDX, nous explorons comment [l’IA] peut vous aider non seulement à écrire du code plus rapidement, mais aussi à écrire du code de meilleure qualité. Actuellement, le projet IDX dispose d’une saisie semi-automatique de code intelligente, d’un chatbot d’assistance et d’actions de code contextuelles telles que « ajouter des commentaires » et « expliquer ce code ». … Nous avons facilité le [déploiement] en intégrant Firebase Hosting, ce qui permet de déployer un aperçu partageable de votre application Web ou de la déployer en production… en quelques clics seulement. Et comme Firebase Hosting prend en charge les backends dynamiques, optimisés par Cloud Functions, cela fonctionne parfaitement pour les frameworks full-stack comme Next.js. [Il] est également construit sur Code OSS, il devrait donc vous sembler familier, peu importe ce que vous construisez.</p><p>Sur quoi repose le développement actuel ? Paul Thurrott explique : « Google annonce un environnement de développement basé sur un navigateur et basé sur l'IA » :</p><p>« Project IDX devient la valeur par défaut » Cela va vous sembler assez familier car il est basé sur Microsoft Visual Studio Code, même si Google n’a jamais pris la peine de le mentionner. … « Code OSS », comme Google l’appelle à tort… renvoie vers le référentiel Visual Studio Code de Microsoft sur GitHub. Et je vais juste exprimer brièvement ma tristesse que cette entreprise n’ait pas pu s’écarter suffisamment longtemps de son chemin pour reconnaître explicitement sa dépendance à tout le travail qui a déjà été fait dans ce domaine. … Passons à autre chose… Je commence à comprendre pourquoi Tim Sneath, qui était auparavant en charge de Flutter, a quitté Google récemment : Il est très clair que Project IDX remplacera un jour Flutter et les autres solutions de développement multiplateformes de Google… Je vois… Google pense que Project IDX devient l’environnement par défaut/supposé pour Flutter, et qu’au fil du temps, cela fait à Android Studio ce que VS Code fait à VS complet : prendre en charge de plus en plus de ses rôles et déplacer les développeurs vers un environnement plus moderne et adaptable. … Google propose trop de solutions de développement différentes, trop de façons de faire les mêmes choses (ou presque). Peut-être que cela se transformera en quelque chose de plus ciblé.</p><p>L'IA mise à part, à quoi ça sert ? Smokel vit dans le monde réel :</p><p>Bien sûr, il est facile de mettre en place un environnement de développement pour votre petit projet personnel. Mais dès que vous commencez à travailler sur un logiciel maintenu depuis quelques années, les dépendances commencent à se développer. Un ancien projet Java typique dépend de Gradle (ou de Maven, voire d'Ant), d'un JDK obsolète, d'Eclipse, des outils Protobuf, des outils XML, des outils personnalisés, etc. Ensuite, votre projet peut nécessiter un linting, un formatage et sera vérifié par certains services tiers. Récemment, Docker et ses amis ont rejoint la fête, et un frontend basé sur le Web nécessite TypeScript, un framework, Webpack et de nombreuses autres bibliothèques et outils. Rejoindre une équipe avec un tel projet n'est pas une tâche facile. Dans un projet de code typique de 500 000 lignes, il peut falloir une journée entière ou plus pour que le système de base soit opérationnel. Toutes les dépendances peuvent se briser de multiples façons et peuvent entraîner de nombreuses recherches de problèmes inutiles. … Cela me permettrait d’économiser beaucoup d’argent et d’efforts si je pouvais disposer d’un environnement de développement reproductible, et cela ne me dérangerait pas que ce soit dans le cloud ou non.</p><p>Cela semble intéressant. Le développeur professionnel Steven Allen est « étonnamment enthousiaste » :</p><p>En tant que développeur professionnel, cela m'enthousiasme étonnamment. Plus besoin d'essayer de configurer une nouvelle pile de développement à chaque fois que je change de projet. C'est vraiment génial. … S'ils parviennent à réussir une transition transparente d'une pile à l'autre, c'est un coup de maître.</p><p>Mais ne risquons-nous pas d’encourager Google à nous remplacer par l’IA ? jma05 n’en est pas si sûr :</p><p>Ne préféreriez-vous pas que les tâches les plus simples soient automatisées et que vous puissiez vous concentrer sur les aspects de plus haut niveau de la tâche, y compris l’intégration ? C’est comme si les langages de machine virtuelle s’occupaient de la gestion de la mémoire afin que vous puissiez vous concentrer sur la logique métier.</p><p>Et VSCode, alors ? abend0c4 aurait aimé que Google sorte des sentiers battus :</p><p>Une expérience de développement basée sur un navigateur ? Je ne suis pas un grand fan de ce genre de choses. … Même VSCode (qui est, en fait, une solution basée sur un navigateur) me semble plutôt maladroit. Si nous devons utiliser un modèle d’interface basé sur le pointage et le clic, ne pourrions-nous pas… avoir quelque chose d’un peu plus, disons, véritablement visuel ?</p><p>Mais Google, dahwolf n'est pas fan :</p><p>Vous ne devriez rien faire de sérieux avec la technologie basée sur Google… car on ne peut pas compter sur elle pour être correctement prise en charge ou même pour exister du tout. … On peut supposer sans risque que toutes les données qui peuvent être collectées seront envoyées au vaisseau-mère pour le but qu’ils jugent approprié. … Google est à la fois nuisible et puéril. Ils ne prennent pas leurs responsabilités. Ils jouent comme des petits enfants et ne peuvent même pas saisir le concept de client. [Mais] leur bureau est une excellente garderie pour adultes. … En effet… les piles d’applications modernes sont complexes, [mais] IDX ne résout pas du tout ce problème. Il y a le même nombre de pièces mobiles derrière le rideau, c’est juste que les assembler est plus facile.</p><p>En attendant, je suppose que kbg signifie « Killed By Google » :</p><p>Quelqu'un veut-il donner le meilleur de lui-même lorsque ce projet sera dans le cimetière de Google ? Je lui donne deux ans.</p><p>—Emma StoneVous lisez The Long View de Richi Jennings. Vous pouvez le contacter à @RiCHi, @richij ou à [email protected].</p><p>Image : Gabriel Ramos (via Unsplash ; nivelée et recadrée)</p>"
Tests Low-Code/No-Code : priorité à l'automatisation des tests améliorée par l'IA,"<p>Alors que les entreprises s’efforcent d’accélérer la livraison de leurs applications et d’obtenir une qualité logicielle sans compromis, les approches traditionnelles d’automatisation des tests ne suffisent plus. Avec l’émergence du low-code/no-code, basé sur la méthodologie Agile et des outils optimisés par l’IA, une nouvelle ère de services d’automatisation de l’assurance qualité efficaces et efficients s’est ouverte. Les attentes du paysage numérique moderne exigent que les services d’automatisation des tests subissent une profonde transformation.</p><p>Les services d'automatisation de l'assurance qualité low-code/no-code représentent un changement de paradigme dans le monde du logiciel. Sa simplicité, son agilité et ses capacités basées sur l'IA permettent aux organisations d'adopter une approche plus efficace et efficiente des tests.</p><h3>Ce que le Low-Code/No-Code apporte au paysage de l'automatisation des tests</h3><p>● Automatisation des tests sans tracas : les plateformes low-code/no-code permettent aux testeurs d'automatiser les tests de régression et fonctionnels avec une facilité remarquable, réduisant ainsi la dépendance à des scripts et à un codage complexes. Cette simplicité accélère le processus de test, permettant des itérations plus rapides et une mise sur le marché plus rapide. ● Alignement agile et vitesse inégalée : l'automatisation des tests low-code/no-code s'intègre parfaitement à la méthodologie Agile et garantit que les tests suivent le rythme des cycles de développement rapides. Cet alignement permet aux organisations de fournir des logiciels de haute qualité dans des délais plus courts, obtenant ainsi un avantage concurrentiel significatif. ● Outils d'automatisation de l'assurance qualité améliorés par l'IA : en exploitant la puissance de l'intelligence artificielle, les outils d'automatisation des tests low-code/no-code peuvent analyser intelligemment de vastes quantités de données de test, identifier des modèles et prendre des décisions éclairées. Cela améliore la couverture des tests, améliore l'efficacité et minimise les faux positifs, ce qui se traduit par des résultats de test plus fiables et plus précis. ● Économies de coûts et utilisation optimale des ressources : en réduisant considérablement le besoin d'une expertise approfondie en matière de script et de codage, les tests d'assurance qualité low-code/no-code réduisent les coûts de maintenance et libèrent des ressources précieuses. Les organisations peuvent allouer leurs budgets de test plus efficacement, obtenant ainsi un meilleur retour sur investissement sur leurs investissements en assurance qualité. ● Qualité logicielle sans compromis : grâce à des tests complets et automatisés, l'automatisation des tests low-code/no-code garantit une qualité logicielle robuste. En minimisant le risque d'erreurs humaines et en identifiant les défauts au début du cycle de vie du développement, les organisations peuvent fournir des produits de qualité supérieure qui répondent systématiquement aux attentes des clients, voire les dépassent. Cette focalisation sur la qualité contribue à renforcer la confiance, à améliorer la réputation de la marque et à fidéliser la clientèle.</p><h3>Pourquoi vous devriez donner la priorité aux services d'automatisation des tests Low-Code/No-Code</h3><p>Les équipes DevOps qui reconnaissent le potentiel des services d’automatisation de l’assurance qualité low-code/no-code et leur capacité à stimuler l’innovation seront bien placées pour mener leur organisation vers le succès.</p><p>Voici ce que l’automatisation des tests low-code/no-code améliorée par l’IA apporte spécifiquement à DevOps :</p><p>● Agilité pour un avantage concurrentiel : la méthodologie agile combinée à l'automatisation de l'assurance qualité low-code/no-code permet aux organisations de réagir rapidement aux changements du marché, aux commentaires des clients et aux opportunités émergentes. Les équipes DevOps peuvent s'assurer qu'elles adoptent l'agilité, ce qui leur permet de surpasser leurs concurrents et de conquérir rapidement de nouveaux marchés. ● Libérer la puissance de l'IA : les plateformes de test d'assurance qualité améliorées par l'IA exploitent les capacités de l'intelligence artificielle pour piloter des tests intelligents. Les équipes DevOps peuvent exploiter la puissance de l'IA pour améliorer la couverture des tests, identifier des modèles complexes et prendre des décisions basées sur les données qui optimisent les processus de test et garantissent des logiciels de haute qualité. ● Optimisation des ressources et efficacité des coûts : en adoptant des pratiques d'automatisation des tests low-code/no-code, les équipes peuvent optimiser l'allocation des ressources et les budgets de test. La dépendance réduite à l'égard des compétences de codage spécialisées permet aux organisations d'exploiter tout le potentiel de leurs équipes de test, de réduire les coûts et d'obtenir des résultats de test plus efficaces. ● Répondre aux exigences de qualité des logiciels : sur le marché concurrentiel d'aujourd'hui, la qualité des logiciels n'est pas négociable. Les équipes DevOps doivent privilégier la méthodologie Agile et l’automatisation des tests optimisée par l’IA pour garantir que leurs organisations fournissent systématiquement des logiciels de haute qualité qui répondent ou dépassent les attentes des clients. Cet engagement envers la qualité contribue à renforcer la confiance, à améliorer la réputation de la marque et à fidéliser la clientèle.</p>"
Envisager l'automatisation sans script : développement d'applications iOS en 2023,"<p>Selon Statista, plus de 31 000 applications ont été publiées sur l’App Store d’Apple en mars 2023. Aussi impressionnant que cela puisse être, ce nombre est considérablement inférieur au nombre d’applications soumises sur l’App Store d’Apple au cours du même mois.</p><p>Et c’est probablement moins que le nombre d’applications supprimées de l’App Store.</p><p>Pourquoi?</p><p>Selon Apple, la plupart des soumissions échouent en raison de problèmes courants tels que des bugs, des plantages, des incomplétude, des données d'espace réservé et des liens rompus.</p><p>Mais obtenir l’approbation d’une application n’est qu’un des nombreux défis auxquels sont confrontés les développeurs iOS aujourd’hui.</p><h3>Attentes des utilisateurs d'applications iOS contemporaines</h3><p>En réalité, même si vous échappez aux yeux d’Apple, il y a un critique encore plus important à prendre en compte : votre public. Les utilisateurs sont beaucoup moins indulgents et ont des attentes élevées. Si votre application n’est pas parfaite, vous perdrez toute chance d’adoption significative et vos utilisateurs iront tout simplement ailleurs.</p><p>Pour les utilisateurs d'iOS, la perfection est tout simplement le statu quo, et les utilisateurs s'y attendent. En pratique, cela signifie que les applications doivent être stables sur tous les appareils et toutes les versions, bénéficier d'améliorations régulières et offrir une expérience utilisateur exceptionnelle à tout moment.</p><p>Une expérience fluide entre les appareils, les versions et les itérationsLes utilisateurs d’iOS s’attendent à la même expérience sur plusieurs appareils. D’un iPhone à l’autre, d’une version à l’autre et d’une taille d’écran à l’autre. Il incombe aux développeurs de donner la priorité à une expérience cohérente sur tous les appareils.</p><p>Cycles de publication rapides et mises à jour régulièresLes utilisateurs d'applications modernes exigent des applications riches en fonctionnalités qui vont au-delà des fonctions simples qu'ils attendent d'une application. Compte tenu des statistiques ci-dessus, il y a de fortes chances que la concurrence soit féroce. Pour réussir, il faut généralement un cycle de publication efficace et rapide avec plus de planification, plus de déploiements et plus de tests.</p><p>Une expérience utilisateur simple et fluideL’expérience utilisateur (UX) et les fonctionnalités sont l’une des principales raisons pour lesquelles l’adoption d’iOS est si forte. Les gens attendent désormais une qualité élevée de tout ce qui se trouve sous la bannière d’Apple : les utilisateurs s’attendent à une expérience utilisateur intuitive et sans problème sur chaque application avec laquelle ils interagissent. L’expérience de chaque utilisateur doit être intuitive, sans problème et cohérente avec les autres applications iOS.</p><h3>Les défis sont nombreux</h3><p>Répondre aux attentes croissantes des utilisateurs implique de nombreux défis. Par exemple :</p><p>Fragmentation du paysage des appareilsAvec autant de types d'appareils et de facteurs de forme en circulation, comment effectuer des tests sur chacun d'entre eux ? Avec des dizaines d'itérations de l'iPhone combinées à un éventail de versions, de tailles d'écran et de configurations, les développeurs d'applications ont besoin d'un moyen de tester sur suffisamment d'appareils pour couvrir la majorité de leurs bases d'utilisateurs.</p><p>Cela conduit de nombreux développeurs à se tourner vers des simulateurs et des émulateurs pour couvrir les appareils auxquels ils n’ont pas accès.</p><p>Cela pose un autre problème. Les simulateurs ne sont pas parfaits. Un simulateur ne reproduit pas les fonctions de l’appareil réel ; il ne peut imiter que certains aspects d’un appareil iOS. Et il ne peut tout simplement pas imiter efficacement le matériel, les fonctionnalités des composants ou le réseau.</p><p>À l’aide d’un simulateur, vous ne pouvez pas tester la façon dont une application réagit à des facteurs tels qu’une batterie faible, un pic de charge du réseau ou une mémoire limitée, sans parler des fonctionnalités du GPS et de l’appareil photo. Vous ne pouvez pas non plus surveiller les mesures d’utilisation ni exécuter des tests de performances significatifs.</p><p>Les appareils réels présentent leur propre défi. La plupart du temps, les développeurs devront se soucier du coût d’acquisition, de stockage, de maintenance et de mise à jour des appareils. De plus, ils devront centraliser et contrôler l’accès à ces derniers. Dans un monde du travail de plus en plus éloigné, ce n’est pas une bonne stratégie.</p><p>Aujourd’hui, la plupart des entreprises s’appuient trop sur les tests manuels. Le résultat ? L’exécution de cas de test devient le goulot d’étranglement qui retarde les versions. Bien sûr, les tests manuels sont inévitables dans certains cas, mais leur nature ponctuelle et incohérente laisse place à l’erreur. Peu importe le niveau de détail des instructions, les gens testent différemment, et c’est un désastre qui ne demande qu’à se produire dans le monde complexe des logiciels d’aujourd’hui.</p><p>Maintenance de scripts de test complexesSi vous automatisez des cas de test, vous avez déjà connu la difficulté de maintenir des scripts de test basés sur du code. Chaque version nécessite des mises à jour simultanées d'innombrables tests unitaires, tests d'intégration et tests d'interface utilisateur. Les plus petites modifications peuvent endommager les cas de test, ce qui entraîne des faux négatifs et davantage de retards de déploiement.</p><p>En plus de cela, vous devez également vous soucier de conserver les talents qui comprennent votre cadre de test spécifique à la langue. Compte tenu des incertitudes économiques actuelles, ce n’est certainement pas une bonne situation.</p><p>Mises à jour iOS constantesChaque année, Apple propose des versions majeures d'iOS ainsi qu'une variété de versions mineures, de correctifs et de corrections de bugs. Les entreprises doivent effectuer des tests après deux cycles de publication : le leur et celui d'Apple. Le non-respect de cette obligation peut entraîner des problèmes de compatibilité et de conformité avec l'App Store.</p><p>Directives de l'App StoreComme je l'ai mentionné ci-dessus, Apple applique des directives strictes pour toutes les applications publiées sur l'App Store. Des tests de qualité peuvent faire la différence entre la sortie d'une application ou l'attente de quelques semaines supplémentaires pour la prochaine approbation. Lorsque le temps c'est de l'argent, cela s'accumule rapidement.</p><p>Sécurité à grande échelleÀ mesure que les exigences évoluent, que la portée augmente et que les fonctionnalités s'accumulent, il est facile de comprendre à quel point il peut devenir de plus en plus difficile de surveiller les failles de sécurité potentielles. En retour, les tests doivent être continuellement mis à jour pour refléter les derniers risques de sécurité.</p><h3>Une évolution vers des solutions sans script</h3><p>L’automatisation sans script fait partie d’un secteur en pleine croissance d’outils d’automatisation sans code, souvent surnommé la révolution sans code. C’est tout ce qu’est l’automatisation des tests sans la dépendance aux frameworks basés sur le code.</p><p>L'automatisation des tests sans script implique l'enregistrement des interactions des utilisateurs avec les éléments de l'application, l'affirmation des résultats attendus et l'évaluation des résultats. Le test est ensuite automatisé, modélisé et étendu pour tester d'autres scénarios.</p><p>Grâce à l'automatisation des tests sans script, vous pouvez parcourir les cas de test étape par étape. Certains outils vous permettent même de tester sur des appareils en direct et de choisir parmi de vrais appareils iOS hébergés dans le cloud.</p><p>Les tests sans script vous permettent de :</p><p>● Réutilisez et modélisez facilement les scripts de test. L'automatisation sans script facilite la réutilisation des cas de test, la création de modèles et la composition de nouveaux cas de test.</p><p>● Accélérez la rentabilisation. Rédigez des cas de test plus rapidement, apportez des modifications sans savoir écrire de code et intégrez-les directement à votre outil CI/CD. Dès que vous apportez des modifications à votre application, votre équipe de test est là. Certains outils de test sans code peuvent analyser votre code source et identifier les lacunes de test afin que vous puissiez les combler immédiatement.</p><p>● Démêlez le réseau de dépendances basées sur le code. Grâce à l'automatisation des tests iOS sans script, les testeurs n'ont pas besoin de déplacer leur code à chaque fois qu'ils effectuent une modification importante. Au lieu de cela, le framework sans code fournit une interface utilisateur visuelle et facile à parcourir qui vous indique simplement ce qui est réussi, ce qui échoue et ce qui doit être mis à jour.</p><p>● Améliorez la collaboration entre les équipes. L'automatisation des tests iOS sans script améliore la collaboration entre les testeurs et les développeurs en permettant à toutes les équipes de visualiser facilement les cas de test.</p><h3>Tests sur des appareils réels</h3><p>Lorsque les problèmes de fragmentation se heurtent aux lacunes de la simulation, les développeurs ont tout intérêt à tester sur des appareils réels. En fin de compte, les tests sur des appareils réels sont le seul moyen de capturer avec précision l’expérience d’un utilisateur final.</p><p>Ce n’est pourtant un secret pour personne : gérer son propre laboratoire d’appareils est coûteux et irréaliste dans les environnements de travail à distance modernes. Une véritable configuration de cloud d’appareils résout ce problème : un cloud d’appareils héberge pour vous des appareils auxquels vous pouvez accéder depuis votre bureau, où que vous soyez.</p><p>Compte tenu des complications croissantes du paysage actuel des applications mobiles et de la concurrence acharnée qui règne dans ce secteur, il convient de garder à l’esprit que vous n’aurez peut-être qu’une seule chance de faire bonne impression auprès de votre public. La clé est de réussir les tests.</p><h3>Vers le futur</h3><p>Tout le monde attend plus. En tant qu’entreprise compétitive, vous devez faire plus avec moins : moins de ressources, moins de temps et moins de marge d’erreur. L’automatisation sans script et les tests sur des appareils réels ne garantissent pas que votre application se démarque de la concurrence, mais ils y contribueront certainement.</p>"
Google annonce la disponibilité du service iPaaS,"<p>Google a mis à disposition aujourd'hui une plateforme d'intégration en tant que service (iPaaS) capable d'invoquer une gamme de méthodes pour intégrer des applications.</p><p>Initialement développé pour la plateforme de gestion d'interface de programmation d'applications (API) Apigee acquise par Google en 2016, le service d'intégration d'applications peut désormais, par exemple, également consommer un événement de publication et d'abonnement ou un événement piloté via une plateforme Salesforce.</p><p>Amit Zavery, vice-président et directeur général de Google Platform, a déclaré que le service d'intégration d'applications offre aux organisations informatiques tous les avantages d'un iPaaS sans leur demander de créer et de gérer elles-mêmes une plateforme d'intégration.</p><p>Le service Google Application Integration donne également accès à un outil Visual Integration Designer qui peut être utilisé pour créer des workflows à l'aide d'un outil low-code. Au total, il existe désormais plus de 75 connecteurs qui peuvent être utilisés pour intégrer plusieurs services Google Cloud et des plateformes tierces qui peuvent s'exécuter dans un environnement informatique cloud ou sur site, a déclaré Zavery.</p><p>En général, les outils visuels transforment la manière dont les intégrations sont créées et développées au sein des organisations, a noté Zavery. Plutôt que d’utiliser un code procédural de niveau inférieur, un outil visuel permet aux développeurs d’employer du low-code pour créer des intégrations. Cela simplifie la collaboration avec les utilisateurs professionnels qui peuvent désormais participer plus facilement au développement des flux de travail.</p><p>En fait, dans certains cas, les utilisateurs professionnels, autrement appelés développeurs citoyens, ont suffisamment de connaissances techniques pour créer leurs propres flux de travail à l’aide d’outils low-code.</p><p>Il y aura naturellement de nombreux défis d’intégration complexes qui nécessiteront du code procédural, mais la plupart des intégrations requises aujourd’hui ne sont pas particulièrement complexes.</p><p>Quel que soit le créateur de l’intégration, le nombre de développeurs employés dans une entreprise continue d’augmenter à mesure que de nouvelles initiatives de transformation numérique sont lancées. Les développeurs ne pourront pas répondre à la demande de ces intégrations s’ils s’appuient uniquement sur le code procédural. La seule façon de réduire efficacement le retard des intégrations est de s’appuyer davantage sur des outils visuels pour les construire. Dans la plupart des cas, l’intégration créée est relativement triviale. La seule raison pour laquelle elle n’a pas été créée plus tôt est qu’il n’y a pas assez de développeurs disponibles pour effectuer cette tâche à l’aide du code procédural.</p><p>Les options iPaaS disponibles ne manquent évidemment pas. À mesure que de plus en plus de charges de travail sont déployées dans le cloud, Google parie que le centre de gravité de l’intégration se déplacera vers les endroits où les charges de travail modernes basées sur des microservices sont déployées afin de réduire la latence globale.</p><p>Il n’est pas certain que les entreprises considèrent encore l’intégration comme une réflexion de dernière minute ou qu’elles utilisent une plateforme d’intégration autour de laquelle toutes les applications s’articulent. Cette dernière approche tend à réduire le coût total de l’intégration par rapport à l’utilisation de plusieurs produits ponctuels qui ne sont pas gérés via un cadre unique, a noté Zavery.</p><p>En fin de compte, les équipes informatiques qui adoptent une iPaaS peuvent se concentrer davantage sur des tâches informatiques à plus forte valeur ajoutée. La question est de déterminer quels projets d’intégration nécessitent réellement des développeurs professionnels dotés d’une grande expertise en matière d’intégration et lesquels, via un outil low-code, peuvent être gérés par presque n’importe quel développeur.</p>"
Tricentis acquiert Waldo pour faire progresser les tests mobiles,"<p>Tricentis a acquis Waldo dans le cadre d'un effort visant à étendre la portée des capacités de tests automatisés qu'elle fournit pour les applications mobiles.</p><p>Waldo ajoute une plateforme SaaS (Software-as-a-Service) qui fournit aux équipes informatiques un outil sans code pour générer des tests d'applications mobiles. Waldo utilise un environnement virtuel pour simuler les appareils iOS et Android de manière à éliminer le besoin d'appareils physiques pour effectuer les tests. Au lieu de cela, les équipes DevOps enregistrent leurs applications, puis utilisent les outils sans code pour générer des tests directement à partir d'un navigateur.</p><p>Mav Turner, CTO de Tricentis, a déclaré que Tricentis avait choisi d'acquérir Waldo car cela permet aux équipes informatiques de générer plus facilement des tests pouvant être intégrés dans un flux de travail DevOps.</p><p>Il existe actuellement un débat intense sur la mesure dans laquelle les tests d’applications doivent être confiés aux développeurs. En théorie, plus les développeurs testent les applications eux-mêmes, moins il devrait y avoir de problèmes une fois qu’une application est déployée dans un environnement de production. Cependant, il faudra toujours des équipes de test dédiées pour effectuer des tests à plusieurs étapes du processus de développement d’applications afin de garantir la qualité, a noté M. Turner.</p><p>La différence est que la plupart de ces tests peuvent inclure des cas d'utilisation de pointe pour lesquels il n'y aurait pas eu suffisamment de temps auparavant, a-t-il ajouté.</p><p>Plus tôt cette année, Tricentis a ajouté la possibilité de tester des applications natives iOS et Android à sa plateforme de logiciel en tant que service (SaaS) Testim dans le cadre d'un effort visant à étendre la portée de cette plateforme aux applications qui s'exécutent nativement sur un appareil mobile.</p><p>Les tests d’applications mobiles sont plus importants que jamais, car le coût d’un échec, en termes d’impact sur l’entreprise, est désormais beaucoup plus élevé, car de plus en plus d’entreprises dépendent des logiciels pour piloter leurs processus métier. Le problème est que bon nombre de ces développeurs d’applications n’ont pas l’esprit d’ingénierie logicielle. Ils ont donc besoin de plateformes de test qui créent et exécutent automatiquement des tests pour leur compte, d’une manière qui peut être personnalisée pour des cas d’utilisation spécifiques.</p><p>Au fil du temps, la qualité des applications devrait s'améliorer de manière constante, car de nombreuses erreurs de bas niveau commises par les développeurs seront éliminées. Cela devrait améliorer tous les aspects, de la sécurité des applications à l'expérience utilisateur, car les applications sont continuellement mises à jour.</p><p>De plus, les organisations qui intègrent des tests dans les workflows DevOps réduisent progressivement le nombre de problèmes à résoudre avant le déploiement des applications.</p><p>Avec l’application croissante de l’intelligence artificielle (IA) aux processus de test, le nombre de raisons pour lesquelles les tests ne sont pas exécutés aussi fréquemment qu’ils le devraient devrait diminuer progressivement. Aujourd’hui, il est encore trop difficile pour de nombreux développeurs de créer des tests, et ils n’en effectuent donc pas autant qu’ils le devraient. Bien entendu, beaucoup d’entre eux manquent tout simplement de temps lorsque l’écriture du code qui pilote l’application prend plus de temps que prévu.</p><p>D’une manière ou d’une autre, les développeurs manqueront d’excuses pour ne pas exécuter de tests à mesure que la responsabilité de la qualité du code augmentera.</p>"
Mendix adopte DevOps pour la prochaine ère du développement d'applications low-code,"<p>Mendix, une filiale de Siemens, a mis à jour aujourd'hui sa plateforme de développement d'applications low-code du même nom pour ajouter la prise en charge des flux de travail DevOps et permettre aux développeurs de composer plus facilement des applications et d'intégrer des capacités d'intelligence artificielle (IA).</p><p>Sheryl Koenigsberg, vice-présidente du marketing produit chez Mendix, a déclaré que Mendix 10 permet d'utiliser les référentiels Git pour le contrôle des versions avec Mendix Pipelines, actuellement en version bêta. Mendix Pipelines est un environnement d'intégration continue/livraison continue (CI/CD) qui sera intégré à la plateforme low-code. De plus, Mendix ajoute la prise en charge des Webhooks qui peuvent être utilisés pour intégrer Mendix aux plateformes CI/CD existantes.</p><p>Mendix a également ajouté un kit de solutions, désormais disponible au grand public, pour permettre de personnaliser les applications de manière à garantir que ces modifications seront préservées lors de la mise à niveau des environnements d'application.</p><p>Il existe désormais également un outil Portfolio Manager pour suivre les projets et un connecteur pour l'intégration avec le logiciel de gestion de projet Jira d'Atlassian.</p><p>Plus tard cette année, Mendix mettra également à disposition du public Adaptation Insights pour fournir des informations sur les extensions d’application.</p><p>À l’avenir, les développeurs pourront exploiter un cadre d’extensibilité pour personnaliser l’environnement de développement intégré (IDE) Mendix Studio Pro en ajoutant leurs propres plugins, assistants, éditeurs et intégrations tierces. Plus tard cette année, Mendix 10 ajoutera également, en version bêta, une version de son IDE Studio Pro pour MacOS.</p><p>L’approche de Mendix en matière de composabilité est également étendue pour intégrer l’IA. L’entreprise ajoute Mendix Assist, un bot qui génère une logique de validation pour la saisie de données. Ce module est la deuxième capacité d’IA développée par Mendix après avoir précédemment présenté Mendix Chat, un outil basé sur un grand modèle de langage créé à l’aide de données Mendix qui sera intégré dans l’environnement de développement intégré (IDE) Mendix plus tard cette année. Mendix Assist sera intégré à Mendix Chat.</p><p>Mendix développe également des LLM supplémentaires pour la création d'applications et, dans le cadre de son engagement en matière de composabilité, prévoit de permettre l'intégration de services d'IA et de LLM tiers dans Mendix Runtime pour créer des « applications intelligentes ». Les modèles d'IA seront convertis au format Open Neural Network Exchange (ONNX), une norme ouverte pour les modèles d'apprentissage automatique, afin de fournir cette capacité.</p><p>De plus, Mendix ajoute la prise en charge des architectures pilotées par événements via des événements commerciaux et un courtier d'événements, pour créer des applications plus complexes.</p><p>D'autres fonctionnalités ajoutées à Mendix 10 incluent des connecteurs REST et de base de données mis à jour, la prise en charge des filtres de données visuels, des propriétés riches et des contrôles de conception, un outil Démarrer à partir d'une feuille de calcul, des outils d'enquête auprès des utilisateurs finaux, un générateur de documents PDF et un ensemble remanié d'outils de gouvernance et d'évaluation des risques.</p><p>Enfin, Mendix ajoute un module Terraform pour simplifier le déploiement de sa plateforme low-code sur Amazon Elastic Kubernetes Service (Amazon EKS) en plus de fournir une implémentation de référence pour la création de clouds privés pour développer des applications à l'aide du service Mendix Cloud.</p><p>Les applications low-code basées sur l’IA étant développées plus rapidement, il est difficile de savoir dans quelle mesure les entreprises sont prêtes à accepter les inévitables bouleversements qui en découleront. Cependant, une chose est sûre : les workflows DevOps utilisés pour déployer ces applications à grande échelle seront bientôt mis à rude épreuve.</p>"
Comment éviter les risques lors de l'utilisation de plusieurs plateformes Low-Code,"<p>Les entreprises continuent de recourir de plus en plus au low-code/no-code (LCNC). Mais cette adoption ne se résume pas toujours à un seul outil : il arrive souvent que plusieurs plateformes low-code/no-code soient utilisées sous le même toit. En fait, Gartner prévoit que d’ici 2024, 75 % des grandes entreprises utiliseront au moins quatre outils de développement low-code pour le développement d’applications informatiques et les initiatives de développement citoyen.</p><p>L’utilisation simultanée de plusieurs plateformes low-code/no-code pose certains problèmes de sécurité. Cela est dû en partie à l’absence de politiques standard pour régir les différentes plateformes de la même manière. Les plateformes low-code sont souvent incompatibles avec les processus de sécurité informatique traditionnels, comme l’analyse des vulnérabilités, les révisions manuelles du code et la surveillance de la sécurité d’exécution. Les organisations qui se lancent à fond dans le développement citoyen ont besoin de moyens sûrs pour utiliser les plateformes low-code/no-code. Alors, comment peuvent-elles permettre cette innovation en toute sécurité sans entraver la productivité ?</p><p>J’ai récemment rencontré Michael Bargury, CTO et cofondateur de Zenity, pour parler de la sécurisation des systèmes LCNC. Bargury, qui supervise la liste des dix meilleurs logiciels low-code de l’OWASP, a une connaissance approfondie des avantages et des inconvénients des plateformes low-code/no-code. Ci-dessous, nous examinerons les risques potentiels liés à l’utilisation de plusieurs plateformes low-code et envisagerons des moyens d’atténuer ces préoccupations.</p><h3>Pourquoi les entreprises ont-elles plusieurs plateformes Low-Code</h3><p>L’intérêt pour le low-code ne cesse de croître et l’adoption du low-code/no-code continue de s’accélérer dans les entreprises. Selon Bargury, les grandes entreprises n’ont souvent pas le choix en la matière : les outils low-code apparaissent de manière organique et il est difficile de contenir leur prolifération.</p><p>L’une des façons de procéder est que le low-code s’intègre aux plateformes SaaS que tout le monde utilise déjà. Les plateformes logicielles faisant partie intégrante des opérations commerciales, comme Salesforce, Microsoft Office et ServiceNow, ont sans doute muté en plateformes low-code, les faisant ressembler davantage à des fournisseurs de cloud qu’à des fournisseurs de SaaS, a déclaré Bargury.</p><p>Selon Bargury, les plateformes low-code émergent également par le biais de transitions ascendantes. Il peut s’agir d’un travailleur du savoir spécifique travaillant dans un sous-ensemble de l’entreprise pour automatiser une opération spécifique à un domaine ou intégrer divers outils. Il existe ensuite des plateformes telles que OutSystems, Mendix ou Mulesoft qui ciblent spécifiquement les développeurs professionnels.</p><p>Les organisations qui misent sur le développement citoyen peuvent créer un centre d’excellence et concentrer leurs efforts sur une seule plateforme. Et les plateformes low-code ciblant les développeurs encourageront parfois une plus grande consolidation. Pourtant, « différentes plateformes résolvent mieux différents cas d’utilisation », explique Bargury. Par conséquent, vous en aurez généralement quelques-unes convergentes dans les mêmes entreprises.</p><h3>Problèmes de sécurité potentiels liés à de multiples plateformes Low-Code</h3><p>L’émergence du low-code est similaire au mouvement BYOD (Bring Your Own Device). Les responsables informatiques et de la sécurité se sont battus pour l’éviter à un moment donné, mais aujourd’hui, tout le monde le fait. Alors, quelles sont les implications en matière de sécurité si le low-code devient omniprésent de la même manière ? Eh bien, quelle que soit la manière dont il est généré, les programmes issus du low-code sont toujours des applications susceptibles de rencontrer les mêmes problèmes logiques. Et malheureusement, comparé au cycle de vie de développement de code traditionnel typique, le développement low-code est entaché de divergences, explique Bargury.</p><h4>Pipelines CI/CD immatures</h4><p>Certaines plateformes n’offrent pas le type de processus CI/CD mature que l’on attend d’une plateforme de développement logiciel. Par exemple, il se peut qu’il n’y ait aucun moyen de créer des tests ou de séparer vos environnements. Comme il n’existe aucun moyen cohérent et uniforme de transférer le code du développement vers la production, vous n’avez pas de moyen d’appliquer un développement sécurisé sur toutes les plateformes. « Vous n’avez aucun moyen de garantir que chaque élément de logiciel est conforme à vos normes », a déclaré Bargury.</p><h4>Bases de code sous-jacentes opaques</h4><p>Dans le développement de logiciels traditionnels, vous effectuez vos propres contrôles de sécurité pour vous assurer que les applications ne contiennent pas de risques. Cela comprend l’analyse par décalage vers la gauche, les portes de sécurité, les contrôles manuels pour détecter les erreurs au plus tôt et l’analyse à l’exécution pour détecter les vulnérabilités inconnues en production. Mais il n’y a pas toujours de parallèles dans le développement low-code. Les solutions low-code ont généralement leur propre façon de faire les choses avec moins de normes, et elles évitent d’exposer le code sous-jacent et Git, a déclaré Bargury.</p><h4>Manque de visibilité</h4><p>Ainsi, avec l’obfuscation low-code, vous perdez un certain degré de visibilité sur le fonctionnement d’une application. Les journaux peuvent être insuffisants ou totalement inaccessibles. Il est également difficile, voire parfois impossible, de mettre en place une surveillance de l’exécution, sans parler de l’analyse de différentes plateformes. Cela signifie que les utilisateurs low-code ne peuvent pas exploiter de puissants outils d’observabilité pour identifier les erreurs et remédier aux failles de sécurité.</p><h4>Manque de politiques unifiées</h4><p>Enfin, établir des autorisations et des permissions communes sur plusieurs plateformes de développement low-code constitue un autre obstacle. Étant donné que les fournisseurs low-code ont leurs propres blocs de construction, vous ne pouvez pas exploiter des outils comme OPA ou Kyverno pour créer et unifier des politiques. L’absence de politiques partagées entre les outils rend difficile la vérification de la mise en œuvre des meilleures pratiques, explique Bargury.</p><h3>Comment sécuriser plusieurs LCNC</h3><p>Le low-code peut offrir un potentiel créatif considérable. Mais, connaissant les risques mentionnés ci-dessus, que devrait faire le service informatique pour réduire les risques liés au low-code, en particulier lors de l’utilisation de plusieurs plateformes ? Eh bien, Bargury a partagé plusieurs étapes pour aider les responsables de la cybersécurité à commencer à aborder en toute sécurité l’émergence de capacités de plus en plus low-code.</p><ol>Placez le développement low-code sous l’égide de la sécurité des applications. Tout d’abord, le low-code doit être placé sous l’égide de la sécurité, si ce n’est pas déjà le cas. « Cela devrait faire partie de leur mandat », a déclaré Bargury. Transférez la responsabilité à des professionnels bien formés à la résolution des menaces. Comprenez votre surface d’exposition. En tant que locataire de sécurité de base, vous ne pouvez pas sécuriser ce que vous ne connaissez pas. Ainsi, Bargury recommande d’augmenter votre visibilité sur chaque plateforme low-code en collectant des journaux lorsque cela est possible et en centralisant votre analyse. Créez des garde-fous automatisés. Ensuite, il est essentiel d’identifier vos risques et de définir des garde-fous pour vos utilisateurs low-code, en particulier lorsque le développement citoyen est impliqué. Le cadre OWASP fournit un bon aperçu des risques courants et des conseils d’atténuation dans l’automatisation des processus robotisés (RPA), l’intégration et le low-code. En général, il est important de concevoir des autorisations en gardant à l’esprit la règle du moindre privilège. Cela peut contribuer à réduire les risques de vulnérabilités telles que LCNC-SEC-03 : Fuite de données et conséquences inattendues et LCNC-SEC-01 : Usurpation d’identité de compte. Comblez les lacunes du cycle de vie du développement (SDLC). Enfin, les plateformes low-code fournissent souvent les éléments de base pour sécuriser les applications, mais il vous appartient toujours de vous assurer qu’elles sont utilisées en toute sécurité. Les équipes de cybersécurité doivent continuellement auditer le SDLC low-code pour s’assurer que les failles ne persistent pas.</ol><li>Placez le développement low-code sous l’égide de la sécurité des applications. Tout d’abord, le low-code doit être placé sous l’égide de la sécurité, si ce n’est pas déjà le cas. « Cela devrait faire partie de leur mandat », a déclaré Bargury. Transférez la responsabilité à des professionnels bien formés à la résolution des menaces.</li><li>Comprenez votre surface d’exposition. En tant que locataire de sécurité de base, vous ne pouvez pas sécuriser ce que vous ne connaissez pas. Ainsi, Bargury recommande d’augmenter votre visibilité sur chaque plateforme low-code en collectant des journaux lorsque cela est possible et en centralisant votre analyse.</li><li>Créez des garde-fous automatisés. Ensuite, il est essentiel d’identifier vos risques et de définir des garde-fous pour vos utilisateurs low-code, en particulier lorsque le développement citoyen est impliqué. Le cadre OWASP fournit un bon aperçu des risques courants et des conseils d’atténuation dans le domaine de l’automatisation des processus robotisés (RPA), de l’intégration et du low-code. En général, il est important de concevoir des autorisations en gardant à l’esprit la règle du moindre privilège. Cela peut aider à réduire le risque de vulnérabilités telles que LCNC-SEC-03 : Fuite de données et conséquences inattendues et LCNC-SEC-01 : Usurpation d’identité de compte.</li><li>Comblez les lacunes du cycle de vie du développement (SDLC). Enfin, les plateformes low-code fournissent souvent les éléments de base pour sécuriser les applications, mais il vous appartient toujours de vous assurer qu'elles sont utilisées en toute sécurité. Les équipes de cybersécurité doivent continuellement auditer le SDLC low-code pour s'assurer que les failles ne persistent pas.</li><h3>Vous êtes responsable de la sécurisation du développement Low-Code</h3><p>Les plateformes de développement low-code ne sont pas à 100 % à l’abri des dangers. Il n’est pas exclu que des pirates informatiques abusent de ces plateformes et les retournent contre leurs propriétaires. Par exemple, l’équipe de détection et de réponse de Microsoft (DART) a signalé comment un groupe de pirates informatiques a utilisé l’accès à un outil low-code pour rester caché au sein d’une organisation pendant six mois, en utilisant le « credential stuffing » pour accéder à un compte administratif. En créant des automatisations, ils ont pu utiliser des outils de découverte internes et exfiltrer des secrets et des données qui auraient pu être utilisés pour une élévation des privilèges.</p><p>Comme vous pouvez le constater, les préoccupations concernant le low-code sont légitimes, en particulier à grande échelle. Cependant, la responsabilité en matière de sécurité n’est pas toujours aussi transparente. À ce jour, il n’existe pas d’équivalent d’un modèle de responsabilité cloud partagé dans le domaine du développement low-code. En fin de compte, c’est vous qui devez prendre les rênes des applications que vous créez et vous assurer que tout est sécurisé.</p>"
"92 % des développeurs utilisent l'IA, selon une enquête ¦ Intel One Mono Font","<p>Bienvenue dans The Long View, où nous passons en revue l'actualité de la semaine et en tirons l'essentiel. Déterminons ce qui compte vraiment.</p><p>Cette semaine : GitHub vante des statistiques incroyables sur l’IA et la magnifique police open source d’Intel.</p><p>Première information de la semaine : une enquête de GitHub suggère que la grande majorité des développeurs utilisent l'IA pour écrire leur code. Est-ce vrai ?</p><h3>Analyse : Non, ce n’est pas possible</h3><p>92 % des développeurs utilisent l’IA pour les aider à coder ? Si vous croyez cela, il y a un pont dont j’aimerais parler.</p><p>Thomas Claburn semble légèrement méfiant : GitHub constate que 92 % des développeurs aiment l'IA</p><p>« Les outils d’IA amélioreront le code »GitHub, qui fait de bonnes affaires en vendant des abonnements à son assistant d’IA Copilot, en proie à des litiges, a interrogé 500 développeurs basés aux États-Unis pour savoir si certains d’entre eux utilisent déjà des outils de codage d’IA au travail. … Ils le font, et en grande partie. … Parmi les principales conclusions du rapport… figure le fait que les développeurs se sont déjà engagés à aider l’IA, manifestement sans se soucier des défis juridiques qui pourraient limiter ces outils pour des raisons de droit d’auteur. … 81 % voient également l’IA comme une voie vers une plus grande collaboration au sein des équipes et des organisations. … Le rapport indique que les développeurs pensent que les outils d’IA amélioreront le code qu’ils créent. … Les personnes interrogées peuvent ne pas avoir connaissance d’études universitaires prouvant le contraire.</p><p>Steven Vaughan-Nichols est précis : l’IA n’est pas l’avenir de la programmation, c’est son présent</p><p>« Devenir un vrai problème » Plus précisément, les développeurs ont déclaré que les outils de codage IA peuvent les aider à respecter les normes de performance existantes avec une qualité de code améliorée, des sorties plus rapides et moins d’incidents au niveau de la production. … En d’autres termes, aujourd’hui, les outils de programmation IA font partie intégrante de l’informatique d’entreprise moderne. … Les développeurs pensent que … la qualité du code plutôt que la quantité de code doit rester une mesure de performance de premier plan. Le problème est que les outils de codage IA obligeront les responsables à se concentrer encore plus sur le simple fait de sortir plus de code plutôt que de fournir un bon code. … Cela devient un vrai problème. Oui, vous pouvez demander à ChatGPT d’écrire un programme pour vous, mais si vous ne comprenez pas ce que vous faites en premier lieu… le code sera toujours nul.</p><p>Vous pouvez tout prouver avec des statistiques. Comptez sur silent_count :</p><p>GitHub constate que 92 % des développeurs aiment les outils d’IA. Et ces outils sont donc moins populaires que Saddam Hussein, élu avec 99 % des voix. Dans les deux cas, je me pose des questions sur la méthodologie.</p><p>Que diriez-vous d'une métaphore du monde réel ? Embrassez la super grosse grenouille :</p><p>« 92 % des clients de McDonald’s ont mangé des frites McDonald’s, selon une enquête réalisée par McDonald’s auprès de ses clients. » … Le résultat semble attendu et donc biaisé, compte tenu de la source.</p><p>Et savourez un Bigburito :</p><p>Nouveau titre : « L’eau est mouillée ». Une grande partie de l’enseignement de la programmation se concentre sur l’automatisation des tâches et la réduction des efforts nécessaires à leur exécution en concevant du code de manière à ce qu’il soit facilement réutilisé. C’est notre métier, et l’IA y joue donc bien sûr un rôle.</p><p>Pour nous rappeler d’où vient le matériel source des modèles, voici silvergig :</p><p>En d’autres termes, 92 % des programmeurs utilisent Stack Overflow pour obtenir des extraits de code qui ne valent pas la peine d’être mémorisés. … ChatGPT ne fait pas tout le travail. Comment savent-ils qu’il s’agit d’une « meilleure qualité, de résultats plus rapides et de moins d’incidents au niveau de la production » ? Ils ne le savent pas, à moins qu’ils ne sachent déjà comment écrire du code.</p><p>A l'inverse, thaway_thaway34 semble effrayé :</p><p>Je suis ingénieur depuis 20 ans, travaillant principalement sur le développement web. J'ai un salaire assez élevé. … L'IA me fait peur pour la sécurité de l'emploi. … Le loyer est très élevé. Je ne me sens pas à l'aise de contracter un prêt hypothécaire malgré les multiples dépôts nécessaires, car je ne sais pas combien de temps je pourrai encore maintenir ma rémunération avec l'IA qui automatise tout. … J'utilise ChatGPT au quotidien pour créer des projets, et plus je l'utilise, plus j'ai peur. C'est tout simplement trop puissant. Plus je l'utilise, moins je suis fier de mon rendement. J'ai juste l'impression que n'importe qui pourrait le faire.</p><p>Intel travaille sur une police de caractères open source destinée aux développeurs. Elle est plutôt belle et s'adresse à un public cible important.</p><h3>Analyse : Très visible pour les personnes malvoyantes</h3><p>Son objectif est de servir « le public de développeurs malvoyants mal desservi en termes de typographie ». Et ce faisant, il pourrait également améliorer le DevX et la productivité de tous les autres.</p><p>Joey Sneddon : La nouvelle police Open Source Mono d’Intel est plutôt correcte</p><p>« Aide à réduire la fatigue oculaire »Entre IBM Plex Mono, Hack, Fira Code et JetBrains Mono Je pense que nous, les utilisateurs de Linux, avons l’embarras du choix en matière de polices monospace open source qui sont belles et fonctionnent parfaitement. Mais il y a toujours de la place pour plus, n’est-ce pas ? Intel le pense, d’où la sortie d’Intel One Mono. Il s’agit d’une « famille de polices monospace expressives qui a été conçue dans un souci de clarté, de lisibilité et de besoins des développeurs ». Mieux encore, elle est… gratuite à télécharger… modifier et… redistribuer. [Un] groupe important de personnes a contribué à la genèse de ce glyphe : les développeurs malvoyants et légalement aveugles. Oui, Intel One Mono n’est pas seulement une police « oh, c’est joli ». Intel affirme qu’elle facilite la lecture et la saisie de code, aide à réduire la fatigue oculaire et peut éventuellement diminuer la fatigue.</p><p>Mais « ça n’a pas l’air génial », estime AmiMoJo :</p><p>Je ne suis pas un expert mais je pense que les lignes ne sont pas assez hautes. Elles semblent compressées et cela rend les contours des caractères et des mots moins clairs. Je pense que certains caractères sont également un peu larges. Les caractères fins comme i et l sont meilleurs s'ils sont étroits, même avec un espacement fixe, cela aide à les différencier. C'est moins agréable visuellement, mais pour le codage, je veux de la lisibilité.</p><p>Quoi qu'il en soit, avons-nous vraiment besoin d'une autre police monospace redimensionnable ? Oui, dit Stormcrow :</p><p>C'est comme si quelqu'un n'avait jamais eu à dire aux programmeurs que leur interface utilisateur était nulle parce qu'elle ne prenait pas en compte les utilisateurs malvoyants qui pourraient avoir besoin d'augmenter la taille des polices, des icônes, des boutons ou des indicateurs visuels. Il y a un très grand nombre d'utilisateurs qui souffrent au moins d'une légère déficience visuelle, que ce soit en raison de l'âge, d'une maladie, d'un accident ou d'une malformation congénitale. Nous voulons tous des éléments visuels qui peuvent être redimensionnés pour une visualisation confortable.</p><p>—Mahatma GandhiVous lisez The Long View de Richi Jennings. Vous pouvez le contacter à @RiCHi ou à [email protected].</p><p>Image : Fabrizio Coco (via Unsplash ; nivelée et recadrée)</p>"
Révolutionner DevOps avec des plateformes Low-Code/No-Code,"<p>L’industrie DevOps connaît une croissance incroyable, avec une valeur dépassant les 8 milliards de dollars en 2022. Les analystes prévoient que le marché sera multiplié par cinq et atteindra près de 40 milliards de dollars d’ici la fin de la décennie. Mais avec cette croissance, un problème important au sein de la chaîne DevOps continue de s’aggraver : un déficit de talents croissant. Le ministère américain du Travail a prédit que d’ici 2030, le déficit mondial d’ingénieurs de développement dépassera 85 millions. En outre, la demande de professionnels DevOps devrait augmenter de plus de 20 % par an pendant le reste de la décennie. Ces tendances contradictoires représentent des défis importants pour les entreprises de logiciels et d’applications. Bien qu’il existe une opportunité substantielle de générer des revenus en créant de nouvelles et meilleures applications, la pénurie de personnel qualifié pour développer ces produits constitue un obstacle important. L’intégration d’outils low-code et no-code dans le processus DevOps pourrait être une solution viable pour combler le déficit de talents. Ces outils offrent divers avantages et gains d’efficacité, notamment la rationalisation du travail des professionnels DevOps existants et la possibilité pour les organisations d’élargir leurs équipes au-delà des sources de personnel traditionnelles. L’exploitation de ces outils pourrait donner aux entreprises du secteur DevOps un avantage concurrentiel.</p><h3>Les défis du DevOps traditionnel</h3><p>Les pratiques DevOps traditionnelles posent des défis importants aux entreprises, qui entravent leur productivité et leur réussite globale. Le premier problème majeur est la pénurie de talents. Selon un rapport du Manpower Group, 75 % des employeurs considèrent que la recherche de talents technologiques est leur principale préoccupation. Alors que la demande de professionnels expérimentés en DevOps continue de croître, il devient de plus en plus difficile pour les entreprises de trouver le personnel adéquat.</p><p>Un autre défi majeur des pratiques DevOps traditionnelles est la courbe d’apprentissage élevée. La prévision de Gartner selon laquelle 75 % des initiatives DevOps ne parviendront pas à répondre aux attentes d’ici 2023 met en évidence la gravité de la courbe d’apprentissage et les défis associés à l’adoption des pratiques DevOps sans formation et expérience adéquates.</p><p>Pour éviter les retards, les coûts accrus et la sous-productivité, les entreprises doivent explorer des solutions innovantes telles que les plateformes low-code et no-code. Cela permettrait aux développeurs citoyens de contribuer au processus de développement et de rationaliser les processus de gestion de l'infrastructure, ce qui permettrait une plus grande efficacité et une plus grande évolutivité dans leurs pratiques DevOps.</p><h3>Comment le Low-Code/No-Code révolutionne DevOps</h3><p>Les plateformes low-code/no-code sont de plus en plus reconnues pour leur potentiel à stimuler le développement d'applications dans les entreprises. Gartner prévoit en effet que d'ici 2024, 80 % des applications seront développées par des professionnels non informatiques. L'adoption de ces outils de productivité peut apporter des avantages significatifs au paysage DevOps, notamment de la manière suivante.</p><p>Réduire la charge de travail et le stressEn utilisant des logiciels low-code et no-code, les entreprises peuvent répartir les tâches de base de création d'applications et de développement à travers l'organisation, libérant ainsi du temps aux développeurs qualifiés et réduisant leur charge de travail et leur stress. Cela améliore considérablement l'expérience sur le lieu de travail et permet aux développeurs de consacrer leur temps à la fourniture de solutions plus complexes et de meilleure qualité.</p><p>Accélérer l'innovation avec des plateformes low-code/no-codeLes plateformes low-code/no-code peuvent accélérer l'innovation en permettant aux développeurs de réaliser rapidement des preuves de concept pour des tâches de développement logiciel plus complexes qui nécessitent une expertise en codage. Les idées et les solutions peuvent être testées avant d'investir du temps et des ressources dans un développement à grande échelle.</p><p>Créer de nouveaux rôles et opportunitésLes plateformes sans code peuvent créer de nouveaux rôles et opportunités au sein de l’entreprise, comme des projets sans code axés sur l’optimisation des processus et la création de solutions. Les développeurs citoyens sans expérience de codage peuvent poursuivre de nouveaux parcours professionnels et saisir de nouvelles opportunités pour contribuer au succès de leur entreprise. Un exemple est l’application de la technologie sans code pour numériser des formulaires papier dans toutes les organisations. Les employés sans expérience de codage peuvent créer des applications mobiles qui accélèrent la collecte de données, améliorent la précision des données et permettent le partage et l’analyse instantanés des données numériques.</p><p>Donner aux développeurs un rôle plus stratégiqueLe développement tactique des logiciels étant réalisé au sein des unités commerciales, les développeurs peuvent consacrer davantage de temps à des technologies de pointe comme la réalité mixte, l'informatique quantique et l'IA. Cela peut leur donner un rôle plus stratégique dans l'entreprise et leur permettre de se concentrer sur la « prochaine grande nouveauté ».</p><h3>Considérations et défis</h3><p>Bien que les plateformes low-code/no-code aient le potentiel d’offrir de nombreux avantages aux équipes DevOps, il est important d’être conscient des défis qui se posent lors de l’association réussie des deux et de la manière de les éviter.</p><p>Applications mal conçues ou non sécuriséesLes applications développées par des non-professionnels de l’informatique présentent un risque plus élevé d’introduire des vulnérabilités susceptibles de compromettre la sécurité de l’application et de l’organisation. De plus, le manque de supervision et de gouvernance peut conduire à de mauvaises pratiques de codage et à une dette technique. Par exemple, l’utilisation de plateformes iPaaS de nouvelle génération par des intégrateurs citoyens a rendu difficile pour les responsables de la sécurité d’avoir une visibilité complète sur les actifs précieux de l’organisation. Les attaquants en sont conscients et ont déjà profité de connexions d’application à application mal sécurisées lors de récentes attaques de la chaîne d’approvisionnement, telles que celles subies par Microsoft et GitHub.</p><p>Les entreprises doivent s’assurer que le personnel informatique vérifie soigneusement comment les technologies low-code et no-code sont adoptées et comment les applications sont examinées afin de réduire les vulnérabilités.</p><p>Personnalisation et évolutivité limitéesBien que les plateformes low-code/no-code puissent accélérer jusqu’à dix fois le développement d’applications, leurs limites peuvent créer des obstacles lors de la création d’applications volumineuses et complexes. Ces plateformes peuvent être utiles pour le développement d’applications de base, mais elles peuvent ne pas être adaptées aux applications complexes ou hautement personnalisées. Par exemple, si votre application nécessite une capacité hors ligne robuste qui gère la résolution des conflits et le stockage hors ligne sur l’appareil, il est préférable de sélectionner une plateforme low-code comme Alpha Anywhere plutôt qu’un générateur d’applications par glisser-déposer comme Appypie, qui convient aux applications moins complexes.</p><p>Intégrations complexes avec les systèmes existantsLes organisations qui tentent d’intégrer des applications low-code et no-code à des systèmes existants ou à d’autres applications tierces peuvent être confrontées à des défis techniques. Par exemple, si une organisation souhaite intégrer une application low-code à un système ERP existant, elle peut être confrontée à des défis en termes de mappage et de synchronisation des données. Certaines applications low-code et no-code sont conçues pour exporter des données et les partager correctement, mais lorsqu’il s’agit d’intégrer des déclencheurs d’événements, une logique métier ou des flux de travail, ces solutions logicielles atteignent leurs limites. Les acheteurs doivent examiner attentivement leurs exigences avant de procéder à un achat.</p><p>Pour relever les défis potentiels des plateformes low-code/no-code, les organisations doivent établir des politiques et des procédures de gouvernance pour garantir le respect des normes de sécurité et de qualité. Cela comprend la mise en œuvre de contrôles d’accès appropriés avec une sécurité zero-trust, des mesures de confidentialité des données et des processus de gestion des vulnérabilités. Les organisations doivent travailler avec leurs fournisseurs de plateformes low-code/no-code pour garantir une intégration transparente avec d’autres systèmes et une évolutivité pour répondre aux besoins en constante évolution. Parallèlement à cela, des évaluations et des audits réguliers des applications développées à l’aide de plateformes low-code/no-code peuvent également aider à identifier et à traiter les risques de sécurité avant qu’ils ne se transforment en problèmes importants.</p><h3>Conclusion</h3><p>L’intégration de plateformes low-code/no-code dans les pratiques DevOps représente une solution prometteuse pour répondre aux défis actuels du secteur. En exploitant ces plateformes, les organisations peuvent élargir leurs équipes au-delà des sources de personnel traditionnelles et créer un environnement plus inclusif pour que les professionnels non informatiques contribuent au processus de développement. L’essor du no-code est une situation gagnant-gagnant pour tout le monde, et lorsque les premiers utilisateurs saisiront cette opportunité, ils pourront obtenir un avantage concurrentiel significatif sur le marché. L’avenir de DevOps est passionnant, et le potentiel du développement low-code/no-code est illimité, libérant le potentiel d’innovation de tous les employés et leur permettant de faire la différence dans leurs organisations.</p>"
Maîtriser l'automatisation DevOps pour la distribution de logiciels modernes,"<p>Les services d’automatisation DevOps sont un aspect crucial du développement logiciel moderne qui aide les organisations à améliorer leurs processus de livraison de logiciels et à suivre le rythme de l’innovation. Grâce à l’automatisation DevOps, les développeurs peuvent automatiser les tâches répétitives et chronophages, ce qui leur permet de se concentrer sur l’écriture de code et la livraison de fonctionnalités plus rapidement et avec une meilleure qualité. En automatisant des processus tels que l’intégration continue, la livraison continue et l’infrastructure en tant que code, les organisations peuvent réduire les coûts, améliorer la collaboration entre les équipes et répondre rapidement à l’évolution des besoins commerciaux et des exigences des clients.</p><p>Dans cet article, nous aborderons les bases de la mise en route des services d’automatisation DevOps, y compris les outils populaires et les meilleures pratiques que les organisations peuvent utiliser pour mettre en œuvre une stratégie d’automatisation réussie.</p><h3>Agilité et efficacité pour une digitalisation intelligente</h3><p>Les technologies émergentes telles que le multicloud, l’IaC, l’IA/ML et l’IoT n’ont fait qu’accroître l’importance de l’automatisation DevOps, car elles posent de nouveaux défis exigeant agilité, flexibilité et efficacité dans les processus de livraison de logiciels. Les environnements multicloud et cloud hybrides, par exemple, peuvent bénéficier de l’automatisation du déploiement et de la gestion des logiciels dans plusieurs environnements cloud. De même, l’IA/ML et l’IoT obligent les organisations à collecter et à traiter de grandes quantités de données en temps réel, ce qui peut s’avérer difficile sans automatisation. L’automatisation DevOps peut aider les organisations à automatiser les pipelines de données et les analyses, leur permettant de traiter les données plus rapidement et avec plus de précision.</p><p>Voici quelques avantages de l’automatisation DevOps :</p><p>● Rapidité et efficacité : l'automatisation DevOps permet aux organisations de fournir des logiciels plus rapidement et avec une meilleure qualité. En automatisant les tâches répétitives et chronophages, les développeurs peuvent se concentrer sur l'écriture de code et la fourniture de fonctionnalités. ● Agilité et flexibilité : l'automatisation DevOps offre aux organisations l'agilité et la flexibilité nécessaires pour s'adapter à l'évolution des besoins commerciaux et des exigences des clients. Les processus automatisés facilitent la publication des mises à jour logicielles et répondent rapidement aux demandes du marché. ● Rentabilité : l'automatisation DevOps réduit les coûts associés au développement de logiciels en réduisant le travail manuel et en minimisant les erreurs. Elle permet également aux organisations d'utiliser les ressources cloud plus efficacement, ce qui peut se traduire par des économies de coûts. ● Meilleure collaboration : en réunissant les différentes parties prenantes avec les développeurs et les opérations, DevOps favorise une approche collaborative pour une CI/CD améliorée. En automatisant les processus, les équipes peuvent travailler ensemble plus efficacement et partager leurs connaissances et leurs commentaires en temps réel. ● Évolutivité : l'automatisation DevOps permet aux organisations de faire évoluer leurs processus de livraison de logiciels rapidement et efficacement. Les processus automatisés facilitent le déploiement de logiciels dans plusieurs environnements et plates-formes, ce qui est essentiel pour les organisations qui doivent évoluer rapidement.</p><h3>Démarrer avec une automatisation DevOps efficace</h3><p>La mise en œuvre de l'automatisation DevOps nécessite une stratégie bien planifiée, des bonnes pratiques et un ensemble d'outils adaptés. Dans cette section, nous verrons comment mettre en œuvre avec succès l'automatisation DevOps dans votre organisation.</p><p>Comprendre DevOpsAvant de commencer avec l'automatisation, il est essentiel de comprendre les principes et les pratiques de DevOps. DevOps est une culture qui met l'accent sur la collaboration et la communication entre les équipes de développement logiciel et d'exploitation informatique pour créer, tester et publier des logiciels plus rapidement et de manière plus fiable. Il existe certains outils courants que les équipes DevOps utilisent pour leur travail, leur collaboration et leur communication :● GitHub : le service d'hébergement de référentiel Git utilisé pour le contrôle de version et la fonctionnalité de gestion du code source, en particulier pour les projets distribués.● JIRA : un outil de gestion de projet qui aide les équipes à planifier, suivre et gérer les projets de développement logiciel.● Slack : une plateforme de communication qui permet la messagerie en temps réel, le partage de fichiers et la collaboration.</p><p>Choisissez les bons outilsL'automatisation est au cœur de DevOps, et il est essentiel de sélectionner les bons outils. Choisissez des outils adaptés à vos besoins, à votre budget et à votre infrastructure. Voici quelques outils d'automatisation DevOps populaires :</p><p>● Jenkins : un serveur d'automatisation open source qui permet des pipelines d'intégration continue et de livraison continue (CI/CD).● GitLab : un gestionnaire de référentiel Git basé sur le Web qui fournit des fonctionnalités CI/CD, une gestion de projet et des outils de collaboration.● Puppet : un outil de gestion de configuration open source qui automatise le déploiement et la gestion de logiciels dans plusieurs environnements.● Chef : un outil de gestion de configuration qui automatise le déploiement et la gestion de logiciels dans plusieurs environnements.● Ansible : des outils open source pour automatiser le provisionnement, le déploiement et la gestion de la configuration de logiciels</p><p>Identifier les processus à automatiser</p><p>Commencez par dresser la liste de tous les processus critiques de votre organisation qui peuvent être améliorés grâce à l'automatisation. Commencez par les tâches répétitives et chronophages qui peuvent être automatisées, telles que les tests de code, le déploiement et la surveillance. Il existe un certain nombre d'outils populaires qui peuvent vous aider à réaliser cette automatisation :</p><p>● Selenium : un framework de test open source qui permet de tester automatiquement les applications Web.● Docker : une plateforme de conteneurisation qui permet la création, le déploiement et la gestion d'applications conteneurisées.● Kubernetes : l'outil d'orchestration de conteneurs open source est essentiel dans le pipeline DevOps pour l'orchestration et l'automatisation du déploiement, de la mise à l'échelle et de la gestion des applications conteneurisées.</p><p>Créer un plan</p><p>Une fois que vous avez identifié les objectifs d'automatisation et sélectionné les outils, créez un plan d'automatisation comprenant une feuille de route et des étapes clés. Commencez par de petits projets et développez progressivement l'automatisation pour couvrir tous les aspects du cycle de vie du développement logiciel. Voici quelques outils populaires pour élaborer une stratégie pour ces cycles de vie :</p><p>● Trello : un outil de gestion de projet qui permet aux équipes d'organiser et de hiérarchiser les tâches à l'aide de tableaux de style Kanban.● Asana : un outil de gestion de projet qui permet aux équipes de suivre et de gérer les tâches à l'aide de listes de tâches, de calendriers et de chronologies.</p><p>Formation de l'équipe</p><p>L'automatisation nécessite de nouvelles compétences. Il est donc essentiel de former votre équipe à utiliser efficacement les outils et les processus. Offrez des formations et des ressources pour aider votre équipe à acquérir de nouvelles compétences et techniques. Voici quelques ressources de formation et d'éducation populaires :</p><p>● Udemy : une plateforme d'apprentissage en ligne qui propose des cours sur les outils et techniques d'automatisation DevOps.● Coursera : une plateforme d'apprentissage en ligne qui propose des cours sur DevOps et des sujets connexes.● Pluralsight : une plateforme d'apprentissage en ligne qui propose des cours sur les outils et techniques d'automatisation DevOps.</p><p>Mise en œuvre de l'amélioration continue</p><p>Une boucle de rétroaction continue est essentielle au processus itératif et à l’amélioration continue de DevOps. Intégrez des mécanismes d’évaluation de vos processus d’automatisation, identifiez les domaines à améliorer et apportez les modifications nécessaires. Voici deux outils couramment utilisés pour ce faire :</p><p>● New Relic : un outil de surveillance des performances des applications qui offre une visibilité en temps réel sur les performances des applications logicielles.● Splunk : un outil d'intelligence opérationnelle qui permet aux organisations d'analyser et de visualiser les données des machines en temps réel.</p>"
L'avenir des tests continus dans le CI/CD,"<p>Si vous vous demandez pourquoi les tests continus sont si importants, pensez à ce qui suit : par le passé, les tests logiciels étaient généralement effectués après l'écriture du code et son envoi au service d'assurance qualité pour des tests indépendants. Lorsque des bugs étaient découverts, le code était renvoyé aux développeurs pour correction. Bien que cette méthode de test ait fonctionné, elle prenait du temps. Aujourd'hui, les entreprises veulent produire rapidement des produits de haute qualité, elles ont donc besoin d'un processus de test plus rapide et plus efficace. C'est là qu'intervient le test continu.</p><p>Dans cet article, nous allons explorer les tests continus depuis leur état actuel et leur avenir dans le CI/CD jusqu'aux technologies et tendances émergentes qui façonneront leur développement. Nous aborderons également l'importance des tests continus pour les entreprises et certains de ses défis.</p><h3>Qu'est-ce que les tests continus ?</h3><p>Les tests continus sont une approche de test logiciel dans laquelle les tests sont automatisés et exécutés tout au long du cycle de vie du développement logiciel. Ils font partie du processus de livraison continue (CD), dans lequel les modifications logicielles sont fournies aux clients de manière continue et itérative.</p><p>Les tests continus visent à identifier les défauts et les problèmes le plus tôt possible, réduisant ainsi le coût et le temps de leur résolution ultérieure. Les tests continus fournissent un retour d'information immédiat à l'équipe de développement, l'aidant à détecter et à résoudre les problèmes potentiels rapidement et efficacement.</p><p>Selon l'enquête Reports and Data Source, 21 % des professionnels de l'assurance qualité ont intégré des tests continus, la gestion du code source et l'intégration continue dans leur processus DevOps pour accélérer la publication du code.</p><h3>Avantages des tests continus</h3><p>Voici plusieurs avantages de la mise en œuvre de tests continus dans le cadre du processus de développement logiciel :● Les tests continus permettent aux équipes d'identifier les bogues plus tôt dans le processus de développement logiciel ;● Les tests continus fournissent un retour immédiat aux développeurs sur la qualité de leur code, leur permettant de résoudre immédiatement tout problème ;● Vous pouvez minimiser les risques commerciaux en évaluant et en identifiant les problèmes potentiels avant qu'ils ne deviennent de véritables problèmes ;● L'automatisation de vos cas de test peut réduire le temps consacré aux tests ;● L'accélération du processus de livraison du logiciel à la production permet de publier le produit plus rapidement ;● Vous pouvez exécuter des tests de performances en similitude, ce qui peut augmenter la vitesse d'exécution des tests.</p><h3>Inconvénients des tests continus</h3><p>Les tests continus font désormais partie intégrante du processus de développement logiciel, mais ils ne sont pas sans poser de problèmes. Alors que les équipes de développement logiciel s’efforcent d’intégrer les tests dans leurs pipelines CI/CD, elles peuvent rencontrer des obstacles qui peuvent entraver leur progression. ● Les tests continus nécessitent un ensemble de compétences différent des tests traditionnels, notamment une expertise en DevOps, en automatisation et en pipelines CI/CD. ● Différents outils et technologies sont disponibles pour les tests continus, et il peut être difficile de choisir les bons. L’intégration de ces outils à d’autres parties du processus de développement peut également s’avérer difficile. ● Pour tirer pleinement parti des avantages des tests continus, vous devez mettre à jour votre stratégie de test en vous éloignant des méthodes de test traditionnelles et en adoptant une approche bien définie de la gestion des données de test. ● Le fait de ne pas intégrer régulièrement le code peut entraîner des problèmes tels que des efforts de codage en double et du code non compatible, entraînant des défauts.</p><h3>Technologies émergentes dans le domaine des tests continus</h3><p>Avec la demande croissante de versions de logiciels plus rapides et plus fiables, des technologies émergentes telles que l’IA/ML, l’automatisation et DevOps sont apparues dans les tests continus. Ces technologies aident les équipes à automatiser et à rationaliser leurs processus de test, à identifier les défauts plus rapidement et à améliorer la qualité globale des logiciels. Examinons-en quelques-unes :</p><p>Intelligence artificielle/apprentissage automatique (IA/ML). L'IA et le ML font référence au domaine de l'informatique qui traite du développement de machines intelligentes capables de simuler l'intelligence humaine et d'apprendre à partir de données.</p><p>L’un des principaux avantages de l’IA et du ML dans les tests continus est la possibilité d’automatiser la génération de cas de test, ce qui réduit le besoin de tests manuels et libère du temps pour d’autres tâches. Cela permet aux testeurs de tester les applications de manière plus complète et plus fréquente, garantissant ainsi que les défauts ou les problèmes sont identifiés et résolus rapidement. L’IA et le ML augmentent la précision des tests en identifiant les modèles et les anomalies dans les données de test.</p><p>Les techniques d’IA et de ML peuvent analyser efficacement et rapidement de grandes quantités de données, leur permettant de reconnaître des modèles et des irrégularités dans les données de test que les testeurs humains pourraient négliger.</p><p>Automatisation : L'automatisation des tests continus fait référence à l'utilisation d'outils et de processus automatisés pour exécuter des tests logiciels de manière répétée et cohérente. Elle implique l'automatisation de différentes étapes du cycle de vie des tests logiciels, telles que la planification des tests, la conception des cas de test, l'exécution des tests et la création de rapports de test.</p><p>L'automatisation permet d'effectuer efficacement des tests de régression, garantissant que les modifications n'introduisent pas de nouveaux défauts ou problèmes dans le logiciel. Les tests peuvent être exécutés 24 heures sur 24, 7 jours sur 7, sans intervention humaine, ce qui réduit le temps et le coût nécessaires aux tests.</p><p>DevOps : DevOps dans les tests continus est l'application des principes DevOps aux tests continus, en se concentrant sur l'intégration des tests dans le cycle de vie du développement logiciel et en permettant une livraison plus rapide et plus fiable des logiciels.</p><p>Dans le contexte des tests continus, DevOps met l'accent sur l'intégration des tests dans le processus de développement, permettant aux développeurs de détecter et de corriger les défauts au début du cycle. DevOps favorise également l'automatisation, la collaboration et la communication entre les équipes de développement et d'exploitation, permettant des tests et un déploiement plus rapides et plus efficaces.</p><p>Blockchain : La technologie Blockchain suscite une attention croissante dans le secteur du développement et des tests de logiciels en raison de sa capacité à fournir un stockage de données sécurisé et inviolable.</p><p>Dans le cadre de tests continus, la blockchain stocke les résultats et les données de test de manière décentralisée et transparente, ce qui rend pratiquement impossible toute modification ou manipulation des données. Cela renforce la crédibilité du processus de test et des résultats et fournit une couche de sécurité supplémentaire pour garantir l'intégrité des données.</p><p>La technologie Blockchain permet un partage de données efficace et transparent entre les parties prenantes impliquées dans le processus de test, permettant une prise de décision plus rapide et plus précise.</p><p>Internet des objets (IoT) : dans le cadre de tests continus, l'IoT simule de nombreux appareils et plateformes IoT, ce qui permet aux testeurs de tester leurs applications sur plusieurs appareils et plateformes. Cela garantit que les applications sont compatibles avec divers appareils et plateformes IoT et fonctionnent de manière fiable et cohérente dans divers environnements.</p><p>Par exemple, lors de la création d’une application qui doit s’exécuter sur plusieurs appareils, il est possible d’utiliser un émulateur pour tester l’application sur votre ordinateur portable sans configurer un environnement de développement pour chaque type d’appareil.</p><p>Les tests continus basés sur l’IoT fournissent un retour d’information en temps réel sur les performances et les fonctionnalités des applications, permettant aux organisations d’identifier et de résoudre les problèmes rapidement et efficacement.</p><h3>Tendances en matière de tests continus</h3><p>Les tests continus évoluent rapidement pour répondre aux besoins des pratiques modernes de développement de logiciels, avec l’émergence de nouvelles tendances pour répondre aux défis auxquels sont confrontées les équipes de développement. Trois tendances clés gagnent actuellement du terrain dans les tests continus : les tests basés sur le cloud, les tests shift-left et les tests de sécurité. Ces tendances sont motivées par la nécessité d’accroître l’efficacité et la rapidité du développement de logiciels tout en garantissant les niveaux de qualité et de sécurité les plus élevés. Examinons ces tendances de plus près.</p><p>Tests basés sur le cloud : les tests continus sont déployés via le cloud computing, qui offre de nombreux avantages tels que la facilité de déploiement, l’accessibilité mobile et la rapidité de configuration. Les entreprises adoptent désormais des services basés sur le cloud en raison de leur disponibilité, de leur flexibilité et de leur rentabilité. Les tests basés sur le cloud ne nécessitent pas de compétences en codage ni de temps de configuration, ce qui en fait un choix populaire pour les entreprises.</p><p>Tests pilotés par l'IA : les tests continus pilotés par l'IA sont souvent intégrés dans des plateformes de test basées sur le cloud, offrant une automatisation de bout en bout pour les tests Web, mobiles et API. Les tests basés sur l'IA et le cloud permettent d'accéder aux environnements de test n'importe où, à tout moment, et permettent d'effectuer des tests automatisés réguliers à l'aide de plateformes comme Selenium.</p><p>Tests Shift-Left : les tests Shift-Left sont des tests logiciels qui impliquent de tester plus tôt dans le cycle de développement plutôt que d'attendre des étapes ultérieures, telles que les tests système ou d'acceptation. L'objectif des tests Shift-Left est d'identifier et de traiter les défauts le plus tôt possible.</p><p>Le report des tests jusqu'à la fin du développement entraîne souvent des corrections de bugs plus compliquées, car le logiciel est déjà entièrement développé. Cela peut entraîner une augmentation des coûts et des délais de mise sur le marché. L'identification et la correction des bugs plus tôt dans le cycle de vie du développement logiciel sont généralement plus rentables.</p><p>Selon le Systems Sciences Institute d’IBM, la réparation d’un bug découvert lors de l’implémentation coûte environ six fois plus cher que celle d’un bug découvert lors de la conception. Si une erreur est détectée après la sortie du produit, le coût de sa correction est quatre à cinq fois plus élevé que celui d’un bug découvert lors de la conception et jusqu’à 100 fois plus élevé que celui d’un bug découvert lors de la phase de maintenance. Cela suggère que le coût d’un bug augmente de manière exponentielle à mesure que le logiciel progresse dans le cycle de vie du logiciel.</p><p>Low-Code/No-Code : Le low-code ou le no-code dans les tests continus fait référence à l'utilisation d'interfaces visuelles et d'éléments ou de modules prédéfinis pour créer et exécuter des tests automatisés au lieu d'écrire du code complexe. Les outils de test low-code/no-code fournissent souvent des interfaces par glisser-déposer et des composants prédéfinis qui peuvent être combinés pour créer des tests, réduisant ainsi le temps et les efforts nécessaires au développement et à la maintenance des scripts de test.</p><p>Ce type de test offre plusieurs avantages, notamment celui de permettre à des experts commerciaux non techniques d'exécuter des tests, d'accélérer la production et l'exécution des tests et d'améliorer la qualité du produit en permettant des tests plus approfondis et plus efficaces.</p><p>En règle générale, selon les statistiques, d’ici 2025, environ 70 % des nouvelles applications commerciales devraient utiliser des technologies low-code ou no-code.</p><p>Tests de sécurité : En raison de l’incidence croissante des menaces de cybersécurité et des violations de données, les tests de sécurité sont devenus un aspect crucial de l’assurance qualité des logiciels. En 2023, le monde de la technologie prévoit que l’accent sera davantage mis sur les tests de sécurité, avec l’émergence d’outils et de méthodologies plus avancés visant à détecter et à résoudre les faiblesses de sécurité des applications logicielles.</p>"
"Non, les emplois de développeurs ne sont pas morts : l’IA signifie que « tout le monde est programmeur » ? ¦ VPU Intel intéressants","<p>Bienvenue dans The Long View, où nous passons en revue l'actualité de la semaine et en tirons l'essentiel. Déterminons ce qui compte vraiment.</p><p>Cette semaine : le PDG de Nvidia fait la une des journaux en déclarant que votre carrière est terminée et qu’Intel continue de se battre.</p><p>Premier point de la semaine : le discours d’ouverture du Computex de « Jensen » Huáng Rénxūn : il affirme que l’IA va occuper de nombreux postes, notamment dans le domaine du développement de logiciels. Selon le courageux milliardaire, n’importe qui peut désormais dire aux ordinateurs ce qu’ils doivent faire, simplement en leur parlant.</p><h3>Analyse : Des conneries totales, évidemment.</h3><p>Nous avons déjà connu cette situation à maintes reprises : une nouvelle technologie magique rend la programmation obsolète. Mais le paradis du no-code n’a jamais eu lieu, principalement parce que ceux qui ont fait ces prédictions étaient extrêmement ignorants en matière de développement logiciel. Huang ne fait pas exception à la règle, et il essaie simplement de vendre plus de GPU.</p><p>Eleanor Olcott et Madhumita Murgia : Jensen Huang, le patron de Nvidia, affirme que l'IA est en train de créer une « nouvelle ère informatique »</p><p>« La demande a grimpé en flèche » Le directeur général de Nvidia a salué une nouvelle ère de l’informatique dans laquelle « tout le monde est un programmeur », [en affirmant que l’IA] avait considérablement abaissé la barrière d’entrée au codage informatique : « Nous avons atteint le point de basculement d’une nouvelle ère informatique », a déclaré Huang… en faisant valoir que l’IA permettait désormais aux individus de créer des programmes simplement en branchant des commandes.… ChatGPT peut générer du code, réduisant le travail humain nécessaire à la création de logiciels, un développement qui devrait révolutionner la programmation. Le discours de Huang à la conférence Computex à Taipei est intervenu quelques jours après que Nvidia a révélé des prévisions de croissance rapide des ventes.… La demande a grimpé en flèche pour les puces de centre de données de Nvidia, y compris le H100, une unité de processeur graphique (GPU) avancée qui réduit considérablement le temps nécessaire à la formation… de modèles tels que ChatGPT. … Huang a également annoncé une nouvelle plate-forme de supercalculateur d’IA appelée DGX GH200 pour aider les entreprises technologiques à créer des modèles d’IA génératifs.</p><p>Ben Blanchard : Tout le monde peut désormais devenir programmeur</p><p>« Il suffit de dire quelque chose » L’intelligence artificielle signifie que tout le monde peut désormais devenir programmeur informatique, car il suffit de parler à l’ordinateur… a déclaré lundi Jensen Huang, saluant la fin de la « fracture numérique ». … S’adressant à des milliers de personnes au forum Computex… Huang, qui est né dans le sud de Taiwan avant que sa famille n’émigre aux États-Unis alors qu’il était enfant, a déclaré que l’IA était à l’origine d’une révolution informatique. « Il n’y a aucun doute… » a-t-il déclaré dans un discours, lâchant de temps en temps des mots en mandarin ou en taïwanais pour le plus grand plaisir de la foule… « La barrière de la programmation est incroyablement basse. Nous avons comblé la fracture numérique. Tout le monde est programmeur maintenant, il suffit de dire quelque chose à l’ordinateur », a-t-il déclaré. « Le rythme des progrès, parce qu’il est si facile à utiliser, est la raison pour laquelle il se développe si rapidement. Cela va toucher littéralement tous les secteurs. »</p><p>Catherine Shu s'inscrit dans la lignée des éléphants dans la pièce</p><p>« Sécheresse » Plusieurs sujets ont à peine été évoqués. … Le fait est qu’au milieu de problèmes tels que les tensions géopolitiques et les pénuries de puces induites par l’IA, l’industrie des semi-conducteurs est en pleine tourmente : …</p><li>Alors que les relations entre les gouvernements américain et chinois continuent de se dégrader, les choses deviennent compliquées dans l’industrie des semi-conducteurs. …</li><li>L’attrition des employés et le manque de talents en général pourraient constituer un véritable casse-tête pour les entreprises de semi-conducteurs. …</li><li>Le calcul de l’IA générative fonctionne sur des puces, principalement des GPU fabriqués par Nvidia, mais ceux-ci deviennent de plus en plus rares. …</li><li>Pendant ce temps, les startups et les grandes entreprises comme Intel et NTT travaillent sur des alternatives comme les puces photoniques [mais] il faudra peut-être des années avant que la technologie photonique ne devienne courante. …</li><li>Taïwan traverse une nouvelle période de sécheresse. La précédente, en 2021, avait eu un impact négatif sur la production de semi-conducteurs du pays, car la production de puces nécessite une énorme quantité d’eau.</li><p>Mais pourquoi sommes-nous « soudainement » si intéressés par les GPU ? John Burek explique : Le point important à retenir</p><p>Il n’y a pas si longtemps… 10 millions de dollars… vous permettaient d’acheter 960 serveurs basés sur CPU, consommant 11 gigawattheures… pour former un… LLM. Le même montant vous permettrait aujourd’hui d’acheter 48 serveurs basés sur GPU utilisant environ un tiers de l’énergie… avec la capacité de former 44 LLM. À l’inverse… former un LLM vous coûterait aujourd’hui environ 400 000 dollars au lieu des 10 millions de dollars initiaux.</p><p>C'est de la poudre de perlimpinpin, pense SilverBirch :</p><p>C’est vraiment intéressant. Parce que si… Huang croit ce qu’il dit, alors les actions de Nvidia devraient bientôt perdre toute leur valeur. [S’il] croit vraiment cela, alors nous sommes à environ 6 semaines de voir Nvidia licencier tous ses ingénieurs logiciels, embaucher une bande d’idiots radins pour parler à leur IA magique, et par conséquent faire complètement couler l’entreprise… Tout le vrai travail dans l’histoire de l’IA a été fait par des ingénieurs incroyablement bien qualifiés avec des millénaires d’expérience cumulés… Cette tendance rend en fait les ingénieurs plus précieux… C’est le plus vieux truc du livre : « Vous n’avez pas besoin de faire X, nous pouvons l’automatiser ! »… Il s’avère qu’ils font juste X avec une balise.</p><p>Et XXongo ne mâche pas ses mots :</p><p>Nvidia n’a aucune idée de ce qu’il faut faire. « Fais ce que je veux » s’avère ne pas être une commande réelle.… Programmer signifie être capable d’envisager et de séquencer clairement le flux logique d’un processus. Si vous ne savez pas comment transformer vos exigences en une séquence claire d’opérations, vous ne pouvez pas « programmer », même si vous avez une IA.</p><p>Avec une réaction plus nuancée, voici dtagames :</p><p>La programmation a toujours consisté à « dire à un ordinateur ce qu’il doit faire ». Cet aspect ne change pas avec les LLM. Ce qui change, c’est le type de langage que nous utilisons pour faire cette explication… Les parties difficiles sont l’architecture, la logique, le développement de l’interface utilisateur et le débogage. Si les LLM peuvent être d’une grande aide pour les programmeurs qui font déjà ce travail, ils ne transformeront pas quelqu’un en programmeur s’il n’a pas déjà une aptitude pour ces domaines.</p><p>Cette métaphore colorée nous est offerte par Enriquevagu :</p><p>Grâce aux machines à écrire, tout le monde peut désormais devenir écrivain.</p><p>Nvidia n'a pas été le seul acteur de l'IA au Computex. Par exemple, Intel a dévoilé son projet d'ajouter un cœur de coprocesseur IA à tous ses SoC de 14e génération.</p><h3>Analyse : C’est une question de vision</h3><p>Un VPU est similaire à un NPU ou à un TPU. L’idée semble bien plus adaptée aux charges de travail de l’IA que le matériel GPU hérité de Nvidia.</p><p>Simon Sharwood déclare : Tous les lacs Meteor reçoivent un VPU</p><p>« Déchargé sur les VPU » Intel va ajouter la technologie VPU qu’il a acquise avec Movidius en 2016 à tous les modèles de son prochain Meteor Lake. … Curieusement, Intel n’a pas précisé l’acronyme, mais a déjà déclaré qu’il signifie Vision Processing Unit. [Il s’agit] d’un silicium IA dédié. … Le VPU doit gérer « l’IA soutenue et le déchargement de l’IA ». Les CPU devront toujours effectuer des tâches d’inférence simples avec une faible latence. … Les GPU pourront effectuer des tâches impliquant le parallélisme des performances et le débit. D’autres travaux liés à l’IA seront déchargés sur les VPU.</p><p>Mais qu'est-ce que c'est ? DamnOregonian explique :</p><p>L’unité de traitement de la vision est un nom stupide, et je ne l’ai pas entendu utilisé depuis qu’il était populaire sur les anciens composants TI OMAP. En réalité, il s’agit d’un élément matériel MMA dédié qui rend l’exécution des moteurs d’inférence [de réseau neuronal] vraiment efficace et rapide. De nos jours, les gens aiment les appeler NPU (Apple) [ou] TPU (NV, Google). Ils sont incroyablement plus rapides qu’un cœur de shader GPU normal dans ce domaine d’activité particulier, et beaucoup plus efficaces.</p><p>C'est une question existentielle, pense Mevets :</p><p>Chipzilla est un nom contesté. … Récemment, nous avons eu Raptor Lake, qui présente de belles images : l’une des dernières lignées de dinosaures avant leur transformation en une espèce moderne. Maintenant, Meteor Lake, qui évoque un lac idyllique, où les dinosaures jouent dans l’eau alors qu’un météore qui a changé le monde s’abat sur la planète.</p><p>—Les BrownVous lisez The Long View de Richi Jennings. Vous pouvez le contacter à @RiCHi ou à [email protected].</p><p>Image : Christian Cueni (via Unsplash ; nivelée et recadrée)</p>"
OpenAI va devenir Open Source — Elon Musk était un « énorme idiot » ¦ Mojo Risin’,"<p>Bienvenue dans The Long View, où nous passons en revue l'actualité de la semaine et en tirons l'essentiel. Déterminons ce qui compte vraiment.</p><p>Cette semaine : des sources affirment qu’OpenAI évoluera vers un avenir open source et qu’il améliorera les performances de l’IA avec Mojo.</p><p>Tout d’abord, cette semaine : une source anonyme a déclaré à Jon Victor de The Information qu’OpenAI allait publier une version open source de son modèle de langage étendu (LLM). Mais est-ce que cela a du sens ?</p><h3>Analyse : Elon obtient ce qu'il veut</h3><p>Iron Man a raconté à CNBC comment il avait financé OpenAI à ses débuts (même si la somme semble avoir été divisée par deux, passant de 100 millions de dollars à seulement 50 millions de dollars). Il a cependant souligné que l’essentiel était qu’OpenAI était censé être… eh bien, ouvert. Plus précisément, une organisation à but non lucratif open source.</p><p>Ananya Mariam Rajesh : OpenAI prépare un nouveau modèle d'IA open source… rapporte</p><p>OpenAI se prépare à publier un nouveau modèle de langage open source au public [a déclaré] une personne au courant du projet. … Il est peu probable qu’OpenAI publie un modèle qui soit compétitif avec GPT, selon le rapport.</p><p>Usama Jawad : Suite au succès de ChatGPT, OpenAI pourrait publier un modèle d’IA open source</p><p>Un nouveau rapport affirme que le créateur de ChatGPT, OpenAI, envisage de publier prochainement un nouveau modèle d’IA open source. … Il s’agirait d’une avancée significative étant donné que GPT-4, le grand modèle de langage (LLM) qui alimente ChatGPT, est un modèle à code source fermé. … Si l’on en croit la dernière rumeur, OpenAI change de cap et cherche à publier une alternative à GPT-4, accessible au public. … Actuellement, OpenAI facture aux clients 20 $ par mois [pour] ChatGPT Plus, qui est alimenté par GPT-4. … D’autres acteurs ont déjà fait des vagues dans cet espace. Meta a publié publiquement son modèle de langage large open source Meta AI (LLaMA) il y a quelques mois. Même la plus petite variante du modèle est entraînée sur plus d’un billion de jetons, ce qui offre aux chercheurs et aux passionnés un vaste terrain de jeu pour explorer la technologie sous-jacente et même l’améliorer. Il est probable qu’OpenAI pense dans le même sens.</p><p>Qui mettra cela en contexte ? Will Douglas Heaven ?</p><p>La semaine dernière, un mémo qui aurait été rédigé par… un ingénieur senior de Google, a dit à haute voix ce que beaucoup dans la Silicon Valley ont dû murmurer depuis des semaines : Un accès libre à l’open source menace l’emprise des Big Tech sur l’IA.… Les grands modèles de langage open source… tombent comme des bonbons d’une piñata :… HuggingChat… StableLM… Alpaca… Dolly… Cerebras-GPT.… L’avenir de la façon dont l’IA est créée et utilisée est à la croisée des chemins. … À bien des égards, c’est une bonne chose. Un meilleur accès à ces modèles a contribué à stimuler l’innovation – il peut également aider à détecter leurs défauts. L’IA ne prospérera pas si seulement quelques entreprises ultra-riches parviennent à contrôler cette technologie ou à décider de la façon dont elle est utilisée.</p><p>Tout est de la faute d’Elon Musk. M. Musk s’entretient avec David Faber :</p><p>J’avoue être un grand idiot. … Je suis la raison pour laquelle OpenAI existe. … Mon Dieu, le destin aime l’ironie – un niveau supérieur. … Il n’existerait pas sans moi. … J’ai trouvé le nom. Le nom OpenAI fait référence à l’open source. L’intention était : « Quel est l’opposé de Google ? » Ce serait une organisation à but non lucratif open source. … Est-il… légal de créer une entreprise en tant qu’organisation à but non lucratif, puis de prendre la propriété intellectuelle et de la transférer à une organisation à but lucratif qui gagne ensuite des tonnes d’argent ? … C’est exactement le contraire de ce pour quoi je vous ai donné de l’argent. … Je crains que Microsoft ait en fait plus de contrôle que… l’équipe de direction d’OpenAI ne le pense.</p><p>Cela résonne avec nr2x :</p><p>Ces outils sont le fruit de travaux universitaires, financés par le gouvernement depuis des décennies, et de contenus utilisateurs, eux aussi générés depuis des décennies. … L’IA des entreprises ne revend que 90 % des biens publics à un prix majoré. Elles devraient être légalement obligées de rendre leur code source ouvert.</p><p>Pendant ce temps, u/wencc souligne que l'indice est dans le nom :</p><p>Vous voulez donc dire qu’OpenAI va ouvrir son IA ?</p><p>Mojo, un sur-ensemble compilé de Python, se propose de devenir le langage de l’IA. La plupart des modèles sont aujourd’hui codés en Python, mais c’est terriblement lent.</p><h3>Analyse : Si quelqu’un peut le faire, c’est l’équipe de Lattner</h3><p>Chris Lattner, le créateur de Swift, MLIR et LLVM, a cofondé Modular, la société à l’origine de Mojo. Je pense donc que nous pouvons supposer qu’il ne s’agit pas d’une opération à la sauvette.</p><p>Jeremy Howard : Mojo pourrait être la plus grande avancée en matière de langage de programmation depuis des décennies</p><p>Aujourd’hui, presque tous les modèles d’IA sont développés en Python, grâce à un langage de programmation flexible et élégant, à des outils et un écosystème fantastiques et à des bibliothèques compilées hautes performances. … Mais Python est des milliers de fois plus lent que des langages comme C++.… Mojo est Python. … Peut-être est-il préférable de dire que Mojo est Python++. … L’une des principales astuces de Mojo est que vous pouvez à tout moment opter pour un « mode » plus rapide en tant que développeur, en utilisant « fn » au lieu de « def » pour créer votre fonction. Dans ce mode, vous devez déclarer exactement le type de chaque variable, et par conséquent Mojo peut créer un code machine optimisé pour l’implémenter. Si vous utilisez « struct » au lieu de « class », vos attributs seront étroitement regroupés en mémoire, de sorte qu’ils pourront même être utilisés dans des structures de données sans courir après des pointeurs. Ce sont les types de fonctionnalités qui permettent à des langages comme C d’être si rapides, et elles sont désormais accessibles aux programmeurs Python.… Au cœur de Mojo se trouve MLIR, qui a déjà été développé depuis de nombreuses années, initialement lancé par Chris Lattner chez Google. Il avait identifié les fondations essentielles d’un « langage de programmation de l’ère de l’IA » et s’était concentré sur leur construction. [Il y a] des raisons d’être optimiste quant à l’avenir de Mojo. Bien que ce projet soit encore à ses débuts, je pense… qu’il va se développer plus rapidement et plus loin que la plupart d’entre nous ne l’imaginent.</p><p>Il est allumé. C'est Jeff Delaney :</p><p>Python est un langage formidable pour la programmation productive, mais il a un gros problème : il est trop lent. Et si vous allez lentement, vous serez la risée des adeptes de Rust et de C++. … Mojo [est] un sur-ensemble de Python qui est… jusqu’à 35 000 fois plus rapide que le Python de votre grand-père. … Voici cinq choses que vous devez savoir :… 1. Ce n’est pas le projet parallèle d’un inconnu sur GitHub, mais plutôt celui d’une entreprise fondée par… le gars qui a créé le langage de programmation Swift et la chaîne d’outils du compilateur LLVM. Si quelqu’un pouvait résoudre les problèmes de Python, c’est bien lui. 2. C’est un langage conçu pour la programmation sur du matériel d’IA comme les GPU exécutant Cuda et d’autres accélérateurs. Il y parvient en exploitant la représentation intermédiaire multi-niveaux (MLIR) pour évoluer… sans trop de complexité. Et il dispose même d’un réglage automatique intégré pour optimiser votre code. … 3. Il est conçu comme un sur-ensemble de Python, de la même manière que TypeScript est un sur-ensemble de JavaScript. Vous n’avez donc pas besoin d’apprendre un autre langage [et] vous pouvez toujours utiliser vos bibliothèques préférées, comme numpy, pandas, etc. 4. Il ajoute une vérification de type forte… et une vérification des erreurs pour la gestion de la mémoire. Il dispose d’un système de propriété et de vérificateurs d’emprunt similaires à Rust et prend également en charge la gestion manuelle de la mémoire avec des pointeurs comme C++. C’est un langage pragmatique qui vous offre la sécurité mais aussi la flexibilité de ne pas être sûr en cas de besoin. … 5. Actuellement, il n’est pas disponible au public. Il est encore en développement très précoce. Il sera open source dans le futur, mais il y a actuellement une liste d’attente pour l’essayer. J’ai eu la chance d’obtenir l’accès anticipé, alors lançons-le :</p><p>Attendez. Pause. 35 000x perf ? Dégagez de ma pelouse, exhorte monkeyxpress :</p><p>Pas encore. … Il faut juste avoir quelqu’un qui a une petite idée de la façon dont fonctionne le matériel. Essayer de « résoudre » ce problème d’ignorance avec des solutions fantaisistes a peu de chances de fonctionner. … Je ne comprends tout simplement pas pourquoi il est si difficile pour quelqu’un d’apprendre les bases de l’architecture CPU/GPU. Si vous faites des recherches sérieuses sur l’IA, cela ne devrait pas être au-dessus de vos forces. … Je vois la même ignorance dans beaucoup de JavaScript. Il est possible de détruire complètement un processeur moderne en faisant quelque chose de très simple si vous ignorez simplement le matériel sous-jacent, alors que d’un autre côté, vous pouvez écrire du code qui fonctionne assez bien en étant un peu respectueux. Malheureusement… l’ignorance est un bonheur pour la plupart des développeurs.</p><p>—Jim MorrisonVous lisez The Long View de Richi Jennings. Vous pouvez le contacter à @RiCHi ou à [email protected].</p><p>Image : Dollar Gill (via Unsplash ; nivelée et recadrée)</p>"
La majorité des organisations déclarent bénéficier des plateformes low-code,"<p>Certains services informatiques ressentent la pression des récents ralentissements économiques. L’année 2023 a déjà été marquée par un nombre disproportionné de licenciements dans le secteur technologique. En conséquence, il n’y a pas toujours assez de développeurs de logiciels disponibles pour répondre à la demande. Cela a conduit certaines organisations à se tourner vers de nouveaux moyens pour maintenir le moral et réduire l’épuisement professionnel, maintenir la productivité et faire plus avec moins.</p><p>Le développement low-code est une solution qui pourrait aider à faire face aux retards croissants dans le traitement des applications. Les plateformes low-code/no-code utilisent des composants réutilisables pour aider les ingénieurs (et les développeurs citoyens) à créer des applications fonctionnelles et des flux de travail internes. De nombreuses équipes indiquent qu'elles utilisent le low-code pour proposer rapidement de nouvelles fonctionnalités. Une étude récente de Microsoft a révélé que 89 % des DSI et des professionnels de l'informatique ont déclaré que le low-code est efficace pour accroître l'efficacité.</p><p>Microsoft Power Platform a récemment financé une étude auprès de 2 000 DSI et professionnels de l’informatique sur leur utilisation des plateformes low-code. Selon le rapport, les utilisateurs ont tiré profit de ces plateformes en modernisant l’informatique existante, en améliorant l’efficacité et en réduisant les coûts, entre autres. Ci-dessous, je vais passer en revue certains points clés de l’étude Microsoft et les comparer à d’autres perspectives.</p><p>Le rapport met en avant une multitude d’avantages liés à l’utilisation de plateformes low-code. L’un d’entre eux est la modernisation des applications existantes : 87 % des DSI et des professionnels de l’informatique ont déclaré que le low-code était très utile pour aider leurs organisations à moderniser les applications existantes. La résolution du problème de la dette technique est une priorité, puisque 69 % des responsables informatiques ont identifié la dette technique comme une menace pour l’innovation. Un autre avantage clé est l’efficacité. L’étude a révélé que l’efficacité des développeurs avec ces plateformes augmente considérablement au fil du temps, atteignant en moyenne 62 % sur trois ans.</p><p>Les plateformes low-code sont également un domaine privilégié pour intégrer l’intelligence artificielle et davantage d’automatisation dans le processus de développement logiciel. Microsoft, qui a récemment annoncé l’intégration de ChatGPT dans sa plateforme Power, a indiqué que 87 % des DSI et des professionnels de l’informatique ont déclaré qu’une IA et une automatisation accrues intégrées aux plateformes low-code les aideraient à mieux exploiter l’ensemble des fonctionnalités.</p><p>Enfin, la réduction des coûts constitue un avantage non négligeable. 87 % des personnes interrogées ont déclaré que le low-code permettait de réduire efficacement les coûts. Ces solutions pourraient accélérer la réalisation des projets en attente, en augmentant l’efficacité et en réduisant les ressources nécessaires à leur mise en œuvre. Cela arrive à un moment où l’optimisation des coûts est essentielle pour éviter la hausse des frais de cloud.</p><p>Comment les équipes de développement travaillent-elles réellement avec ces plateformes ? L’un des cas d’utilisation les plus courants est l’amélioration des processus de données en rationalisant les intégrations et en disposant d’un référentiel centralisé. En fait, 86 % des DSI et des professionnels de l’informatique ont déclaré que le low-code avait aidé leur organisation à générer des informations plus précises à partir de leurs données. Ces informations basées sur les données ont été utilisées pour mieux servir les clients et les parties prenantes internes.</p><p>Par exemple, ÖBB, un opérateur ferroviaire autrichien, a utilisé une plateforme low-code pour synchroniser les données et automatiser les demandes de service client avec des agents virtuels. D’autres études de cas font état de l’utilisation de Microsoft Power Platform pour la migration à partir de systèmes existants et la réduction des délais de traitement des documents.</p><p>Mais au-delà du rapport de Microsoft, tout le monde n’est pas totalement convaincu par le low-code. Par exemple, le PDG de StackOverflow a exprimé des réserves, car les plateformes low-code ont finalement un plafond. Avec le low-code, la personnalisation est limitée, ce qui en fait un choix peu adapté aux développeurs expérimentés ou aux entreprises spécialisées dans les technologies. Les entreprises doivent également atténuer les répercussions potentielles sur la sécurité si elles permettent aux utilisateurs professionnels de créer des applications, ce qui nécessite de nouvelles règles et de nouvelles politiques. Les utilisateurs de plateformes low-code peuvent également être victimes de la dépendance vis-à-vis des fournisseurs et d’une récupération des données difficile, ce qui souligne la nécessité de plateformes ouvertes avec accès programmatique.</p><p>Les solutions low-code sont une option viable pour aider à éliminer les éléments du backlog informatique, automatiser les processus fastidieux et libérer les ingénieurs pour qu'ils se concentrent sur des questions plus urgentes. Certains outils low-code/no-code aident également à démocratiser le développement d'applications auprès de personnes ayant des compétences différentes, attirant ainsi de nouveaux utilisateurs dans le domaine du développement. Et l'intérêt pour le low-code continue de croître : Markets and Markets prévoit un taux de croissance annuel composé (TCAC) sur le marché des plateformes industrielles de développement low-code de 28,1 % pour atteindre 45,5 milliards de dollars d'ici 2025.</p><p>Naturellement, les conclusions et les études de cas de ce rapport sont un peu biaisées en faveur des avantages de l’utilisation de Microsoft Power Platform. Néanmoins, il sert d’indication sur les divers avantages des plateformes low-code. Pour plus d’informations, vous pouvez lire le rapport complet ici sur le blog Microsoft Power Platform.</p>"
ChatGPT peut-il corriger des bugs ? Le développeur de « Wolverine » dit OUI,"<p>Bienvenue dans The Long View, où nous passons en revue l'actualité de la semaine et en tirons l'essentiel. Déterminons ce qui compte vraiment.</p><p>Cette semaine : au lieu d’utiliser l’IA pour la programmation, pourquoi pas pour le débogage ? Le pseudonyme « BioBootloader » affirme avoir persuadé GPT-4 de rendre son code auto-réparateur.</p><h3>Analyse : de la poudre aux yeux</h3><p>C’est impressionnant, ne serait-ce que pour l’ingéniosité de l’ingénierie des messages. Mais il y a une énorme différence entre corriger une erreur d’exécution et faire en sorte qu’un programme fasse ce que dit l’histoire utilisateur. On ne sait pas si Wolverine est une étape dans le processus ou une impasse.</p><p>Quelle est l’histoire ? Benj Edwards rapporte : « Un développeur crée un programme d’IA « régénératif » qui corrige les bugs à la volée » :</p><p>« Pas encore complètement exploré » Déboguer un programme défectueux peut être frustrant, alors pourquoi ne pas laisser l’IA le faire pour vous ? C’est ce qu’a fait un développeur connu sous le nom de « BioBootloader » en créant Wolverine, un programme qui peut donner aux programmes Python des « capacités de guérison régénératrices ». … (Oui, tout comme le super-héros Marvel.)… Dans la démo… BioBootloader montre une fenêtre côte à côte, avec le code Python à gauche et les résultats de Wolverine à droite dans un terminal. Il charge un script de calculatrice personnalisé dans lequel il ajoute volontairement quelques bugs, puis l’exécute. … GPT-4 renvoie une explication des erreurs du programme, affiche les modifications qu’il essaie d’apporter, puis réexécute le programme. Lorsqu’il détecte de nouvelles erreurs, GPT-4 corrige à nouveau le code, puis il s’exécute correctement. … Bien qu’il s’agisse actuellement d’un prototype primitif, des techniques comme Wolverine illustrent un avenir potentiel où les applications pourraient être capables de corriger leurs propres bugs, même ceux inattendus qui peuvent apparaître après le déploiement. Bien entendu, les implications, la sécurité et la sagesse d’autoriser une telle situation n’ont pas encore été pleinement explorées.</p><p>Vivons-nous dans le futur ? Donald Papp a dévoilé l’histoire à bout de souffle : « Wolverine donne à vos scripts Python la capacité de s’auto-réparer » :</p><p>« Invite soigneusement rédigée » Le script Python de démonstration est une simple calculatrice qui fonctionne à partir de la ligne de commande, et BioBootloader y introduit quelques bugs. Il orthographie mal une variable utilisée comme valeur de retour et supprime entièrement la fonction subtract_numbers(a, b). L’exécution de ce script seul plante simplement, mais l’utilisation de Wolverine dessus a un résultat très différent.… GPT-4 identifie correctement les deux bugs (même si un seul d’entre eux a directement conduit au crash) mais… Wolverine applique en fait les modifications proposées au script bogué et le réexécute. Cette fois-ci, il y a toujours une erreur, car les modifications précédentes de GPT-4 incluaient une instruction de retour hors de portée. Pas de problème, car Wolverine consulte à nouveau GPT-4, crée et formate une modification, l’applique et réexécute le script modifié. Cette fois, le script s’exécute avec succès.… Une grande partie de ce que Wolverine fait est grâce à une invite soigneusement rédigée.</p><p>C'est une bouche de cheval ? L'entité connue sous le nom de BioBootloader génère le jeton suivant, puis le suivant, puis le suivant et encore le suivant :</p><p>Il s'agit simplement d'un prototype rapide que j'ai réalisé en quelques heures. Il existe de nombreuses extensions possibles et les contributions sont les bienvenues :</p><li>ajouter des indicateurs pour personnaliser l'utilisation, comme demander la confirmation de l'utilisateur avant d'exécuter le code modifié</li><li>d'autres itérations sur le format d'édition dans lequel GPT répond. Actuellement, il a un peu de mal avec l'indentation, mais je suis sûr que cela peut être amélioré</li><li>une suite d'exemples de fichiers bogués sur lesquels nous pouvons tester des invites pour garantir la fiabilité et mesurer l'amélioration</li><li>plusieurs fichiers/bases de code : envoyer à GPT tout ce qui apparaît dans la trace de la pile</li><li>gestion élégante des fichiers volumineux : devrions-nous simplement envoyer les classes/fonctions GPT pertinentes ?</li><li>extension à d'autres langages que Python.</li><p>Quelque chose, quelque chose, SKYNET ? jszymborski le dit avec ironie :</p><p>Tout est amusant et ludique jusqu'à ce qu'un subprocess.run([""rm"", ""/"", ""-rf""]) se glisse là et que vous ne remarquez pas.</p><p>SRSLY mais ? physicsphairy a essayé quelque chose de similaire :</p><p>Il y a des limites à la complexité que vous pouvez implémenter avec ChatGPT, la plus importante étant le nombre de jetons qu'il peut conserver dans sa mémoire d'exécution. Cela dit, il peut certainement faire une quantité raisonnable d'architecture, y compris des choses comme la création d'UML réel. En codant un backend, vous pouvez lui demander une liste complète des points de terminaison d'API que vous devrez implémenter, même la spécification OpenAPI pour cela. Il n'a aucun problème avec un projet couvrant plusieurs fichiers, mais vous devez soit spécifier la disposition du fichier, soit le laisser le créer. Mon expérience est qu'une fois que la conversation est suffisamment avancée, il commence à « oublier », surtout si vous avez emprunté des chemins que vous choisissez plus tard de ne pas suivre. Il est très efficace pour le débogage. Vous pouvez ne rien savoir d'un langage et continuer à donner à GPT les messages d'erreur/traces de pile et éventuellement faire le bon changement pour que votre code fonctionne.</p><p>Cela « éventuellement » fait beaucoup de travail. Unequivocal a expérimenté ChatGPT comme assistant de codage :</p><p>C'est vraiment génial pour les intégrations d'API et autres codages « poubelles » où je sais ce qui doit être fait, mais il y a un tas d'éléments capricieux qui doivent être intégrés. C'est particulièrement efficace dans les API et les interfaces qui ont une documentation médiocre ou inexistante :… Cela a probablement réduit mon temps/effort de développement de moitié.… Mais exécuter une IA sans supervision sur une base de code ? Pas encore.</p><p>Je ne sais pas si c'est une efficacité brillante ou de la pure paresse. Sortez de la pelouse de Robbie :</p><p>Très astucieux… mais cela semble être simplement un outil pour encourager les mauvaises pratiques : « Oh, une erreur, je laisse l’IA la corriger. » Mieux vaut comprendre et déboguer correctement son code par soi-même, et aussi utiliser un langage compilé où ces erreurs seront toutes trouvées au moment de la compilation plutôt que d’apparaître aléatoirement à un moment donné pendant l’exécution.</p><p>Quoi qu’il en soit, c’est une définition extrêmement limitée de « l’auto-guérison ». Todd Knarr pense que c’est un jeu de salon :</p><p>C’est bien beau… mais ce n’est pas le gros problème. … Le gros problème n’est pas les programmes qui plantent. Ceux-ci sont généralement causés par des bugs faciles à trouver et à corriger. Parlez-moi quand l’IA peut prendre un programme qui fonctionne parfaitement bien mais qui produit un mauvais résultat, déterminer que le résultat est erroné, déterminer quel devrait être le bon résultat, revenir en arrière pour trouver où se trouvait l’erreur et la corriger. Et expliquez-moi comment la corriger.</p><p>Pendant ce temps, Andreas-Motzek va droit au but :</p><p>Il y a un bug si un programme ne se comporte pas conformément aux exigences. Comment ChatGTP connaît-il les exigences ?</p><p>—Benjamin FranklinVous lisez The Long View de Richi Jennings. Vous pouvez le contacter à @RiCHi ou à [email protected].</p><p>Image : Alex Shuper (via Unsplash ; nivelée et recadrée)</p>"
Comment le « Grand Rééquilibrage » accélère l’adoption du Low-Code/No-Code,"<p>Si vous lisez simplement les gros titres, vous pourriez penser que les carrières dans le secteur technologique sont limitées, en particulier pour les développeurs et les professionnels DevOps. Les médias et les sites d’emploi ont mis en avant chaque semaine les licenciements depuis le début de l’année, avec plus de 120 000 employés éliminés dans plus de 400 entreprises (dont Amazon, Alphabet, Microsoft, Meta et d’autres). Avec une telle élimination de talents techniques, on pourrait penser qu’il y aurait une surabondance de développeurs et peu de nouvelles opportunités de carrière pour les développeurs de logiciels.</p><p>En fait, c’est le contraire qui semble se produire. Aux États-Unis, la croissance de l’emploi s’est fortement accélérée en janvier, tandis que le taux de chômage est tombé à son plus bas niveau depuis 53 ans. Selon un récent rapport de Bain & Company, au niveau macroéconomique, la demande de talents techniques est toujours élevée, mais elle augmente désormais dans les secteurs non technologiques. « La croissance de la demande de talents technologiques de la part des entreprises non technologiques a vraiment changé la donne », a déclaré Jonathan Frick, associé chez Bain et l’un des auteurs de l’étude. En s’appuyant sur des offres d’emploi accessibles au public et sur des données du gouvernement américain, Bain a déterminé que la demande de travailleurs technologiques dans les entreprises non technologiques dépasse pour la première fois la demande dans les entreprises technologiques.</p><p>La « Grande Démission » est-elle en train de faire place au « Grand Rééquilibrage » alors que d’autres secteurs rattrapent enfin leur retard et ont la possibilité de trouver et d’embaucher des talents techniques ? Cela semble en partie vrai, mais il y a un autre point à retenir : le fait que les développeurs ne changent pas simplement d’employeur… il s’agit d’un changement plus fondamental et structurel dans le secteur. Alors que les talents ne se limitent plus aux entreprises technologiques traditionnelles, les entreprises non technologiques cherchent à appliquer l’innovation logicielle différemment. Voyons donc pourquoi cela ouvre la voie à 2023, « l’année du no-code ».</p><h3>Demande continue d'applications numériques</h3><p>On dit que « toutes les entreprises sont désormais des entreprises de logiciels » (selon les mots de Watts S. Humphrey, le père de la qualité dans les logiciels et de la CMMI). Les entreprises de toutes tailles et de tous les secteurs ont tiré parti des logiciels pour mettre en œuvre des initiatives de transformation numérique de grande envergure et placer les logiciels au cœur de leur stratégie commerciale. En fait, IDC prévoit que d’ici cette année, plus de 500 millions d’applications et de services numériques seront développés et déployés à l’aide d’approches cloud natives, soit le même nombre d’applications développées au cours des 40 dernières années. La majorité de ces nouvelles applications seront ciblées sur des scénarios de transformation numérique spécifiques à chaque secteur et définiront les exigences concurrentielles dans chaque secteur.</p><p>L’appétit croissant pour les applications numériques dépasse toujours largement l’offre de développeurs sur le marché. En conséquence, les organisations non technologiques recherchent désespérément des solutions nouvelles et créatives pour répondre à la demande. C’est l’une des principales raisons pour lesquelles les entreprises de tous les secteurs et de toutes les tailles se sont tournées vers le no-code. En accélérant le rythme de développement des logiciels, en utilisant des outils de glisser-déposer visuels et intuitifs, le no-code uniformise les règles du jeu et permet une livraison plus rapide des applications numériques sans avoir à attendre les ressources informatiques ou de développement rares.</p><h3>Les budgets de personnel restent limités</h3><p>Les entreprises non technologiques ont tendance à être plus pragmatiques dans leur façon d’investir. Contrairement aux entreprises technologiques, elles sont moins susceptibles d’investir dans de « nouvelles technologies brillantes », mais recherchent des justifications commerciales plus strictes et des retours sur investissement pour les projets de développement. En outre, l’incertitude générale persistante du marché et les inquiétudes concernant la récession continueront de pousser les entreprises à tirer le meilleur parti de leurs investissements. Ainsi, même s’il peut être plus facile de trouver des développeurs dans le vivier de talents, il n’existe pas de chèque en blanc pour embaucher à n’importe quel prix.</p><p>Cela incitera les organisations non technologiques à rechercher des moyens de permettre le développement d’applications au sein de leurs équipes commerciales dans le cadre d’une approche « Do it yourself » (DIY) du développement de logiciels. L’approche DIY permet aux équipes commerciales de jouer un rôle plus central dans le développement d’applications en utilisant des solutions low-code/no-code. En démocratisant le développement d’applications, le low-code/no-code permet à toute une nouvelle gamme de rôles non développeurs (souvent appelés « développeurs citoyens ») au sein d’une organisation de prendre en charge la création d’applications logicielles. Si les développeurs informatiques et professionnels restent importants pour certains types d’applications, l’utilisation du no-code a augmenté le vivier de talents au sein de la plupart des organisations, permettant aux employés de l’entreprise d’assumer des tâches de développement.</p><h3>Les organisations non technologiques responsables de la livraison quotidienne</h3><p>Les startups du secteur technologique sont habituées à un cycle de vie d’innovation traditionnel, qui consiste traditionnellement à accepter des années de défis tant que la startup peut démontrer une croissance rapide à tout prix ; une seule sortie réussie est considérée comme une récompense. Cependant, les entreprises non technologiques n’ont généralement pas le luxe de ce type de modèle de développement et sont scrutées pour montrer leur rentabilité et leurs bénéfices trimestriels. Les entreprises non technologiques recherchent des approches pour accélérer de nouvelles sources de ventes ou ajouter de nouveaux produits sur le marché plus rapidement. Elles doivent exploiter des stratégies de développement d’applications qui produisent des résultats en quelques jours/semaines (et non en mois/années).</p><p>En revanche, une approche de « livraison quotidienne » sans code est beaucoup plus évolutive et fournit un flux continu mais rapide de mises à jour à l’utilisateur final dans le cadre d’un cycle d’amélioration continue à grande vitesse. Le déploiement peut être basé sur des fonctionnalités spécifiques sans qu’il soit nécessaire de le relier à une échéance de sprint Agile spécifique ou à d’autres jalons formels. Ce mode de livraison quotidienne continue s’appuie sur le développement rapide et l’automatisation continue du déploiement fournis par les plateformes low-code/no-code. Ensemble, cela permet de pousser fréquemment (peut-être quotidiennement) des mises à jour rapides et de petite taille vers la production tout en maintenant des niveaux de qualité plus élevés que les versions de logiciels « big bang » traditionnelles.</p><h3>Conclusion</h3><p>On dit que chaque défi présente de nouvelles opportunités. Alors que les récents licenciements dans le secteur technologique semblent créer des défis et de l’incertitude, « The Great Rebalance » offre l’opportunité d’un nouveau modèle accéléré d’innovation dans tous les secteurs, à mesure que les entreprises non techniques trouvent des modèles nouveaux et différents pour le développement de logiciels. Dans les marchés dynamiques et imprévisibles dans lesquels nous vivons aujourd’hui, ceux qui évoluent et exploitent le low-code/no-code pour être compétitifs, se développer et prospérer dépasseront et devanceront leurs pairs. C’est pourquoi les entreprises adoptent avec enthousiasme des outils low-code/no-code et des approches de livraison quotidiennes pour profiter des avantages de l’accélération des délais de mise sur le marché et de la réduction des délais de livraison des résultats.</p>"
npm est un cloaque à escroqueries et spams ¦ Google dans la campagne antitrust de Microsoft,"<p>Bienvenue dans The Long View, où nous passons en revue l'actualité de la semaine et en tirons l'essentiel. Déterminons ce qui compte vraiment.</p><p>Cette semaine : le registre npm souffre d'une infestation de spam et Microsoft rend Google triste.</p><p>Tout d'abord cette semaine : les escrocs et les experts SEO inondent le référentiel npm de packages indésirables. Bien entendu, c'est exactement ce qui se passe toujours lorsque vous proposez un service gratuit pour les blobs partagés.</p><h3>Analyse : de nouveaux problèmes s'accumulent</h3><p>Opinion impopulaire : il est temps d’en finir avec les dépôts centralisés.</p><p>Gabi Dobocan : Un nouveau package NPM sur deux est un spam SEO</p><p>« La pointe de l’iceberg »Sur les ~320k nouveaux packages ou versions npm…au cours de la semaine dernière, au moins ~185k [sont] du spam SEO. Rien qu’au cours de la dernière heure au moment de la rédaction de cet article, 1583 nouveaux packages de spam de livres électroniques ont été publiés. Tous… sont actuellement en ligne sur npmjs.com.…La plupart des packages de spam…proviennent d’un seul…canal Telegram malveillant, avec plus de 7 000 membres…ciblant les russophones. Les noms des packages sont définis pour correspondre aux recherches sur divers sujets sensibles, comme la guerre en Ukraine ou les décisions d’investissement prises par Gazprom. La description du package, cependant, se lit comme suit : « Oubliez les problèmes financiers pour toujours : une nouvelle méthode de gain vous permettra de gagner des millions sans quitter votre domicile ! »…Nous sommes en train de signaler tous les packages de spam identifiés à npm. Nous pensons que ce n’est que la pointe de l’iceberg, car nous avons pu identifier de nombreux packages qui sont en ligne dans le référentiel npm depuis des années (comme uyo-xint).</p><p>Ah, la tragédie des biens communs de Lloyd. Peut-être que npm devrait facturer un petit prix par package ? dspillett explique pourquoi pas :</p><p>Les gens ne s’en soucieront pas, même si les frais sont minimes. Certains ne le peuvent tout simplement pas (pas d’accès aux systèmes de paiement internationaux), d’autres ne voudront tout simplement pas de cette administration supplémentaire. … Une alternative gratuite va surgir, beaucoup s’y tourneront et, une fois qu’elle sera suffisamment importante, elle deviendra une cible de spam, et nous reviendrons au point de départ, sauf que les choses sont un peu plus fragmentées.</p><p>Avec une autre idée, voici peterww :</p><p>Communauté de merde, expérience de merde. Ils ont besoin d'une modération communautaire... Cela pourrait être encore amélioré par divers moyens (captchas, confirmation de l'identité de l'utilisateur par SMS, etc.) Mais l'essentiel est d'avoir des humains dans la boucle, de ne pas permettre à n'importe qui de publier n'importe quoi et d'avoir un moyen d'identifier et de mettre en pause rapidement tout ce qui ressemble à un malware.</p><p>Une peste sur leurs deux maisons, pense verdverm :</p><p>Est-ce… un argument contre les registres centralisés ? Pourquoi ne pas aller directement à l’hôte du code source ? … La gestion des dépendances sans registre est la façon dont Go fonctionne aujourd’hui, et ne présente pas ces problèmes :…1. Pas besoin de passer du temps à publier, il suffit de pousser un commit2. Pas besoin de npm i ou de modifier un fichier : les modules peuvent être déduits des importations car ils utilisent le FQDN.</p><p>Pendant ce temps, ArchieBunker souhaite que vous quittiez sa pelouse :</p><p>La vraie question est de savoir pourquoi il est nécessaire d'intégrer autant de bibliothèques tierces. Comment diable des logiciels ont-ils pu être écrits dans les décennies qui ont précédé cette absurdité ?</p><p>Un vice-président de Google Cloud a critiqué Microsoft Azure, affirmant que l'entreprise recourait à des offres groupées immorales et à des accords secrets. Google demande aux régulateurs antitrust de l'UE d'agir.</p><h3>Analyse : la casserole rencontre la bouilloire IaaS</h3><p>Sérieusement, Google ? Quand il s’agit de tirer parti de votre énorme position sur le marché, votre réputation n’est pas vraiment irréprochable.</p><p>Foo Yun Chee : Google estime que les pratiques de Microsoft en matière de cloud sont anticoncurrentielles</p><p>« Querelle entre Google et Microsoft »Google Cloud a accusé Microsoft de pratiques anticoncurrentielles en matière de cloud computing et a critiqué les accords imminents avec plusieurs fournisseurs de cloud européens, affirmant que ceux-ci ne résolvent pas les problèmes plus larges concernant ses conditions de licence. [Alphabet] a soulevé la question auprès des agences antitrust et a exhorté les régulateurs antitrust de l’Union européenne à y regarder de plus près. « Microsoft a définitivement une posture très anticoncurrentielle dans le cloud. Ils tirent parti d’une grande partie de leur domination dans le secteur sur site ainsi que sur Office 365 et Windows pour lier Azure et le reste des services cloud », a déclaré Amit Zavery, vice-président de Google Cloud. « Lorsque nous parlons à beaucoup de nos clients, ils trouvent que beaucoup de ces pratiques de regroupement… les restrictions de prix et de licence font qu’il leur est difficile de choisir d’autres fournisseurs. »… Zavery a rejeté l’idée selon laquelle le problème n’est qu’une querelle entre Google et Microsoft : « C’est le cloud. « L’idée était de proposer un moyen ouvert et flexible de déployer votre logiciel et de [donner] aux clients plus de choix afin qu’ils puissent exécuter leur logiciel à l’endroit de leur choix. »</p><p>Bien sûr, il s’agit du cloud, mais Google joue à des jeux similaires. u/Savoritz20 :</p><p>Je serai toujours favorable à une concurrence plus forte. Tous les fournisseurs de cloud, y compris Google, rendent la migration vers un autre cloud incroyablement compliquée et coûteuse. Bien que le cloud soit toujours moins cher que sur site (dans la plupart des cas), il sera intéressant de voir ce que font les entreprises alors qu'elles continuent d'augmenter leurs prix. Le monde du cloud commence à ressembler au monde du streaming TV, sauf que vous ne pouvez pas simplement cliquer sur un bouton pour annuler votre abonnement.</p><p>Et tenez compte de la réplique grossière de OfMiceAndMenus :</p><p>Quoi ? Oh, va te faire foutre, Google. Tu es l’un des plus gros monopoles anticoncurrentiels, et même dans certains des mêmes domaines… Si tu veux poursuivre Microsoft pour pratiques déloyales en matière de cloud computing, tu vas devoir d’abord passer par AWS. C’est un poisson bien plus gros dans cet étang.</p><p>Une partie de la plainte de Google concerne les prix attractifs de Microsoft. u/_bobby_tables_ ne voit pas les choses de cette façon :</p><p>Ma facture Azure semble indiquer qu’il y a de la place pour la concurrence.</p><p>—Stephen HawkingVous avez lu The Long View de Richi Jennings. Vous pouvez le contacter à @RiCHi ou [email protected].</p><p>Image : Boxed Water (via Unsplash ; nivelée et recadrée)</p>"
Le Low-Code devrait s'inquiéter de ChatGPT,"<p>ChatGPT est-il la révolution technologique qui sauvera le monde ou la boîte de Pandore qui finira par le détruire ? Et si ni l’un ni l’autre n’existait ? En mettant ces deux extrêmes de côté, une question plus rationnelle est de savoir si ChatGPT va vous voler votre emploi, surtout si vous travaillez dans le développement de logiciels.</p><p>Est-ce une préoccupation légitime ? Ce genre de conversations n’a rien de nouveau. Les nouvelles technologies passent toujours par ce cycle : elles commencent par susciter l’intrigue, puis la peur et le ressentiment, avant d’être finalement acceptées et adoptées comme la nouvelle norme. ChatGPT et d’autres IA en langage naturel sont sans aucun doute de nouvelles tendances passionnantes au potentiel énorme. L’un des domaines du potentiel de ChatGPT qui a été largement négligé est la manière dont il peut démocratiser le développement de logiciels. Les fournisseurs low-code/no-code devraient-ils s’en inquiéter ?</p><h3>Tenir la promesse du Low-Code</h3><p>Le low code promet depuis longtemps de démocratiser le développement logiciel en permettant aux non-codeurs de développer eux-mêmes des applications. Cette « démocratisation de l’informatique » promet une nouvelle vague d’innovation en permettant aux organisations de créer de nouveaux processus sans avoir à s’adresser à l’informatique. Si le low code a déjà permis d’accomplir de grandes choses au moment et à l’endroit où il a été mis en œuvre, la quantité de changement qu’il peut apporter est fondamentalement limitée par les choix du développeur. Le développeur choisit toujours les aspects de l’application qui peuvent être configurés par l’utilisateur, de sorte que l’utilisateur n’a toujours pas d’accès fondamental au code. Bien que cela ait été la force du low code (puisque les utilisateurs ne peuvent pas endommager le code sous-jacent s’ils ne peuvent pas y accéder), les utilisateurs sont toujours redevables aux développeurs de faire quoi que ce soit d’important. ChatGPT pourrait permettre aux utilisateurs d’apporter des modifications plus importantes aux applications, ce qui permettrait potentiellement aux organisations d’accomplir bien plus qu’avec le low code et en deux fois moins de temps.</p><h3>Le développement de logiciels n’est que le début</h3><p>ChatGPT peut faire bien plus que d’aider les non-développeurs à créer les applications dont ils ont besoin. Si vous pensez à la raison la plus courante de l’échec d’un projet informatique, elle est rarement due uniquement à une mauvaise livraison ou à une mauvaise gestion. La plupart des projets informatiques échouent parce qu’ils ne produisent pas les résultats souhaités par les utilisateurs. Cela se produit en raison d’une rupture de communication entre le service informatique et les utilisateurs finaux. D’un côté, les utilisateurs ne parviennent pas à transmettre exactement ce qu’ils veulent et le service informatique ne pose pas les bonnes questions pour le savoir. Les exigences (c’est-à-dire les résultats escomptés) se perdent dans la traduction parce que les techniciens et les non-techniciens parlent tout simplement des langues différentes.</p><p>Dans un scénario où le message est trop souvent perdu dans la traduction, ChatGPT peut servir d’interprète entre ceux qui construisent et maintiennent l’informatique et le personnel plus large qui l’utilise au quotidien. ChatGPT peut combler le fossé car les utilisateurs n’auront pas besoin de compétences techniques pour réaliser les changements qu’ils souhaitent.</p><h3>Commencez toujours par l’analyse de rentabilisation</h3><p>Mettre en œuvre un changement dans une organisation est semé d’embûches et d’incertitudes. Comme pour tout projet, il est important de commencer par les fondamentaux de ce que vous essayez d’accomplir, et non par la technologie que vous souhaitez utiliser. Quelle que soit l’ampleur de votre utilisation de ChatGPT, vous devez commencer par définir les résultats que vous souhaitez atteindre et travailler à partir de là. La manière d’atteindre ces résultats est une décision technique qui intervient beaucoup plus tard. Si l’une de vos questions est de permettre un changement plus rapide et plus adaptable aux besoins de l’entreprise, ChatGPT pourrait bien faire partie de la réponse. N’oubliez pas de définir d’abord le problème, d’élaborer l’analyse de rentabilisation, puis d’évaluer les différentes solutions pour atteindre ces objectifs. Ne vous laissez pas emporter par le battage médiatique.</p><h3>ChatGPT a besoin d'espace pour prospérer en dehors du secteur informatique</h3><p>ChatGPT a le potentiel de faire le lien entre les utilisateurs techniques et non techniques de chaque organisation. Il peut réduire le fossé entre ces types de personnes radicalement différents pour accélérer le changement dans l’organisation et offrir de meilleurs résultats pour tous. Mais il est essentiel que des technologies comme ChatGPT soient implantées dans les domaines où elles auront le plus de chances de s’épanouir. Dans ce qui peut sembler une déclaration controversée de la part d’un acteur du secteur informatique, je pense que, comme le low-code, ChatGPT doit se situer en dehors du domaine technique. ChatGPT doit sortir du secteur informatique où il est né pour atteindre son plein potentiel. La question est de savoir si le secteur informatique est prêt à le laisser partir.</p><p>Image via Unsplash</p>"
Microsoft Power Platform intègre ChatGPT : ce que cela signifie,"<p>Microsoft a récemment annoncé l’intégration de ChatGPT dans sa suite de développement low-code Power Platform. Cette annonce fait suite à l’annonce de la recherche Bing optimisée par ChatGPT et à l’engagement de Microsoft d’investir des milliards dans sa société partenaire, OpenAI.</p><p>ChatGPT, le modèle de langage étendu (LLM), a atteint un statut viral en raison de sa capacité à générer des sorties textuelles incroyablement complexes à partir d’invites simples. Et maintenant, les entreprises espèrent tirer profit de sa puissance. L’inclusion de ChatGPT par Microsoft dans ses outils Power Virtual Agents et AI Builder signalera probablement une plus grande inclusion native de modèles d’IA dans d’autres environnements de développement low-code dans l’ensemble du secteur.</p><p>Mais tout n’est pas rose dans le monde de l’IA générative. Les utilisateurs ont dressé une longue liste d’échecs de ChatGPT, allant de simples erreurs arithmétiques et d’informations inexactes à des biais sociaux et même à une tentative de dissoudre le mariage d’un journaliste. L’IA semble sûre d’elle, mais les « hallucinations » qu’elle produit peuvent être incroyablement fausses. Si de telles inexactitudes persistent dans les cas d’utilisation en production, elles pourraient conduire à de fausses suggestions qui déroutent les utilisateurs et même nuire à la réputation d’une entreprise.</p><p>Ci-dessous, je vais examiner les implications de ce nouveau paradigme de développement piloté par l’IA, en explorant les avantages et les risques potentiels de l’intégration des LLM dans les cadres de développement low-code. Nous soulignerons également comment cela peut perturber la concurrence et examinerons les éléments que les dirigeants devraient garder à l’esprit lorsqu’ils cherchent à tirer parti de cette nouvelle technologie.</p><p>Les plateformes de développement low-code (LCDP) sont excellentes pour l’abstraction de fonctionnalités complexes en composants utilisables. Elles offrent généralement des fonctionnalités de glisser-déposer et des modèles réutilisables pour permettre aux développeurs citoyens et aux programmeurs professionnels de travailler de manière autonome. L’intégration de ChatGPT dans un tel environnement low-code présente de nombreux avantages potentiels. Par exemple, en tant que fonctionnalité de Power Virtual Agents, ChatGPT peut être utilisé pour créer des chatbots qui se connectent aux ressources publiques de l’entreprise et aux données internes de l’entreprise. Cela pourrait aider les utilisateurs à développer de manière transparente une IA sensible au contexte et formée sur les documents d’une entreprise.</p><p>L'utilisation de l'IA dans le low-code peut stimuler le développement grâce à des inférences et des conseils approfondis. Une telle assistance de l'IA peut accélérer considérablement les efforts de développement grâce à une saisie semi-automatique améliorée et à des informations intelligentes, en générant rapidement du code standard et en faisant des suggestions plus adaptées à la tâche à accomplir que vos modèles statiques classiques.</p><p>Les chatbots basés sur GPT et exploitant l’IA formée sur les documents d’une entreprise pourraient être incroyablement plus utiles qu’un modèle standard sans contexte. Dans le domaine du support client, une IA formée en interne pourrait être utile pour résumer les informations de l’entreprise et automatiser les activités de support manuelles. Fournir un moyen low-code pour générer de tels chatbots permet également d’apporter l’IA avancée à un plus large éventail d’utilisateurs. Dans l’ensemble, cela pourrait accélérer le rythme du développement, en particulier pour les interfaces mobiles, les flux de travail automatisés et les chatbots contextuels.</p><p>Dans le sillage de ChatGPT, le marché s’est empressé de réagir. Les géants de la technologie ont lancé leur propre IA générative, avec des critiques mitigées. Et certains, dont moi-même, se demandent comment le low-code et l’IA cohabiteront dans cette nouvelle ère. La génération de code basée sur le langage naturel remplacera-t-elle entièrement le besoin de programmation, qu’elle soit traditionnelle ou « sans code » ?</p><p>Cela reste incertain. Mais ce qui semble le plus plausible, c’est que ces développements récents vont relever la barre dans l’ensemble de l’industrie du logiciel et améliorer la manière dont les LCDP sont construits et utilisés. L’IA a le pouvoir d’améliorer les LCDP de plusieurs manières, notamment en améliorant l’expérience du développeur, en formant des modèles ML sur mesure et en créant des expériences utilisateur finales plus intelligentes.</p><p>Cependant, alors que Microsoft investit des milliards dans la recherche et le développement de l’IA, il pourrait être difficile pour les plateformes low-code de taille moyenne de suivre le rythme sans leurs propres flux de travail pilotés par l’IA. Ainsi, les plateformes LCDP qui n’intègrent pas leur propre IA robuste risquent de perdre de nouveaux abonnés. De plus, les ingénieurs espérant créer des modèles d’IA fonctionnant sur des ensembles de données internes préféreront peut-être travailler avec une suite technologique cloud plus vaste dans laquelle leurs données sont stockées de manière native.</p><p>ChatGPT et d’autres modèles génératifs sont absolument impressionnants, mais les résultats ne sont pas fiables à 100 %. Et au moment de la rédaction de cet article, l’utilisation de ChatGPT dans PowerApps est encore expérimentale, ce qui est révélateur du fait que ChatGPT et l’IA générative en général sont encore en phase d’expérimentation.</p><p>Cela n’est pas de bon augure pour les programmeurs qui s’appuient sur ses résultats, étant donné le risque d’inexactitudes. En effet, même si les résultats de ChatGPT semblent fiables, ils sont générés à partir de connaissances extraites du Web public, qui contient souvent des bugs, des erreurs et des inefficacités.</p><p>Les résultats de ChatGPT peuvent même suggérer des fonctionnalités totalement inexistantes ! C’est malheureusement un problème actuel avec le fournisseur d’API de géocodage OpenCage. ChatGPT recommande régulièrement aux utilisateurs d’intégrer le « service de recherche de téléphone » d’OpenCage pour certaines invites. Mais… OpenCage n’offre même pas cette fonctionnalité. L’équipe a reçu tellement de plaintes de développeurs en colère qu’elle a même dû publier une déclaration expliquant ce qui s’est passé.</p><p>Avec la génération de code par IA, l’accent n’est plus mis sur le codage en dur, mais sur la création et l’organisation des invites et le débogage des erreurs. Et même si cela donne aux programmeurs une nouvelle agilité, cela ne résout pas tous les problèmes de développement logiciel, notamment le côté DevOps de l’équation. Il y aura toujours des frictions dans le déploiement du code et la mise en place d’une architecture optimale. De plus, en raison des vulnérabilités croissantes de la chaîne d’approvisionnement des logiciels, l’automatisation du code qui se déroule en boucle dans des dépendances tierces doit nécessiter une réflexion approfondie sur la sécurité. Il existe également un risque de rupture des modifications et de problèmes de maintenance continue avec n’importe quel logiciel.</p><p>Un autre élément important est que le low-code nécessite une gouvernance correctement sécurisée. Les utilisateurs métiers du no-code ne disposent peut-être pas de la supervision de sécurité nécessaire pour comprendre les implications du lancement de nouveaux services. Et lorsque vous ajoutez l’IA à l’équation, les implications techniques s’intensifient. L’IA peut entraîner des violations éthiques, et il a été constaté que les robots communiquent de la colère et des idées irrationnelles lorsqu’ils sont poussés et poussés.</p><p>On parle d’« hallucination » lorsqu’un modèle d’IA débite avec assurance des informations insensées ou inexactes. Et même si c’est le cas de certains modèles actuellement, ils acceptent activement les commentaires et sont réentraînés. Au fil du temps, leurs résultats s’amélioreront. Mais pour l’instant, les ingénieurs doivent être conscients qu’ils sont encore en phase d’expérimentation. Les entreprises doivent donc faire preuve de prudence et tester d’abord les nouvelles innovations en matière d’IA sur des processus internes. Et l’adoption de l’IA doit être gérée avec soin pour éviter les erreurs de configuration et les abus.</p><p>L’IA est là, et l’avenir est là. Mais même si elle fait tomber certaines barrières du codage, les développeurs ont encore du pain sur la planche. Cette réalité est une victoire pour les solutions low-code qui offrent des pipelines de livraison de logiciels standard et des fonctionnalités de collaboration centralisées. Si les LCDP parviennent à suivre le rythme de l’IA et à l’intégrer à leurs flux de travail, les deux parties devraient s’en sortir plutôt bien dans cette nouvelle ère.</p><p>Surprise — cet article a été entièrement écrit par ChatGPT. Je plaisante ! Rien de tout cela ne l’est. J’en ai juste assez de voir ce moment « gotcha » à la fin des segments d’actualité…</p><p>Ce message a été écrit par un humain.</p>"
